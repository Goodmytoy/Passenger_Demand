{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excited-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import ast\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Data_by_API(object):\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.features = None\n",
    "        self.main_key = None\n",
    "#         self.serviceKey = serviceKey\n",
    "    \n",
    "    \n",
    "    def calculate_max_page(self, type = \"json\"):\n",
    "        rq = self.request()\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = rq.text, type = type)\n",
    "        \n",
    "        self.n_rows = int(self.params_dict[\"numOfRows\"])\n",
    "        \n",
    "        try:\n",
    "            self.total_count = int(rq_dict[\"response\"][\"body\"][\"totalCount\"])\n",
    "        except:\n",
    "            xmlsoup = BeautifulSoup(rq.text,'html.parser')\n",
    "            self.total_count = int(xmlsoup.find(\"totalcount\").text)\n",
    "                \n",
    "        max_page = int(np.ceil(self.total_count / self.n_rows))\n",
    "        \n",
    "        print(f\"n_rows : {self.n_rows}, total_count : {self.total_count}, max_page = {max_page}\")\n",
    "        \n",
    "        return max_page\n",
    "    \n",
    "    \n",
    "    def create_request_url(self, params_dict):\n",
    "#         params_dict[\"service_key\"] = self.serviceKey\n",
    "        params_list = [f\"{k}={v}\" for k, v in params_dict.items()]\n",
    "        params_str = \"&\".join(params_list)\n",
    "#         print(params_str)\n",
    "        \n",
    "        self.request_url = self.url + params_str\n",
    "        \n",
    "        return self.request_url\n",
    "    \n",
    "    \n",
    "    def create_request_urls(self):\n",
    "        max_page = self.calculate_max_page(type = self.type)\n",
    "        \n",
    "        params_dict = self.params_dict.copy()\n",
    "        \n",
    "        request_urls= []\n",
    "        for i in range(max_page):\n",
    "            params_dict[\"pageNo\"] = i + 1\n",
    "            request_urls.append(self.create_request_url(params_dict = params_dict))\n",
    "            \n",
    "        return request_urls\n",
    "    \n",
    "\n",
    "    \n",
    "    def to_dict(self, txt, type):\n",
    "        # json / xml to dict\n",
    "        if type == \"json\":\n",
    "            rq_dict = ast.literal_eval(txt)\n",
    "        elif type == \"xml\":\n",
    "            rq_dict = xmltodict.parse(txt)\n",
    "            \n",
    "        return rq_dict\n",
    "    \n",
    "    \n",
    "    def extract_values_from_dict(self, dct):\n",
    "        try: \n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"][\"item\"]\n",
    "        except:\n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"]\n",
    "            \n",
    "        return dict_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    def parse(self, request, features = None, type = \"json\"):\n",
    "        \n",
    "        data_dict = defaultdict(list)\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = request.text, type = type)\n",
    "        \n",
    "        # 일부 url의 경우는 item이 아닌 items에 값이 존재\n",
    "        dict_list = self.extract_values_from_dict(dct = rq_dict)\n",
    "        self.dict_list = dict_list\n",
    "        # 값이 1개인 경우 list가 아니라 dictionary 1개가 반환되므로, 이를 list(dict)형태로 변환\n",
    "        if isinstance(dict_list, dict):\n",
    "            dict_list = [dict_list]\n",
    "        \n",
    "        # item이 없는 경우 빈 Dictionary(data dict)를 반환\n",
    "        if dict_list is None:\n",
    "            return data_dict\n",
    "        \n",
    "        if features is None:\n",
    "            features = dict_list[0].keys()\n",
    "            \n",
    "        for x in dict_list:\n",
    "            for col in features:\n",
    "                data_dict[col].append(x.get(col))\n",
    "\n",
    "        return data_dict\n",
    "    \n",
    "    \n",
    "    def request(self, request_url = None):\n",
    "        \n",
    "        if request_url == None:\n",
    "            request_url = self.request_url\n",
    "            \n",
    "        rq = requests.get(request_url, allow_redirects = True)\n",
    "        \n",
    "        return rq\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class Weather_Data_by_API(Data_by_API):\n",
    "    \n",
    "    base_url = \"http://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList?\"\n",
    "    \n",
    "    def __init__(self, params_dict):\n",
    "        super().__init__(url = self.base_url)\n",
    "        self.request_url = super().create_request_url(params_dict = params_dict)\n",
    "        self.params_dict = params_dict\n",
    "        self.type = params_dict[\"dataType\"].lower()\n",
    "    \n",
    "    \n",
    "    def get(self):\n",
    "        \n",
    "        self.request_urls = self.create_request_urls()\n",
    "\n",
    "        data_dict = defaultdict(list)\n",
    "        for request_url in self.request_urls:\n",
    "            rq = self.request(request_url = request_url)\n",
    "            text_dict = self.parse(request = rq, features = None, type = self.type)\n",
    "            \n",
    "            for k, v in text_dict.items():\n",
    "                data_dict[k].extend(v)\n",
    "            \n",
    "        return pd.DataFrame(data_dict)\n",
    "    \n",
    "    \n",
    "def Load_Weather_Data(params_dict,\n",
    "                      save_tf = False, \n",
    "                      save_path = os.getcwd()):\n",
    "    \n",
    "    weather_api = Weather_Data_by_API(params_dict = params_dict)\n",
    "    weather_data = weather_api.get()\n",
    "    \n",
    "    \n",
    "    # index 초기화\n",
    "    weather_data = weather_data.drop_duplicates().reset_index(drop=True)\n",
    "  \n",
    "    # 저장여부 변수가 True면 csv파일로 저장, False면 Df로 리턴\n",
    "    if save_tf == True :\n",
    "        weather_data.to_csv(save_path +'/weather_data.csv', index=False)\n",
    "    else :\n",
    "        return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "remarkable-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./asdfadsf/asdfasdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "motivated-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(save_path) == False:\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "running-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_key = 'eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D'\n",
    "google_key = \"ReOsv=IfT43PVLSiA4vDRjs=40TCqIw97oVP2D9QpmU=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "negative-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_year  = \"2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "respiratory-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_params = {\"serviceKey\" : service_key,\n",
    "                   \"stnIds\" : \"152\",\n",
    "                   \"startDt\" : f\"{base_year}0101\",\n",
    "                   \"startHh\" : \"00\",\n",
    "                   \"endDt\" : f\"{base_year}1230\", \n",
    "                   \"endHh\" : \"23\",\n",
    "                   \"numOfRows\" : \"900\",\n",
    "                   \"dataType\" : \"XML\",\n",
    "                   \"pageNo\" : \"1\",\n",
    "                   \"dataCd\" : \"ASOS\",\n",
    "                   \"dateCd\" : \"HR\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mighty-camel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList?serviceKey=eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D&stnIds=152&startDt=20200101&startHh=00&endDt=20201230&endHh=23&numOfRows=900&dataType=XML&pageNo=1&dataCd=ASOS&dateCd=HR'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_api.request_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "three-august",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcalculate_max_page\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrq_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"body\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"totalCount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'response'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-71092eb3b6c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweather_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeather_Data_by_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweather_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_request_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcreate_request_urls\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mmax_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_max_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcalculate_max_page\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mxmlsoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmlsoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"totalcount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmax_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "weather_api = Weather_Data_by_API(params_dict = weather_params)\n",
    "weather_data = weather_api.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "infectious-silicon",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcalculate_max_page\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrq_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"body\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"totalCount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'response'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fc370014cb69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 날씨 정보 수집\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLoad_Weather_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mLoad_Weather_Data\u001b[0;34m(params_dict, save_tf, save_path)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mweather_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeather_Data_by_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mweather_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_request_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcreate_request_urls\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mmax_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_max_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcalculate_max_page\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mxmlsoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmlsoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"totalcount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmax_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# 날씨 정보 수집\n",
    "Load_Weather_Data(weather_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-lewis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-romance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-wheat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-crossing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-plaza",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "green-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "continuing-programming",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ds_user1/.ssh/id_rsa.pub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b55dbfef185b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/ds_user1/.ssh/id_rsa.pub\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ds_user1/.ssh/id_rsa.pub'"
     ]
    }
   ],
   "source": [
    "f = open(\"/home/ds_user1/.ssh/id_rsa.pub\", \"r\")\n",
    "text = f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "irish-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlemaps import exceptions\n",
    "exceptions.ApiError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "simplified-boundary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "googlemaps.exceptions.ApiError"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exceptions.ApiError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crucial-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call([\"pip\", \"install\", \"bs4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "referenced-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_params_dict = {\"serviceKey\" : 'eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D', \"solYear\" : 2020}\n",
    "\n",
    "import subprocess\n",
    "subprocess.call([\"pip\", \"install\", \"beautifulsoup4\"])\n",
    "subprocess.call([\"pip\", \"install\", \"xmltodict\"])\n",
    "subprocess.call([\"pip\", \"install\", \"ast\"])\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import ast\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Data_by_API(object):\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.features = None\n",
    "        self.main_key = None\n",
    "#         self.serviceKey = serviceKey\n",
    "    \n",
    "    \n",
    "    def calculate_max_page(self, type = \"json\"):\n",
    "        rq = self.request()\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = rq.text, type = type)\n",
    "        \n",
    "        self.n_rows = int(self.params_dict[\"numOfRows\"])\n",
    "        \n",
    "        try:\n",
    "            self.total_count = int(rq_dict[\"response\"][\"body\"][\"totalCount\"])\n",
    "        except:\n",
    "            xmlsoup = BeautifulSoup(rq.text,'html.parser')\n",
    "            self.total_count = int(xmlsoup.find(\"totalcount\").text)\n",
    "                \n",
    "        max_page = int(np.ceil(self.total_count / self.n_rows))\n",
    "        \n",
    "        print(f\"n_rows : {self.n_rows}, total_count : {self.total_count}, max_page = {max_page}\")\n",
    "        \n",
    "        return max_page\n",
    "    \n",
    "    \n",
    "    def create_request_url(self, params_dict):\n",
    "#         params_dict[\"service_key\"] = self.serviceKey\n",
    "        params_list = [f\"{k}={v}\" for k, v in params_dict.items()]\n",
    "        params_str = \"&\".join(params_list)\n",
    "#         print(params_str)\n",
    "        \n",
    "        self.request_url = self.url + params_str\n",
    "        \n",
    "        return self.request_url\n",
    "    \n",
    "    \n",
    "    def create_request_urls(self):\n",
    "        max_page = self.calculate_max_page(type = self.type)\n",
    "        \n",
    "        params_dict = self.params_dict.copy()\n",
    "        \n",
    "        request_urls= []\n",
    "        for i in range(max_page):\n",
    "            params_dict[\"pageNo\"] = i + 1\n",
    "            request_urls.append(self.create_request_url(params_dict = params_dict))\n",
    "            \n",
    "        return request_urls\n",
    "    \n",
    "\n",
    "    \n",
    "    def to_dict(self, txt, type):\n",
    "        # json / xml to dict\n",
    "        if type == \"json\":\n",
    "            rq_dict = ast.literal_eval(txt)\n",
    "        elif type == \"xml\":\n",
    "            rq_dict = xmltodict.parse(txt)\n",
    "            \n",
    "        return rq_dict\n",
    "    \n",
    "    \n",
    "    def extract_values_from_dict(self, dct):\n",
    "        try: \n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"][\"item\"]\n",
    "        except:\n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"]\n",
    "            \n",
    "        return dict_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    def parse(self, request, features = None, type = \"json\"):\n",
    "        \n",
    "        data_dict = defaultdict(list)\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = request.text, type = type)\n",
    "        \n",
    "        # 일부 url의 경우는 item이 아닌 items에 값이 존재\n",
    "        dict_list = self.extract_values_from_dict(dct = rq_dict)\n",
    "        self.dict_list = dict_list\n",
    "        # 값이 1개인 경우 list가 아니라 dictionary 1개가 반환되므로, 이를 list(dict)형태로 변환\n",
    "        if isinstance(dict_list, dict):\n",
    "            dict_list = [dict_list]\n",
    "        \n",
    "        # item이 없는 경우 빈 Dictionary(data dict)를 반환\n",
    "        if dict_list is None:\n",
    "            return data_dict\n",
    "        \n",
    "        if features is None:\n",
    "            features = dict_list[0].keys()\n",
    "            \n",
    "        for x in dict_list:\n",
    "            for col in features:\n",
    "                data_dict[col].append(x.get(col))\n",
    "\n",
    "        return data_dict\n",
    "    \n",
    "    \n",
    "    def request(self, request_url = None):\n",
    "        \n",
    "        if request_url == None:\n",
    "            request_url = self.request_url\n",
    "            \n",
    "        rq = requests.get(request_url, allow_redirects = True)\n",
    "        \n",
    "        return rq\n",
    "\n",
    "class Holiday_Data_by_API(Data_by_API):\n",
    "    \n",
    "    holiday_url = \"http://apis.data.go.kr/B090041/openapi/service/SpcdeInfoService/getHoliDeInfo?\"\n",
    "    restday_url = \"http://apis.data.go.kr/B090041/openapi/service/SpcdeInfoService/getRestDeInfo?\"\n",
    "    \n",
    "    def __init__(self, params_dict, type):\n",
    "        if type == \"holi\":\n",
    "            base_url = self.holiday_url\n",
    "        elif type == \"rest\":\n",
    "            base_url = self.restday_url\n",
    "            \n",
    "        super().__init__(url = base_url)\n",
    "#         self.year = year\n",
    "        self.params_dict = params_dict\n",
    "        self.type = \"xml\"\n",
    "        \n",
    "    \n",
    "    def create_request_urls(self, params_dict):\n",
    "        params_dict = params_dict.copy()\n",
    "        request_urls = []\n",
    "        for x in range(1, 13):\n",
    "            if x < 10:\n",
    "                params_dict[\"solMonth\"] =  f\"0{str(x)}\"\n",
    "\n",
    "            else:\n",
    "                params_dict[\"solMonth\"] =  str(x)\n",
    "                \n",
    "            request_urls.append(self.create_request_url(params_dict = params_dict))\n",
    "    \n",
    "        return request_urls\n",
    "    \n",
    "    \n",
    "    def get(self):\n",
    "        \n",
    "        if \"solMonth\" in self.params_dict.keys():\n",
    "            self.request_urls = [self.create_request_url(params_dict = self.params_dict)]\n",
    "        else:             \n",
    "            self.request_urls = self.create_request_urls(params_dict = self.params_dict)\n",
    "        \n",
    "        data_dict = defaultdict(list)\n",
    "        for request_url in self.request_urls:\n",
    "            \n",
    "            rq = super().request(request_url = request_url)\n",
    "            temp_dict = super().parse(request = rq, features = [\"locdate\", \"dateName\"], type = self.type)\n",
    "            \n",
    "            for k, v in temp_dict.items():\n",
    "                data_dict[k].extend(v)\n",
    "\n",
    "                    \n",
    "        return pd.DataFrame(data_dict)\n",
    "    \n",
    "\n",
    "\n",
    "def Load_Holiday_Data(params_dict,\n",
    "                      save_tf = False, \n",
    "                      save_path = os.getcwd()):\n",
    "    \n",
    "    holiday_api = Holiday_Data_by_API(params_dict = params_dict, type = \"rest\")\n",
    "    holiday_data = holiday_api.get()\n",
    "    \n",
    "    # index 초기화\n",
    "    holiday_data = holiday_data.reset_index(drop=True)\n",
    "  \n",
    "    # 저장여부 변수가 True면 csv파일로 저장, False면 Df로 리턴\n",
    "    if save_tf == True :\n",
    "        holiday_data.to_csv(save_path +'/holiday_data.csv', index=False)\n",
    "    else :\n",
    "        return holiday_data\n",
    "    \n",
    "holiday_data = Load_Holiday_Data(holiday_params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-mouth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-devon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-cleaner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-offense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_Load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southwest-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"울산\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occupied-beach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows : 1000, total_count : 500, max_page = 1\n"
     ]
    }
   ],
   "source": [
    "# 학교(초중고) 정보 수집\n",
    "Load_School_Data(school_params_dict,\n",
    "                 select_region = city, save_tf = True, save_path = \"/home/seho/Passenger_Demand/data/api_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "identified-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_geocodeDf() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9db52c72ec24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 대학교 정보 수집\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m Load_University_Data(university_params_dict,\n\u001b[0m\u001b[1;32m      3\u001b[0m                      \u001b[0mgoogle_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AIzaSyDfLv3OzniRbUc7tTRBJndpiuyepHSmUrE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mselect_region\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0msave_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/Passenger_Demand/model/Data_Load/University_Data_by_API.py\u001b[0m in \u001b[0;36mLoad_University_Data\u001b[0;34m(params_dict, google_key, select_region, save_tf, save_path)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Geocoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0muniversity_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_geocodeDf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniversity_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adres\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoogle_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# index 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_geocodeDf() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# 대학교 정보 수집\n",
    "Load_University_Data(university_params_dict,\n",
    "                     google_key = 'AIzaSyDfLv3OzniRbUc7tTRBJndpiuyepHSmUrE',\n",
    "                     select_region = city,\n",
    "                     save_tf = True,\n",
    "                     save_path = \"/home/seho/Passenger_Demand/data/api_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-plastic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
