{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "anticipated-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "\n",
    "\n",
    "def get_geocode(x, google_key):\n",
    "    gmaps = googlemaps.Client(key= google_key)\n",
    "    \n",
    "    try:\n",
    "        result = gmaps.geocode(x)[0][\"geometry\"][\"location\"]\n",
    "        \n",
    "    except:\n",
    "        result = None\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_geocodeDf(df, col, google_key):\n",
    "    tempDf = df.copy()\n",
    "    tempDf[\"lat_lng\"] = tempDf[col].apply(lambda x: get_geocode(x, google_key))\n",
    "    \n",
    "    tempDf = tempDf[tempDf['lat_lng'].notnull()].copy()\n",
    "    tempDf[\"latitude\"] = tempDf[\"lat_lng\"].apply(lambda x: x[\"lat\"])\n",
    "    tempDf[\"longitude\"] = tempDf[\"lat_lng\"].apply(lambda x: x[\"lng\"])\n",
    "    \n",
    "    del tempDf[\"lat_lng\"]\n",
    "    return tempDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "expanded-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import ast\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Data_by_API(object):\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.features = None\n",
    "        self.main_key = None\n",
    "#         self.serviceKey = serviceKey\n",
    "    \n",
    "    \n",
    "    def calculate_max_page(self, type = \"json\"):\n",
    "        rq = self.request()\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = rq.text, type = type)\n",
    "        \n",
    "        self.n_rows = int(self.params_dict[\"numOfRows\"])\n",
    "        \n",
    "        try:\n",
    "            self.total_count = int(rq_dict[\"response\"][\"body\"][\"totalCount\"])\n",
    "        except:\n",
    "            xmlsoup = BeautifulSoup(rq.text,'html.parser')\n",
    "            self.total_count = int(xmlsoup.find(\"totalcount\").text)\n",
    "                \n",
    "        max_page = int(np.ceil(self.total_count / self.n_rows))\n",
    "        \n",
    "        print(f\"n_rows : {self.n_rows}, total_count : {self.total_count}, max_page = {max_page}\")\n",
    "        \n",
    "        return max_page\n",
    "    \n",
    "    \n",
    "    def create_request_url(self, params_dict):\n",
    "#         params_dict[\"service_key\"] = self.serviceKey\n",
    "        params_list = [f\"{k}={v}\" for k, v in params_dict.items()]\n",
    "        params_str = \"&\".join(params_list)\n",
    "#         print(params_str)\n",
    "        \n",
    "        self.request_url = self.url + params_str\n",
    "        \n",
    "        return self.request_url\n",
    "    \n",
    "    \n",
    "    def create_request_urls(self):\n",
    "        max_page = self.calculate_max_page(type = self.type)\n",
    "        \n",
    "        params_dict = self.params_dict.copy()\n",
    "        \n",
    "        request_urls= []\n",
    "        for i in range(max_page):\n",
    "            params_dict[\"pageNo\"] = i + 1\n",
    "            request_urls.append(self.create_request_url(params_dict = params_dict))\n",
    "            \n",
    "        return request_urls\n",
    "    \n",
    "\n",
    "    \n",
    "    def to_dict(self, txt, type):\n",
    "        # json / xml to dict\n",
    "        if type == \"json\":\n",
    "            rq_dict = ast.literal_eval(txt)\n",
    "        elif type == \"xml\":\n",
    "            rq_dict = xmltodict.parse(txt)\n",
    "            \n",
    "        return rq_dict\n",
    "    \n",
    "    \n",
    "    def extract_values_from_dict(self, dct):\n",
    "        try: \n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"][\"item\"]\n",
    "        except:\n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"]\n",
    "            \n",
    "        return dict_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    def parse(self, request, features = None, type = \"json\"):\n",
    "        \n",
    "        data_dict = defaultdict(list)\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = request.text, type = type)\n",
    "        \n",
    "        # 일부 url의 경우는 item이 아닌 items에 값이 존재\n",
    "        dict_list = self.extract_values_from_dict(dct = rq_dict)\n",
    "        self.dict_list = dict_list\n",
    "        # 값이 1개인 경우 list가 아니라 dictionary 1개가 반환되므로, 이를 list(dict)형태로 변환\n",
    "        if isinstance(dict_list, dict):\n",
    "            dict_list = [dict_list]\n",
    "        \n",
    "        # item이 없는 경우 빈 Dictionary(data dict)를 반환\n",
    "        if dict_list is None:\n",
    "            return data_dict\n",
    "        \n",
    "        if features is None:\n",
    "            features = dict_list[0].keys()\n",
    "            \n",
    "        for x in dict_list:\n",
    "            for col in features:\n",
    "                data_dict[col].append(x.get(col))\n",
    "\n",
    "        return data_dict\n",
    "    \n",
    "    \n",
    "    def request(self, request_url = None):\n",
    "        \n",
    "        if request_url == None:\n",
    "            request_url = self.request_url\n",
    "            \n",
    "        rq = requests.get(request_url, allow_redirects = True)\n",
    "        \n",
    "        return rq\n",
    "        \n",
    "\n",
    "class University_Data_by_API(Data_by_API):\n",
    "    \n",
    "    base_url = \"http://www.career.go.kr/cnet/openapi/getOpenApi?\" # JSON , XML\n",
    "    \n",
    "    def __init__(self, params_dict):\n",
    "        super().__init__(url = self.base_url)\n",
    "        self.request_url = super().create_request_url(params_dict = params_dict)\n",
    "        self.params_dict = params_dict\n",
    "        self.type = params_dict.get(\"contentType\")\n",
    "    \n",
    "    \n",
    "    def extract_values_from_dict(self, dct):\n",
    "        try: \n",
    "            dict_list = dct[\"dataSearch\"][\"content\"]\n",
    "        except:\n",
    "            dict_list = dct[\"dataSearch\"][\"content\"]\n",
    "        \n",
    "        return dict_list\n",
    "    \n",
    "    \n",
    "    def create_request_urls(self):\n",
    "        max_page = 1\n",
    "        \n",
    "        params_dict = self.params_dict.copy()\n",
    "        \n",
    "        request_urls= []\n",
    "        for i in range(max_page):\n",
    "            params_dict[\"thisPage\"] = i + 1\n",
    "            request_urls.append(super().create_request_url(params_dict = params_dict))\n",
    "            \n",
    "        return request_urls\n",
    "  \n",
    "    \n",
    "    def get(self):\n",
    "        \n",
    "        self.request_urls = self.create_request_urls()\n",
    "        \n",
    "        data_dict = defaultdict(list)\n",
    "        for request_url in self.request_urls:\n",
    "            rq = self.request(request_url = request_url)\n",
    "            temp_dict = self.parse(request = rq, features = None, type = self.type)\n",
    "            \n",
    "            for k, v in temp_dict.items():\n",
    "                data_dict[k].extend(v)\n",
    "            \n",
    "        return pd.DataFrame(data_dict)\n",
    "    \n",
    "\n",
    "    \n",
    "def Load_University_Data(params_dict,\n",
    "                         google_key,\n",
    "                         select_region = '', \n",
    "                         save_tf = False, \n",
    "                         save_path = os.getcwd()):\n",
    "    \n",
    "    university_api = University_Data_by_API(params_dict = params_dict)\n",
    "    university_data = university_api.get()\n",
    "    \n",
    "    # 선택된 지역 데이터 추출\n",
    "    if select_region != '':\n",
    "        university_data = university_data.loc[university_data[\"region\"].str.contains(select_region)]\n",
    "\n",
    "    # Geocoding\n",
    "    university_data = get_geocodeDf(university_data, \"adres\", google_key)\n",
    "    \n",
    "    # index 초기화\n",
    "    university_data = university_data.reset_index(drop=True)\n",
    "  \n",
    "    # 저장여부 변수가 True면 csv파일로 저장, False면 Df로 리턴\n",
    "    if save_tf == True :\n",
    "        if os.path.exists(save_path) == False:\n",
    "            os.makedirs(save_path)        \n",
    "        university_data.to_csv(save_path +'/university_data.csv', index=False)\n",
    "    else :\n",
    "        return university_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exciting-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "university_params = {\"apiKey\" : service_key,\n",
    "                          \"svcType\" : 'api',\n",
    "                          \"svcCode\" : 'SCHOOL',\n",
    "                          \"gubun\" : 'univ_list',\n",
    "                          \"thisPage\" : 1,\n",
    "                          \"perPage\" : 1000,\n",
    "                          \"contentType\" : \"json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://www.career.go.kr/cnet/openapi/getOpenApi?apiKey=eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D&svcType=api&svcCode=SCHOOL&gubun=univ_list&thisPage=1&perPage=1000&contentType=json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interim-vampire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.career.go.kr/cnet/openapi/getOpenApi?apiKey=eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D&svcType=api&svcCode=SCHOOL&gubun=univ_list&thisPage=1&perPage=1000&contentType=json'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "university_api.request_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "french-hardware",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3437\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-18-6720b50c942f>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    university_data = university_api.get()\n",
      "  File \u001b[1;32m\"<ipython-input-16-904ae0e66e4a>\"\u001b[0m, line \u001b[1;32m164\u001b[0m, in \u001b[1;35mget\u001b[0m\n    temp_dict = self.parse(request = rq, features = None, type = self.type)\n",
      "  File \u001b[1;32m\"<ipython-input-16-904ae0e66e4a>\"\u001b[0m, line \u001b[1;32m91\u001b[0m, in \u001b[1;35mparse\u001b[0m\n    rq_dict = self.to_dict(txt = request.text, type = type)\n",
      "  File \u001b[1;32m\"<ipython-input-16-904ae0e66e4a>\"\u001b[0m, line \u001b[1;32m70\u001b[0m, in \u001b[1;35mto_dict\u001b[0m\n    rq_dict = ast.literal_eval(txt)\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.8/ast.py\"\u001b[0m, line \u001b[1;32m59\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/conda/lib/python3.8/ast.py\"\u001b[0;36m, line \u001b[0;32m47\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <!DOCTYPE html>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "university_api = University_Data_by_API(params_dict = university_params)\n",
    "university_data = university_api.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-graphics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-payment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bearing-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./asdfadsf/asdfasdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "guided-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(save_path) == False:\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dense-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_key = 'eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D'\n",
    "google_key = \"ReOsv=IfT43PVLSiA4vDRjs=40TCqIw97oVP2D9QpmU=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "billion-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_year  = \"2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crude-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_params = {\"serviceKey\" : service_key,\n",
    "                   \"stnIds\" : \"152\",\n",
    "                   \"startDt\" : f\"{base_year}0101\",\n",
    "                   \"startHh\" : \"00\",\n",
    "                   \"endDt\" : f\"{base_year}1230\", \n",
    "                   \"endHh\" : \"23\",\n",
    "                   \"numOfRows\" : \"900\",\n",
    "                   \"dataType\" : \"XML\",\n",
    "                   \"pageNo\" : \"1\",\n",
    "                   \"dataCd\" : \"ASOS\",\n",
    "                   \"dateCd\" : \"HR\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "historical-phone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList?serviceKey=eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D&stnIds=152&startDt=20200101&startHh=00&endDt=20201230&endHh=23&numOfRows=900&dataType=XML&pageNo=1&dataCd=ASOS&dateCd=HR'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_api.request_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superior-hamilton",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcalculate_max_page\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrq_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"body\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"totalCount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'response'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-71092eb3b6c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweather_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeather_Data_by_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweather_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_request_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcreate_request_urls\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mmax_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_max_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcalculate_max_page\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mxmlsoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmlsoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"totalcount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmax_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "weather_api = Weather_Data_by_API(params_dict = weather_params)\n",
    "weather_data = weather_api.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "premium-intervention",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcalculate_max_page\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrq_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"body\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"totalCount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'response'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fc370014cb69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 날씨 정보 수집\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLoad_Weather_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mLoad_Weather_Data\u001b[0;34m(params_dict, save_tf, save_path)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mweather_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeather_Data_by_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mweather_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_request_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcreate_request_urls\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mmax_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_max_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8dd2b6ce6bd>\u001b[0m in \u001b[0;36mcalculate_max_page\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mxmlsoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmlsoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"totalcount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmax_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# 날씨 정보 수집\n",
    "Load_Weather_Data(weather_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-implementation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-senegal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-lewis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-constant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-junction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "monthly-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hispanic-holly",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ds_user1/.ssh/id_rsa.pub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b55dbfef185b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/ds_user1/.ssh/id_rsa.pub\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ds_user1/.ssh/id_rsa.pub'"
     ]
    }
   ],
   "source": [
    "f = open(\"/home/ds_user1/.ssh/id_rsa.pub\", \"r\")\n",
    "text = f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cognitive-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlemaps import exceptions\n",
    "exceptions.ApiError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intimate-tractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "googlemaps.exceptions.ApiError"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exceptions.ApiError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "german-right",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call([\"pip\", \"install\", \"bs4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "capital-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_params_dict = {\"serviceKey\" : 'eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D', \"solYear\" : 2020}\n",
    "\n",
    "import subprocess\n",
    "subprocess.call([\"pip\", \"install\", \"beautifulsoup4\"])\n",
    "subprocess.call([\"pip\", \"install\", \"xmltodict\"])\n",
    "subprocess.call([\"pip\", \"install\", \"ast\"])\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import ast\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Data_by_API(object):\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.features = None\n",
    "        self.main_key = None\n",
    "#         self.serviceKey = serviceKey\n",
    "    \n",
    "    \n",
    "    def calculate_max_page(self, type = \"json\"):\n",
    "        rq = self.request()\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = rq.text, type = type)\n",
    "        \n",
    "        self.n_rows = int(self.params_dict[\"numOfRows\"])\n",
    "        \n",
    "        try:\n",
    "            self.total_count = int(rq_dict[\"response\"][\"body\"][\"totalCount\"])\n",
    "        except:\n",
    "            xmlsoup = BeautifulSoup(rq.text,'html.parser')\n",
    "            self.total_count = int(xmlsoup.find(\"totalcount\").text)\n",
    "                \n",
    "        max_page = int(np.ceil(self.total_count / self.n_rows))\n",
    "        \n",
    "        print(f\"n_rows : {self.n_rows}, total_count : {self.total_count}, max_page = {max_page}\")\n",
    "        \n",
    "        return max_page\n",
    "    \n",
    "    \n",
    "    def create_request_url(self, params_dict):\n",
    "#         params_dict[\"service_key\"] = self.serviceKey\n",
    "        params_list = [f\"{k}={v}\" for k, v in params_dict.items()]\n",
    "        params_str = \"&\".join(params_list)\n",
    "#         print(params_str)\n",
    "        \n",
    "        self.request_url = self.url + params_str\n",
    "        \n",
    "        return self.request_url\n",
    "    \n",
    "    \n",
    "    def create_request_urls(self):\n",
    "        max_page = self.calculate_max_page(type = self.type)\n",
    "        \n",
    "        params_dict = self.params_dict.copy()\n",
    "        \n",
    "        request_urls= []\n",
    "        for i in range(max_page):\n",
    "            params_dict[\"pageNo\"] = i + 1\n",
    "            request_urls.append(self.create_request_url(params_dict = params_dict))\n",
    "            \n",
    "        return request_urls\n",
    "    \n",
    "\n",
    "    \n",
    "    def to_dict(self, txt, type):\n",
    "        # json / xml to dict\n",
    "        if type == \"json\":\n",
    "            rq_dict = ast.literal_eval(txt)\n",
    "        elif type == \"xml\":\n",
    "            rq_dict = xmltodict.parse(txt)\n",
    "            \n",
    "        return rq_dict\n",
    "    \n",
    "    \n",
    "    def extract_values_from_dict(self, dct):\n",
    "        try: \n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"][\"item\"]\n",
    "        except:\n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"]\n",
    "            \n",
    "        return dict_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    def parse(self, request, features = None, type = \"json\"):\n",
    "        \n",
    "        data_dict = defaultdict(list)\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = request.text, type = type)\n",
    "        \n",
    "        # 일부 url의 경우는 item이 아닌 items에 값이 존재\n",
    "        dict_list = self.extract_values_from_dict(dct = rq_dict)\n",
    "        self.dict_list = dict_list\n",
    "        # 값이 1개인 경우 list가 아니라 dictionary 1개가 반환되므로, 이를 list(dict)형태로 변환\n",
    "        if isinstance(dict_list, dict):\n",
    "            dict_list = [dict_list]\n",
    "        \n",
    "        # item이 없는 경우 빈 Dictionary(data dict)를 반환\n",
    "        if dict_list is None:\n",
    "            return data_dict\n",
    "        \n",
    "        if features is None:\n",
    "            features = dict_list[0].keys()\n",
    "            \n",
    "        for x in dict_list:\n",
    "            for col in features:\n",
    "                data_dict[col].append(x.get(col))\n",
    "\n",
    "        return data_dict\n",
    "    \n",
    "    \n",
    "    def request(self, request_url = None):\n",
    "        \n",
    "        if request_url == None:\n",
    "            request_url = self.request_url\n",
    "            \n",
    "        rq = requests.get(request_url, allow_redirects = True)\n",
    "        \n",
    "        return rq\n",
    "\n",
    "class Holiday_Data_by_API(Data_by_API):\n",
    "    \n",
    "    holiday_url = \"http://apis.data.go.kr/B090041/openapi/service/SpcdeInfoService/getHoliDeInfo?\"\n",
    "    restday_url = \"http://apis.data.go.kr/B090041/openapi/service/SpcdeInfoService/getRestDeInfo?\"\n",
    "    \n",
    "    def __init__(self, params_dict, type):\n",
    "        if type == \"holi\":\n",
    "            base_url = self.holiday_url\n",
    "        elif type == \"rest\":\n",
    "            base_url = self.restday_url\n",
    "            \n",
    "        super().__init__(url = base_url)\n",
    "#         self.year = year\n",
    "        self.params_dict = params_dict\n",
    "        self.type = \"xml\"\n",
    "        \n",
    "    \n",
    "    def create_request_urls(self, params_dict):\n",
    "        params_dict = params_dict.copy()\n",
    "        request_urls = []\n",
    "        for x in range(1, 13):\n",
    "            if x < 10:\n",
    "                params_dict[\"solMonth\"] =  f\"0{str(x)}\"\n",
    "\n",
    "            else:\n",
    "                params_dict[\"solMonth\"] =  str(x)\n",
    "                \n",
    "            request_urls.append(self.create_request_url(params_dict = params_dict))\n",
    "    \n",
    "        return request_urls\n",
    "    \n",
    "    \n",
    "    def get(self):\n",
    "        \n",
    "        if \"solMonth\" in self.params_dict.keys():\n",
    "            self.request_urls = [self.create_request_url(params_dict = self.params_dict)]\n",
    "        else:             \n",
    "            self.request_urls = self.create_request_urls(params_dict = self.params_dict)\n",
    "        \n",
    "        data_dict = defaultdict(list)\n",
    "        for request_url in self.request_urls:\n",
    "            \n",
    "            rq = super().request(request_url = request_url)\n",
    "            temp_dict = super().parse(request = rq, features = [\"locdate\", \"dateName\"], type = self.type)\n",
    "            \n",
    "            for k, v in temp_dict.items():\n",
    "                data_dict[k].extend(v)\n",
    "\n",
    "                    \n",
    "        return pd.DataFrame(data_dict)\n",
    "    \n",
    "\n",
    "\n",
    "def Load_Holiday_Data(params_dict,\n",
    "                      save_tf = False, \n",
    "                      save_path = os.getcwd()):\n",
    "    \n",
    "    holiday_api = Holiday_Data_by_API(params_dict = params_dict, type = \"rest\")\n",
    "    holiday_data = holiday_api.get()\n",
    "    \n",
    "    # index 초기화\n",
    "    holiday_data = holiday_data.reset_index(drop=True)\n",
    "  \n",
    "    # 저장여부 변수가 True면 csv파일로 저장, False면 Df로 리턴\n",
    "    if save_tf == True :\n",
    "        holiday_data.to_csv(save_path +'/holiday_data.csv', index=False)\n",
    "    else :\n",
    "        return holiday_data\n",
    "    \n",
    "holiday_data = Load_Holiday_Data(holiday_params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-commander",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-equipment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-sandwich",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-guitar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_Load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "white-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"울산\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southwest-vertical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows : 1000, total_count : 500, max_page = 1\n"
     ]
    }
   ],
   "source": [
    "# 학교(초중고) 정보 수집\n",
    "Load_School_Data(school_params_dict,\n",
    "                 select_region = city, save_tf = True, save_path = \"/home/seho/Passenger_Demand/data/api_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sharp-burner",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_geocodeDf() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9db52c72ec24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 대학교 정보 수집\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m Load_University_Data(university_params_dict,\n\u001b[0m\u001b[1;32m      3\u001b[0m                      \u001b[0mgoogle_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AIzaSyDfLv3OzniRbUc7tTRBJndpiuyepHSmUrE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mselect_region\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0msave_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/Passenger_Demand/model/Data_Load/University_Data_by_API.py\u001b[0m in \u001b[0;36mLoad_University_Data\u001b[0;34m(params_dict, google_key, select_region, save_tf, save_path)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Geocoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0muniversity_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_geocodeDf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniversity_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adres\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoogle_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# index 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_geocodeDf() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# 대학교 정보 수집\n",
    "Load_University_Data(university_params_dict,\n",
    "                     google_key = 'AIzaSyDfLv3OzniRbUc7tTRBJndpiuyepHSmUrE',\n",
    "                     select_region = city,\n",
    "                     save_tf = True,\n",
    "                     save_path = \"/home/seho/Passenger_Demand/data/api_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-stand",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
