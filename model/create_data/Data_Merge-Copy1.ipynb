{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statistical-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spectacular-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Parallelize_DataFrame import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prime-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-timothy",
   "metadata": {},
   "source": [
    "### 마이비 카드 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occasional-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 11.1 s, total: 36.1 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mybicard = pd.read_parquet('/home/seho/Passenger_Demand/data/mybicard.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alert-desktop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36261767, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "overhead-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집일자 데이트 포맷으로 변환\n",
    "#mybicard[\"collectdate\"] = pd.to_datetime(mybicard[\"collectdate\"], format = \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "positive-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전송일자 데이트 포맷으로 변환\n",
    "mybicard[\"transdate\"] = pd.to_datetime(mybicard[\"transdate\"], format = \"%Y%m%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smart-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 승객 수 변수 생성(일반 + 학생 + 아동)\n",
    "mybicard[\"totalcnt\"] = mybicard[[\"normalcnt\", \"studentcnt\", \"childcnt\"]].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "persistent-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_nm에 공백이 포함되어 있어 공백 제거\n",
    "mybicard[\"route_nm\"] = mybicard[\"route_nm\"].replace(\"\\s\", \"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "distributed-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ;mybicard = mybicard.sort_values([\"transdate\", \"seq\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caroline-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard = mybicard.rename(columns = {\"stop_id\" : \"mybi_stop_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-shield",
   "metadata": {},
   "source": [
    "### 401번 버스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "usual-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401 = mybicard.loc[(mybicard[\"route_nm\"] == \"401\") & (mybicard[\"transflag\"].isin([\"환승\", \"비환승\"])), [\"route_nm\", \"transdate\", \"mybi_stop_id\", \"normalcnt\", \"studentcnt\", \"childcnt\", \"totalcnt\"]].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fundamental-giving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1964401, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "apparent-input",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770869, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-dimension",
   "metadata": {},
   "source": [
    "### 정류장 X,Y 좌표 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "former-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경주시, 양산시, 울산광역시, 부산광역시\n",
    "bus_stop_info = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_버스 정류소 위치 정보_20200531.csv\", encoding = \"euc-kr\")\n",
    "bus_stop_info = bus_stop_info.loc[bus_stop_info[\"권역\"] == \"울산광역시\"]\n",
    "bus_stop_info.columns = [\"stop_nm\", \"stop_id\", \"longitude\", \"latitude\", \"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "convertible-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_1 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_율리_꽃바위.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401_2 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_꽃바위_율리.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401 = pd.concat([bus_stop_401_1, bus_stop_401_2])\n",
    "bus_stop_401.columns = [\"mybi_stop_id\", \"stop_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "broadband-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_info = pd.merge(bus_stop_401, bus_stop_info, on = \"stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daily-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401 = pd.merge(mybicard_401, bus_stop_401_info[[\"mybi_stop_id\", \"stop_id\", \"stop_nm\", \"longitude\", \"latitude\"]], on = \"mybi_stop_id\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "combined-specific",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mybicard_401 = mybicard_401.drop([\"mybi_stop_id\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "latest-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401 = mybicard_401.loc[mybicard_401[\"transdate\"].dt.hour.isin([1,2,3,4]) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "israeli-rating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770869, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bright-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg = (mybicard_401.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='60Min')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "better-review",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mybi_stop_id</th>\n",
       "      <th>transdate</th>\n",
       "      <th>normalcnt</th>\n",
       "      <th>studentcnt</th>\n",
       "      <th>childcnt</th>\n",
       "      <th>totalcnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 08:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 10:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 11:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 12:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314857</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-25 08:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314858</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-25 17:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314859</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-25 21:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314860</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-26 18:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314861</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-28 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314862 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mybi_stop_id           transdate  normalcnt  studentcnt  childcnt  \\\n",
       "0            3100020 2020-04-08 06:00:00          2           0         0   \n",
       "1            3100020 2020-04-08 08:00:00          7           0         0   \n",
       "2            3100020 2020-04-08 10:00:00          2           0         0   \n",
       "3            3100020 2020-04-08 11:00:00          2           0         0   \n",
       "4            3100020 2020-04-08 12:00:00          1           0         0   \n",
       "...              ...                 ...        ...         ...       ...   \n",
       "314857       3103633 2020-11-25 08:00:00          6           0         0   \n",
       "314858       3103633 2020-11-25 17:00:00          1           0         0   \n",
       "314859       3103633 2020-11-25 21:00:00          2           2         0   \n",
       "314860       3103633 2020-11-26 18:00:00          1           0         0   \n",
       "314861       3103633 2020-11-28 10:00:00          1           0         0   \n",
       "\n",
       "        totalcnt  \n",
       "0              2  \n",
       "1              7  \n",
       "2              2  \n",
       "3              2  \n",
       "4              1  \n",
       "...          ...  \n",
       "314857         6  \n",
       "314858         1  \n",
       "314859         4  \n",
       "314860         1  \n",
       "314861         1  \n",
       "\n",
       "[314862 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "quality-wound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314862, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "executed-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg.to_parquet(\"/home/seho/Passenger_Demand/data/mybicard_401_agg.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-database",
   "metadata": {},
   "source": [
    "### 결측치 \n",
    "하루의 수집 데이터의 수가 0인 날짜의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "instant-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_data(data, date_col, stop_id_col, target_cols):\n",
    "    \n",
    "    if isinstance(target_cols, list) == False:\n",
    "        target_cols = [target_cols]\n",
    "    \n",
    "    # 1시간 단위로 Target 변수들을 집계\n",
    "    agg_dict = {col:sum for col in target_cols}\n",
    "    data_agg = (data.groupby([stop_id_col, pd.Grouper(key=date_col, freq='60Min')])\n",
    "                    .agg(agg_dict)\n",
    "                    .reset_index())\n",
    "    \n",
    "    return data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "saving-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = create_base_data(mybicard_401, date_col = \"transdate\", stop_id_col = \"stop_id\", target_cols = [\"totalcnt\", \"normalcnt\", \"studentcnt\", \"childcnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "christian-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(data, date_col):\n",
    "    \n",
    "    # 시간 변수들 생성\n",
    "    # 요일\n",
    "    data[\"dayofweek\"] = data[date_col].dt.dayofweek\n",
    "    dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "    data[\"dayofweek\"] = data[\"dayofweek\"].replace(dow_dict)\n",
    "    \n",
    "    # 시간\n",
    "    data[\"hour\"] = data[date_col].dt.hour\n",
    "    \n",
    "    # 월\n",
    "    data[\"month\"] = data[date_col].dt.month\n",
    "    \n",
    "    # 주\n",
    "    data[\"weekofyear\"] = data[date_col].dt.isocalendar().week\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "lonely-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_date(data, date_col, stop_id_col, except_hours = None):\n",
    "    \n",
    "    if isinstance(except_hours, list) == False:\n",
    "        except_hours = [except_hours]\n",
    "        \n",
    "    # 정류장별 모든 시간대의 조합을 생성해 버스 집계 데이터를 Join\n",
    "    # 데이터가 존재하지 않는 시간대 : NA -> 이후 Impute\n",
    "    \n",
    "    # 데이터의 시작과 끝 사이를 1시간 간격으로 구분하여 list 생성\n",
    "    dt_list = pd.date_range(start = data[date_col].min(), end = data[date_col].max(), freq = \"1h\")\n",
    "    date_df = pd.DataFrame({date_col : dt_list}).reset_index(drop = True)\n",
    "    stop_id_df = pd.DataFrame({stop_id_col : data[stop_id_col].drop_duplicates()}).reset_index(drop = True)\n",
    "\n",
    "    # 전체 일정(시간 단위)과 정류소 별 조합 DF 생성\n",
    "    all_date = pd.merge(date_df, stop_id_df, how = \"cross\")\n",
    "    \n",
    "    # 결측일의 데이터를 채워넣은 전체 데이터를 left join\n",
    "    all_date = pd.merge(all_date, data, on = [date_col, stop_id_col], how = \"left\")\n",
    "    \n",
    "    all_date = all_date.loc[all_date[date_col].dt.hour.isin(except_hours) == False]\n",
    "    \n",
    "    return all_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "outdoor-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_date = create_all_date(data = base_data, date_col = \"transdate\", stop_id_col = \"stop_id\", except_hours=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "civilian-truth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(563300, 6)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_date.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "baking-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_date = add_time_features(data = all_date, date_col = \"transdate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cubic-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_bus_demand_data(data, date_col, stop_id_col):\n",
    "    # 일 단위 집계 -> 데이터가 존재하지 않는 일은 결측일로 판단 (missing_date)\n",
    "    count_by_date = data.groupby([pd.Grouper(key=date_col, freq=\"1D\")]).size().reset_index(name = \"cnt\")\n",
    "    missing_date = count_by_date.loc[count_by_date[\"cnt\"] == 0, date_col]\n",
    "    \n",
    "    # 1) 결측일을 제외한 결측치(데이터가 존재하지 않는 시간대)는 승객이 0명 이므로 0으로 대체\n",
    "    data = data.loc[data[date_col].dt.date.isin(missing_date.dt.date) == False].fillna(0)\n",
    "    \n",
    "    # 2) 최근 n주의 같은 요일 같은 시간대의 평균값으로 Impute\n",
    "    data = impute_recent_mean_data(data = data, missing_date = missing_date, date_col = \"transdate\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_bus_demand_data(data = all_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "inner-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_date = mybicard_401_agg.groupby([pd.Grouper(key=\"transdate\", freq=\"1D\")]).size().reset_index(name = \"cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "mighty-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_date = count_by_date.loc[count_by_date[\"cnt\"] == 0, \"transdate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-conditioning",
   "metadata": {},
   "source": [
    "#### 결측일을 제외한 결측치(특정 시간에 데이터가 없는 경우)는 승객이 0이므로 0으로 대체한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "limiting-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 시작과 끝 사이를 1시간 간격으로 구분하여 list 생성\n",
    "dt_list = pd.date_range(start = mybicard_401_agg[\"transdate\"].min(), end = mybicard_401_agg[\"transdate\"].max(), freq = \"1h\")\n",
    "\n",
    "transdate_df = pd.DataFrame({\"transdate\" : dt_list}).reset_index(drop = True)\n",
    "mybi_stop_id_df = pd.DataFrame({\"mybi_stop_id\" : mybicard_401_agg[\"mybi_stop_id\"].drop_duplicates()}).reset_index(drop = True)\n",
    "\n",
    "# 전체 일정(시간 단위)과 정류소 별 조합 DF 생성\n",
    "all_date = pd.merge(transdate_df, mybi_stop_id_df, how = \"cross\")\n",
    "\n",
    "# 결측일의 데이터를 채워넣은 전체 데이터를 left join\n",
    "ml_data = pd.merge(all_date, mybicard_401_agg, on = [\"mybi_stop_id\", \"transdate\"], how = \"left\")\n",
    "\n",
    "ml_data[\"dayofweek\"] = ml_data[\"transdate\"].dt.dayofweek\n",
    "dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "ml_data[\"dayofweek\"] = ml_data[\"dayofweek\"].replace(dow_dict)\n",
    "ml_data[\"hour\"] = ml_data[\"transdate\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "medical-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측일이 아닌 결측값은 승객수가 없다고 판단하여 0으로 대체\n",
    "ml_data = ml_data.loc[ml_data[\"transdate\"].dt.date.isin(missing_date.dt.date) == False].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "substantial-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차량을 운행하지 않는 1, 2, 3, 4 시간대 제외\n",
    "ml_data = ml_data.loc[ml_data[\"hour\"].isin([1,2,3,4]) == False ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-commission",
   "metadata": {},
   "source": [
    "#### n주 전 같은 요일 같은 시간대의 인원 수로 Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sporting-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_recent_data(data, missing_date, date_col = \"transdate\"):\n",
    "    data = data.copy()\n",
    "    for x in missing_date:\n",
    "        temp = []\n",
    "        w = 0\n",
    "        while len(temp) == 0:\n",
    "            w +=1\n",
    "            temp = data.loc[data[date_col].dt.date == (x - timedelta(weeks = w)).date()].copy()\n",
    "\n",
    "        temp[date_col] = temp[date_col] + timedelta(weeks = w)\n",
    "        data = pd.concat([data, temp], 0)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-carpet",
   "metadata": {},
   "source": [
    "#### 최근 n주의 같은 요일 같은 시간대의 평균값으로 Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "hazardous-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_recent_mean_data(data, missing_date, date_col):\n",
    "\n",
    "    data = data.copy()\n",
    "\n",
    "    # 요일, 시간 추가\n",
    "    data[\"dayofweek\"] = data[\"transdate\"].dt.dayofweek\n",
    "    dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "    data[\"dayofweek\"] = data[\"dayofweek\"].replace(dow_dict)\n",
    "    data[\"hour\"] = data[\"transdate\"].dt.hour\n",
    "         \n",
    "    \n",
    "    for x in missing_date:\n",
    "        base_date = x\n",
    "        w = 0\n",
    "        # 결측일의 이전 4주를 기본으로 검색하며, 데이터가 없는 경우 범위를 1주씩 늘려가며 데이터 조회\n",
    "        temp = []\n",
    "        while len(temp) == 0:\n",
    "            temp = data.loc[(data[\"transdate\"].dt.date.between((x - timedelta(weeks = 4+w)).date(), x.date())) & (data[\"transdate\"].dt.dayofweek == x.day_of_week)].copy()\n",
    "            w += 1\n",
    "\n",
    "        # 4+w 전까지의 데이터를 찾아서 정류장별, 요일별, 시간별 평균값 산출\n",
    "        temp2 = temp.groupby([\"mybi_stop_id\", \"dayofweek\", \"hour\"]).agg({\"totalcnt\" : np.mean,\n",
    "                                                                         \"normalcnt\" : np.mean,\n",
    "                                                                         \"studentcnt\" : np.mean,\n",
    "                                                                         \"childcnt\" : np.mean}).reset_index()\n",
    "        # 평균값 변환 (Float -> Int : 반올림 효과)\n",
    "        temp2[\"totalcnt\"] = temp2[\"totalcnt\"].astype(int)\n",
    "        temp2[\"normalcnt\"] = temp2[\"normalcnt\"].astype(int)\n",
    "        temp2[\"studentcnt\"] = temp2[\"studentcnt\"].astype(int)\n",
    "        temp2[\"childcnt\"] = temp2[\"childcnt\"].astype(int)\n",
    "\n",
    "        # 기준 일자, 시간으로 부터 transdate을 재생성\n",
    "        temp2[\"transdate\"] = temp2.apply(lambda x: base_date + timedelta(hours = x[\"hour\"]), 1)\n",
    "\n",
    "        data = pd.concat([data, temp2], 0)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "governing-royal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.51 s, sys: 0 ns, total: 7.51 s\n",
      "Wall time: 7.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = impute_recent_mean_data(data = ml_data, missing_date = missing_date, date_col = \"transdate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "exposed-airport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-decimal",
   "metadata": {},
   "source": [
    "### 시계열 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "small-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_feature(data, target_cols, date_cols, lags, groupby_cols = None):\n",
    "    data = data.copy()\n",
    "    if isinstance(lags, list) == False:\n",
    "        lags = [lags]\n",
    "    if isinstance(date_cols, list) == False:\n",
    "        date_cols = [date_cols]\n",
    "    if isinstance(target_cols, list) == False:\n",
    "        target_cols = [target_cols]\n",
    "    if isinstance(groupby_cols, list) == False:\n",
    "        groupby_cols = [groupby_cols]\n",
    "    \n",
    "    for lg in lags:\n",
    "        if groupby_cols is None:\n",
    "            cnt_bf = data.set_index(date_cols)[target_cols].shift(freq = lg).reset_index()\n",
    "        else:\n",
    "            cnt_bf = data.set_index(date_cols).groupby(groupby_cols)[target_cols].shift(freq = lg).reset_index()\n",
    "        \n",
    "        rename_dict = {col: f\"{col}_bf{lg}\" for col in target_cols}\n",
    "        cnt_bf = cnt_bf.rename(columns = rename_dict)\n",
    "        \n",
    "        data = pd.merge(data, cnt_bf, on = date_cols + groupby_cols, how = \"left\")\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecological-accordance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 0 ns, total: 1.35 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = create_lag_feature(data = ml_data, target_cols = \"totalcnt\", date_cols = \"transdate\", lags = [\"1d\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\"], groupby_cols = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "connected-compact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 15)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-number",
   "metadata": {},
   "source": [
    "### 날짜별 평균 Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "physical-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_daily = (ml_data.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\", np.mean), \n",
    "                                        studentcnt = (\"studentcnt\", np.mean), \n",
    "                                        childcnt = (\"childcnt\", np.mean),\n",
    "                                        totalcnt = (\"totalcnt\", np.mean))\n",
    "                                   .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ready-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lag = create_lag_feature(data = mybicard_401_agg_daily, target_cols = \"totalcnt\", date_cols = \"transdate\", lags = [\"1d\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\"], groupby_cols = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "affected-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [\"1d\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\"]\n",
    "rename_dict = {f\"{col}_bf{lg}\": f\"{col}_bf{lg}_total\" for col in [\"totalcnt\"] for lg in lags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "casual-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lag = daily_lag.rename(columns = rename_dict)\n",
    "daily_lag[\"date\"] = daily_lag[\"transdate\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "collect-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"date\"] = ml_data[\"transdate\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "stainless-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_lag[[\"date\", \"mybi_stop_id\"] + list(rename_dict.values())], on = [\"date\", \"mybi_stop_id\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "radio-recording",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 23)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-engine",
   "metadata": {},
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-valentine",
   "metadata": {},
   "source": [
    "#### 1) 이전 n개일자들의 동일 시간대 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "completed-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_agg(data, target_cols, date_col, groupby_cols, col_nm = \"\", rollings = [\"2d\"], agg_func = [np.mean, np.std]):\n",
    "    if isinstance(target_cols, list) == False:\n",
    "        target_cols = [target_cols]\n",
    "        \n",
    "    if isinstance(groupby_cols, list) == False:\n",
    "        groupby_cols = [groupby_cols]\n",
    "        \n",
    "    if col_nm != \"\":\n",
    "        col_nm = f\"{col_nm}_\"\n",
    "    \n",
    "    \n",
    "    for rl in rollings:\n",
    "        for tg in target_cols:\n",
    "            data = data.set_index(date_col).sort_index(ascending=True).copy()\n",
    "            rolling_data = data.groupby(groupby_cols)[tg].rolling(rl).agg(agg_func)\n",
    "            rolling_data = rolling_data.rename(columns = {\"mean\" : f\"{tg}_ma_{col_nm}mean_{rl}\", \n",
    "                                                          \"std\" : f\"{tg}_ma_{col_nm}std_{rl}\"})\n",
    "            rolling_data = rolling_data.groupby(groupby_cols).shift(1).reset_index()    \n",
    "            \n",
    "            data = pd.merge(data.reset_index(), rolling_data, on = [date_col] + groupby_cols, how = \"left\")\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "allied-conditions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 0 ns, total: 2.89 s\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = calculate_moving_agg(data = ml_data, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\", \"hour\"], col_nm = \"hour\", rollings = [\"2d\", \"3d\", \"4d\", \"5d\", \"6d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "imposed-montana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 33)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-ranch",
   "metadata": {},
   "source": [
    "#### 2) n주전까지의 동일 요일의 동일 시간대 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "serial-causing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.6 s, sys: 0 ns, total: 3.6 s\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = calculate_moving_agg(data = ml_data, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\", \"hour\", \"dayofweek\"], col_nm = \"hour_week\", rollings = [\"14d\", \"21d\", \"28d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "soviet-peoples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 39)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-couple",
   "metadata": {},
   "source": [
    "#### 3) 이전 n개일자들의 전체 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "colored-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_1d = (ml_data.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())\n",
    "\n",
    "mybicard_401_agg_1d[\"dayofweek\"] = mybicard_401_agg_1d[\"transdate\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "polish-degree",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 ms, sys: 0 ns, total: 118 ms\n",
      "Wall time: 122 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "daily_agg = calculate_moving_agg(data = mybicard_401_agg_1d, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\"], col_nm = \"daily\", rollings = [\"2d\", \"3d\", \"4d\", \"5d\", \"6d\"])\n",
    "daily_agg[\"date\"] = daily_agg[\"transdate\"].dt.date\n",
    "daily_agg = daily_agg.drop([\"transdate\", \"normalcnt\", \"studentcnt\", \"childcnt\", \"totalcnt\", \"dayofweek\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "certified-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_agg, on = [\"mybi_stop_id\", \"date\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "loaded-appraisal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 49)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-radiation",
   "metadata": {},
   "source": [
    "#### 4) n주전까지의 동일 요일의 전체 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "democratic-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 143 ms, sys: 0 ns, total: 143 ms\n",
      "Wall time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "daily_week_agg = calculate_moving_agg(data = mybicard_401_agg_1d, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\", \"dayofweek\"], col_nm = \"daily_week\", rollings = [\"14d\", \"21d\", \"28d\"])\n",
    "daily_week_agg[\"date\"] = daily_week_agg[\"transdate\"].dt.date\n",
    "daily_week_agg = daily_week_agg.drop([\"transdate\", \"normalcnt\", \"studentcnt\", \"childcnt\", \"totalcnt\", \"dayofweek\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "complete-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_week_agg, on = [\"mybi_stop_id\", \"date\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "interracial-kingston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 55)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-credit",
   "metadata": {},
   "source": [
    "#### 5) n주전까지의 주 평균의 이동평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "genuine-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_1d = (ml_data.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())\n",
    "mybicard_401_agg_1d[\"hour\"] = mybicard_401_agg_1d[\"transdate\"].dt.hour\n",
    "mybicard_401_agg_1d[\"weekofyear\"] = mybicard_401_agg_1d[\"transdate\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "appointed-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_1w = mybicard_401_agg_1d.groupby([\"mybi_stop_id\", \"weekofyear\"])[\"totalcnt\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "reverse-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_agg = calculate_moving_agg(data = mybicard_401_agg_1w, target_cols = [\"totalcnt\"], date_col = \"weekofyear\", groupby_cols = [\"mybi_stop_id\"], col_nm = \"weekly\", rollings = [2,3,4])\n",
    "weekly_agg = weekly_agg.drop(\"totalcnt\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "white-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"weekofyear\"] = ml_data[\"transdate\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "subsequent-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, weekly_agg, on = [\"mybi_stop_id\", \"weekofyear\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "living-ratio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 62)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 62)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-reggae",
   "metadata": {},
   "source": [
    "### 특일 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "canadian-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/holiday_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "treated-tobago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holiday_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "finite-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data[\"date\"] = pd.to_datetime(holiday_data[\"locdate\"], format = \"%Y%m%d\").dt.date\n",
    "holiday_data = holiday_data.drop([\"locdate\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "level-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.DataFrame({\"date\" : pd.date_range(\"2020-01-01\", \"2020-12-31\", freq = \"1D\")})\n",
    "date_df[\"weekend\"] = np.where(date_df[\"date\"].dt.dayofweek.isin([5,6]), \"Y\", \"N\")\n",
    "date_df[\"date\"] = date_df[\"date\"].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-persian",
   "metadata": {},
   "source": [
    "#### 공휴일 / 명절 여부 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "visible-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공휴일(holiday), 명절(ntl_holiday) 구분\n",
    "ntl_holiday = holiday_data.loc[holiday_data[\"dateName\"].isin([\"설날\", \"추석\"])]\n",
    "ntl_holiday = ntl_holiday.rename(columns = {\"dateName\" : \"ntl_holi\"})\n",
    "\n",
    "holiday = holiday_data.loc[holiday_data[\"dateName\"].isin([\"설날\", \"추석\"]) == False]\n",
    "holiday = holiday.rename(columns = {\"dateName\" : \"holi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "suspected-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.merge(date_df, ntl_holiday, on = \"date\", how = \"left\")\n",
    "date_df = pd.merge(date_df, holiday, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "artistic-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df.assign(ntl_holi = np.where(date_df[\"ntl_holi\"].isna(), \"N\", \"Y\"),\n",
    "                         holi = np.where(date_df[\"holi\"].isna(), \"N\", \"Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-university",
   "metadata": {},
   "source": [
    "#### 3일 이상 연휴 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "running-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df[\"rest_yn\"] = date_df[[\"weekend\", \"ntl_holi\", \"holi\"]].apply(lambda x: any(x == \"Y\"), 1)\n",
    "date_df[\"rest_yn\"] = np.where(date_df[\"rest_yn\"],\"Y\", \"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "operating-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seq_y(data, criterion = 2):\n",
    "    seq_list = []\n",
    "    Y_cnt = 0\n",
    "    for i, x in enumerate(data):\n",
    "        if x == \"Y\":\n",
    "            Y_cnt += 1\n",
    "\n",
    "        if (x == \"N\") | (i == len(data)):\n",
    "            if Y_cnt > criterion:\n",
    "                temp_list = [\"Y\"] * Y_cnt\n",
    "                seq_list += temp_list\n",
    "            elif (Y_cnt > 0) & (Y_cnt <= criterion):\n",
    "                temp_list = [\"N\"] * Y_cnt\n",
    "                seq_list += temp_list\n",
    "            seq_list.append(\"N\")\n",
    "            Y_cnt = 0\n",
    "            \n",
    "    return seq_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "enormous-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df[\"seq_holi\"] = find_seq_y(data = date_df[\"rest_yn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "adjustable-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df.drop([\"weekend\", \"rest_yn\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "collected-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, date_df, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "small-tamil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 65)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-change",
   "metadata": {},
   "source": [
    "### 날씨 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "satellite-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/weather_2018.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "mediterranean-vertex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8064, 38)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "undefined-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = weather_data.loc[:, [\"tm\", \"ta\", \"hm\", \"rn\", \"dc10Tca\",  \"dsnw\", \"wd\", \"ws\"]]\n",
    "weather_data = weather_data.rename(columns = {\"tm\" : \"time\",\n",
    "                                              \"ta\" : \"temperature\",\n",
    "                                              \"hm\" : \"humidity\",\n",
    "                                              \"rn\" : \"precipitation\",\n",
    "                                              \"dc10Tca\" : \"전운량\",\n",
    "                                              \"dsnw\" : \"snowfall\",\n",
    "                                              \"wd\" : \"풍향\",\n",
    "                                              \"ws\" : \"풍속\"})\n",
    "weather_data[\"time\"] = pd.to_datetime(weather_data[\"time\"], format = \"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "alert-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weather_data.columns:\n",
    "    if col == \"time\":\n",
    "        continue\n",
    "    weather_data[col] = weather_data[col].replace(\"\", \"0.0\").astype(float)\n",
    "    weather_data[col] = weather_data[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ceramic-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data[\"time_hours\"] = weather_data[\"time\"].dt.strftime(\"%Y-%m-%d %H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fabulous-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"transdate_hours\"] = ml_data[\"transdate\"].dt.strftime(\"%Y-%m-%d %H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "spectacular-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, weather_data[[\"time_hours\", \"temperature\", \"humidity\", \"precipitation\", \"snowfall\"]], left_on = \"transdate_hours\", right_on = \"time_hours\")\n",
    "ml_data = ml_data.drop([\"transdate_hours\", \"time_hours\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "sapphire-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 69)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 69)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-diesel",
   "metadata": {},
   "source": [
    "### 미세먼지 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abandoned-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_data = pd.read_csv(\"/home/seho/Passenger_Demand/data/pm_data.csv\")\n",
    "pm_data[\"issueDate\"] = pd.to_datetime(pm_data[\"issueDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "temporal-article",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clearVal</th>\n",
       "      <th>sn</th>\n",
       "      <th>districtName</th>\n",
       "      <th>dataDate</th>\n",
       "      <th>issueVal</th>\n",
       "      <th>issueTime</th>\n",
       "      <th>clearDate</th>\n",
       "      <th>issueDate</th>\n",
       "      <th>moveName</th>\n",
       "      <th>clearTime</th>\n",
       "      <th>issueGbn</th>\n",
       "      <th>itemCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>322</td>\n",
       "      <td>세종</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>80</td>\n",
       "      <td>12:00</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>세종권역</td>\n",
       "      <td>19:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>323</td>\n",
       "      <td>충북</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>77</td>\n",
       "      <td>13:00</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>중부권역</td>\n",
       "      <td>19:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>320</td>\n",
       "      <td>대구</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>83</td>\n",
       "      <td>14:00</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>대구권역</td>\n",
       "      <td>16:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>321</td>\n",
       "      <td>충남</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>76</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>북부권역</td>\n",
       "      <td>22:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>316</td>\n",
       "      <td>경남</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>84</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>함안권역</td>\n",
       "      <td>15:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>충남</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>85</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>북부권역</td>\n",
       "      <td>15:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>전북</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>77</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>장수권역</td>\n",
       "      <td>14:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>전북</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>80</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>익산권역</td>\n",
       "      <td>15:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>302</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>경기</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>82</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>남부권</td>\n",
       "      <td>17:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>303</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>전북</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>81</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>전주권역</td>\n",
       "      <td>14:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  clearVal   sn districtName    dataDate  issueVal issueTime  \\\n",
       "0             0        33  322           세종  2020-12-29        80     12:00   \n",
       "1             1        33  323           충북  2020-12-29        77     13:00   \n",
       "2             2        34  320           대구  2020-12-28        83     14:00   \n",
       "3             3        28  321           충남  2020-12-28        76     21:00   \n",
       "4             4        30  316           경남  2020-12-24        84     11:00   \n",
       "..          ...       ...  ...          ...         ...       ...       ...   \n",
       "299         299        31    3           충남  2020-01-03        85     11:00   \n",
       "300         300        29    6           전북  2020-01-03        77     00:00   \n",
       "301         301        19    1           전북  2020-01-03        80     02:00   \n",
       "302         302        33    2           경기  2020-01-03        82     11:00   \n",
       "303         303        34    5           전북  2020-01-03        81     22:00   \n",
       "\n",
       "      clearDate  issueDate moveName clearTime issueGbn itemCode  \n",
       "0    2020-12-29 2020-12-29     세종권역     19:00      주의보     PM25  \n",
       "1    2020-12-29 2020-12-29     중부권역     19:00      주의보     PM25  \n",
       "2    2020-12-28 2020-12-28     대구권역     16:00      주의보     PM25  \n",
       "3    2020-12-29 2020-12-28     북부권역     22:00      주의보     PM25  \n",
       "4    2020-12-24 2020-12-24     함안권역     15:00      주의보     PM25  \n",
       "..          ...        ...      ...       ...      ...      ...  \n",
       "299  2020-01-05 2020-01-03     북부권역     15:00      주의보     PM25  \n",
       "300  2020-01-04 2020-01-04     장수권역     14:00      주의보     PM25  \n",
       "301  2020-01-05 2020-01-03     익산권역     15:00      주의보     PM25  \n",
       "302  2020-01-04 2020-01-03      남부권     17:00      주의보     PM25  \n",
       "303  2020-01-05 2020-01-03     전주권역     14:00      주의보     PM25  \n",
       "\n",
       "[304 rows x 13 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "comfortable-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_data_agg = pm_data.loc[pm_data[\"districtName\"] == \"울산\"].groupby(pd.Grouper(key=\"issueDate\", freq=\"1D\")).size().reset_index(name = \"pm_alert_cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "regulation-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"date\"] = ml_data[\"transdate\"].dt.strftime(\"%Y-%m-%d\")\n",
    "pm_data_agg[\"issueDate\"] = pm_data_agg[\"issueDate\"].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "antique-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, pm_data_agg, how = \"left\", left_on = \"date\", right_on = \"issueDate\")\n",
    "ml_data = ml_data.drop([\"issueDate\"], 1)\n",
    "ml_data[\"pm_alert_cnt\"] = ml_data[\"pm_alert_cnt\"].fillna(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "numerical-disabled",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 70)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-rachel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-omega",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-banks",
   "metadata": {},
   "source": [
    "### 정류장 X,Y 좌표 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "overall-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경주시, 양산시, 울산광역시, 부산광역시\n",
    "bus_stop_info = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_버스 정류소 위치 정보_20200531.csv\", encoding = \"euc-kr\")\n",
    "bus_stop_info = bus_stop_info.loc[bus_stop_info[\"권역\"] == \"울산광역시\"]\n",
    "bus_stop_info.columns = [\"stop_nm\", \"stop_id\", \"longitude\", \"latitude\", \"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "regulated-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_1 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_율리_꽃바위.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401_2 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_꽃바위_율리.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401 = pd.concat([bus_stop_401_1, bus_stop_401_2])\n",
    "bus_stop_401.columns = [\"mybi_stop_id\", \"stop_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dimensional-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_info = pd.merge(bus_stop_401, bus_stop_info, on = \"stop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-wholesale",
   "metadata": {},
   "source": [
    "### 상권정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "distinguished-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_area = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_상권정보_201231.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "tracked-glossary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52188, 39)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_area.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "valid-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = trading_area[\"상권업종중분류명\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "hydraulic-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(latlon1, latlon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1 = map(radians, latlon1)\n",
    "    lat2, lon2 = map(radians, latlon2)\n",
    "#     lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def count_store_nearby(data, trading_area = trading_area, dist = 0.1, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = trading_area[\"상권업종중분류명\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = trading_area[[\"위도\", \"경도\"]].apply(lambda x: haversine((x[\"위도\"], x[\"경도\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = trading_area.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"store_category_{i}\"] = (within_data[\"상권업종중분류명\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "atomic-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.12it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.10it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.13it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 s, sys: 0 ns, total: 19.4 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                           func = count_store_nearby, \n",
    "                                           num_cores = 12, \n",
    "                                           trading_area = trading_area, \n",
    "                                           dist = 0.2, \n",
    "                                           category_list = category_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-shuttle",
   "metadata": {},
   "source": [
    "### 병원정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "beautiful-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/hospital_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "animal-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_data.to_csv(\"hospital_data.csv\", encoding = \"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "accredited-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_data[\"category\"] = hospital_data[\"의료기관종별\"].replace({\"한방병원\" : \"병원\",\n",
    "                                                                  \"치과병원\" : \"병원\",\n",
    "                                                                  \"일반요양병원\" : \"요양병원\",\n",
    "                                                                  \"부속의원\" : \"의원\",\n",
    "                                                                  \"치과의원\" : \"의원\",\n",
    "                                                                  \"한의원\" : \"의원\",\n",
    "                                                                  \"보건지소\" : \"보건소\",\n",
    "                                                                  \"보건진료소\" : \"보건소\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "demographic-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_category_list = hospital_data[\"category\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "chemical-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hospital_nearby(data, hospital_data = hospital_data, dist = 0.2, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = hospital_data[\"category\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = hospital_data[[\"lat\", \"lng\"]].apply(lambda x: haversine((x[\"lat\"], x[\"lng\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = hospital_data.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"hospital_category_{i}\"] = (within_data[\"category\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "legendary-cross",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 23.78it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24.00it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.93it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.80it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.79it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.66it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.19it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.41it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.66it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.36it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24.53it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.07 s, sys: 0 ns, total: 1.07 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                           func = count_hospital_nearby, \n",
    "                                           num_cores = 12, \n",
    "                                           hospital_data = hospital_data, \n",
    "                                           dist = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-doubt",
   "metadata": {},
   "source": [
    "### 학교정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "multiple-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = pd.read_excel(\"/home/seho/Passenger_Demand/data/gv_school.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dimensional-mambo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12883, 35)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "revolutionary-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"표준일차명\"] = school_data[\"표준일차명\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "shared-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = school_data.loc[school_data[\"표준일차명\"].str.contains(\"울산\", na=\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "under-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "subject-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "diagnostic-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geocode(x, gmaps):\n",
    "    try:\n",
    "        result = gmaps.geocode(x)[0][\"geometry\"][\"location\"]\n",
    "        # result = [temp[\"lat\"], temp[\"lng\"]]\n",
    "    except:\n",
    "        result = None\n",
    "    \n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "integrated-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"category\"] = school_data[\"학교종류\"].replace({\"전문대학(3년제)\" : \"전문대학\",\n",
    "                                                          \"사내대학(전문)\" : \"전문대학\",\n",
    "                                                          \"기능대학\" : \"전문대학\",\n",
    "                                                          \"일반대학원\" : \"대학원\",\n",
    "                                                          \"전문대학원\" : \"대학원\",\n",
    "                                                          \"특수대학원\" : \"대학원\",\n",
    "                                                          \"일반고등학교\" : \"고등학교\",\n",
    "                                                          \"공업고등학교\" : \"고등학교\",\n",
    "                                                          \"상업고등학교\" : \"고등학교\",\n",
    "                                                          \"가사고등학교\" : \"고등학교\",\n",
    "                                                          \"체육고등학교\" : \"고등학교\",\n",
    "                                                          \"외국어고등학교\" : \"고등학교\",\n",
    "                                                          \"과학고등학교\" : \"고등학교\",\n",
    "                                                          \"예술고등학교\" : \"고등학교\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "temporal-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 481 ms, sys: 0 ns, total: 481 ms\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "school_data[\"lat_lng\"] = school_data[\"새주소\"].apply(get_geocode, gmaps = gmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "compound-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"lat\"] = school_data[\"lat_lng\"].apply(lambda x: x[\"lat\"])\n",
    "school_data[\"lng\"] = school_data[\"lat_lng\"].apply(lambda x: x[\"lng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "outer-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_school_nearby(data, school_data = school_data, dist = 0.2, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = school_data[\"category\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = school_data[[\"lat\", \"lng\"]].apply(lambda x: haversine((x[\"lat\"], x[\"lng\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = school_data.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"school_category_{i}\"] = (within_data[\"category\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "higher-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 102.96it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 77.12it/s] \n",
      "100%|██████████| 11/11 [00:00<00:00, 76.67it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 81.10it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 79.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 74.05it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 75.82it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 73.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 74.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 86.17it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 81.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 747 ms, sys: 0 ns, total: 747 ms\n",
      "Wall time: 807 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                              func = count_school_nearby, \n",
    "                                              num_cores = 12, \n",
    "                                              school_data = school_data, \n",
    "                                              dist = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-escape",
   "metadata": {},
   "source": [
    "### 정류장 정보 Join(거리기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "sexual-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, bus_stop_401_info.drop([\"stop_id\", \"city\"],1), on = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "asian-convert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 175)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 175)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-travel",
   "metadata": {},
   "source": [
    "### 울산행사정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "acoustic-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = pd.read_csv(\"~/Passenger_Demand/data/ulsan_event_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "manual-whole",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 19)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "sized-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data[\"eventStartDate\"] = pd.to_datetime(event_data[\"eventStartDate\"], format = \"%Y-%m-%d\")\n",
    "event_data[\"eventEndDate\"] = pd.to_datetime(event_data[\"eventEndDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "present-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_event_nearby(data, event_data, dist = 0.2):\n",
    "    data_copy = data.copy()\n",
    "    within_data = event_data.loc[(event_data[\"eventStartDate\"] <= data_copy[\"transdate\"]) & (event_data[\"eventEndDate\"] >= data_copy[\"transdate\"])]\n",
    "    \n",
    "    if len(within_data) == 0:\n",
    "        data_copy[f\"event_nearby\"] = 0\n",
    "    else:\n",
    "        dist_list = within_data[[\"latitude\", \"longitude\"]].apply(lambda x: haversine((x[\"latitude\"], x[\"longitude\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "        data_copy[f\"event_nearby\"] = (dist_list <= dist).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "enabling-major",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51745/51745 [03:32<00:00, 243.24it/s]\n",
      "100%|██████████| 51745/51745 [03:33<00:00, 242.30it/s]\n",
      "100%|██████████| 51745/51745 [03:38<00:00, 236.29it/s]\n",
      "100%|██████████| 51745/51745 [03:41<00:00, 234.05it/s]\n",
      "100%|██████████| 51745/51745 [03:42<00:00, 233.08it/s]\n",
      "100%|██████████| 51745/51745 [03:39<00:00, 235.81it/s]\n",
      "100%|██████████| 51745/51745 [03:41<00:00, 233.70it/s]\n",
      "100%|██████████| 51745/51745 [03:41<00:00, 233.23it/s]\n",
      "100%|██████████| 51745/51745 [03:39<00:00, 235.56it/s]\n",
      "100%|██████████| 51745/51745 [03:42<00:00, 232.61it/s]\n",
      "100%|██████████| 51745/51745 [03:41<00:00, 233.26it/s]\n",
      "100%|██████████| 51745/51745 [03:42<00:00, 232.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.8 s, sys: 0 ns, total: 32.8 s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = parallelize_dataframe(df = ml_data, \n",
    "                                func = count_event_nearby, \n",
    "                                num_cores = 12, \n",
    "                                event_data = event_data, \n",
    "                                dist = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "rising-short",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 176)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 176)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-nylon",
   "metadata": {},
   "source": [
    "### 축제 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "sensitive-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data = pd.read_csv(\"~/Passenger_Demand/data/festival_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "pharmaceutical-arrangement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 18)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "festival_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "thirty-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data[\"fstvlStartDate\"] = pd.to_datetime(festival_data[\"fstvlStartDate\"], format = \"%Y-%m-%d\")\n",
    "festival_data[\"fstvlEndDate\"] = pd.to_datetime(festival_data[\"fstvlEndDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "improved-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_festival_nearby(data, festival_data, dist = 0.2):\n",
    "    data_copy = data.copy()\n",
    "    within_data = festival_data.loc[(festival_data[\"fstvlStartDate\"] <= data_copy[\"transdate\"]) & (festival_data[\"fstvlEndDate\"] >= data_copy[\"transdate\"])]\n",
    "    \n",
    "    if len(within_data) == 0:\n",
    "        data_copy[f\"festival_nearby\"] = 0\n",
    "    else:\n",
    "        dist_list = within_data[[\"latitude\", \"longitude\"]].apply(lambda x: haversine((x[\"latitude\"], x[\"longitude\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "        data_copy[f\"festival_nearby\"] = (dist_list <= dist).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "superb-ordinance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51745/51745 [01:31<00:00, 563.83it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 560.97it/s]\n",
      "100%|██████████| 51745/51745 [01:31<00:00, 563.95it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 560.48it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 561.49it/s]\n",
      "100%|██████████| 51745/51745 [01:31<00:00, 563.31it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 561.81it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 561.99it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 561.17it/s]\n",
      "100%|██████████| 51745/51745 [02:26<00:00, 352.92it/s]\n",
      "100%|██████████| 51745/51745 [02:27<00:00, 349.96it/s]\n",
      "100%|██████████| 51745/51745 [02:26<00:00, 353.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 0 ns, total: 1min 17s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = parallelize_dataframe(df = ml_data, \n",
    "                                func = count_festival_nearby, \n",
    "                                num_cores = 12, \n",
    "                                festival_data = festival_data, \n",
    "                                dist = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "posted-flight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 177)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "invisible-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.drop([\"weekofyear\", \"date\"], 1).to_pickle(\"/home/seho/Passenger_Demand/data/ml_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-crest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-webmaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-india",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-filing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ready-regard",
   "metadata": {},
   "source": [
    "### 인구 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = pd.read_csv(\"~/Passenger_Demand/data/울산광역시_인구 현황_20200727.csv\", encoding = \"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?latlng=35.60467,129.4328&key=AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://maps.googleapis.com/maps/api/geocode/json?latlng=35.60467,129.4328&key=AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps.reverse_geocode((35.60467, 129.4328), language = \"korean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
