{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mysterious-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liberal-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Parallelize_DataFrame import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imported-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-letter",
   "metadata": {},
   "source": [
    "### 마이비 카드 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "armed-corruption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 8.71 s, total: 36.1 s\n",
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mybicard = pd.read_parquet('/home/seho/Passenger_Demand/data/mybicard.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mounted-project",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36261767, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "green-gates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collectdate</th>\n",
       "      <th>seq</th>\n",
       "      <th>route_nm</th>\n",
       "      <th>transdate</th>\n",
       "      <th>sumamount</th>\n",
       "      <th>stop_nm</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>normalcnt</th>\n",
       "      <th>studentcnt</th>\n",
       "      <th>studentamount</th>\n",
       "      <th>childcnt</th>\n",
       "      <th>childamount</th>\n",
       "      <th>transflag</th>\n",
       "      <th>mybicardnumber</th>\n",
       "      <th>base_ymd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20201003</td>\n",
       "      <td>26934</td>\n",
       "      <td>482-2</td>\n",
       "      <td>20201001 22:20:05</td>\n",
       "      <td>0</td>\n",
       "      <td>공업탑</td>\n",
       "      <td>3101347</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>환승</td>\n",
       "      <td>D900562094954</td>\n",
       "      <td>20201001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20201003</td>\n",
       "      <td>77969</td>\n",
       "      <td>482-2</td>\n",
       "      <td>20201001 22:15:04</td>\n",
       "      <td>1250</td>\n",
       "      <td>옥동행정복지센터.울산대공원정문</td>\n",
       "      <td>3102806</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>비환승</td>\n",
       "      <td>D900545114415</td>\n",
       "      <td>20201001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20201003</td>\n",
       "      <td>100264</td>\n",
       "      <td>104</td>\n",
       "      <td>20201001 22:44:42</td>\n",
       "      <td>1250</td>\n",
       "      <td>울산대후문</td>\n",
       "      <td>3100479</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>비환승</td>\n",
       "      <td>D100520894142</td>\n",
       "      <td>20201001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20201004</td>\n",
       "      <td>100508</td>\n",
       "      <td>701</td>\n",
       "      <td>20201001 18:20:02</td>\n",
       "      <td>0</td>\n",
       "      <td>병영사거리</td>\n",
       "      <td>3101274</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>환승</td>\n",
       "      <td>D900554620077</td>\n",
       "      <td>20201001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20201004</td>\n",
       "      <td>59746</td>\n",
       "      <td>104</td>\n",
       "      <td>20201001 11:11:21</td>\n",
       "      <td>820</td>\n",
       "      <td>남목1동</td>\n",
       "      <td>3101482</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>비환승</td>\n",
       "      <td>D900525646981</td>\n",
       "      <td>20201001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169550</th>\n",
       "      <td>20201120</td>\n",
       "      <td>38071</td>\n",
       "      <td>1127</td>\n",
       "      <td>20201121 00:14:38</td>\n",
       "      <td>2080</td>\n",
       "      <td>?????</td>\n",
       "      <td>3101460</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>???</td>\n",
       "      <td>D900644987520</td>\n",
       "      <td>20201121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169551</th>\n",
       "      <td>20201120</td>\n",
       "      <td>4216</td>\n",
       "      <td>1137</td>\n",
       "      <td>20201121 00:18:48</td>\n",
       "      <td>1700</td>\n",
       "      <td>??</td>\n",
       "      <td>3101456</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>???</td>\n",
       "      <td>D900590544747</td>\n",
       "      <td>20201121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169552</th>\n",
       "      <td>20201120</td>\n",
       "      <td>181900</td>\n",
       "      <td>106</td>\n",
       "      <td>20201121 00:06:19</td>\n",
       "      <td>1250</td>\n",
       "      <td>??????</td>\n",
       "      <td>3101242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>???</td>\n",
       "      <td>D900613753769</td>\n",
       "      <td>20201121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169553</th>\n",
       "      <td>20201120</td>\n",
       "      <td>240930</td>\n",
       "      <td>1127</td>\n",
       "      <td>20201121 00:12:30</td>\n",
       "      <td>2080</td>\n",
       "      <td>?????</td>\n",
       "      <td>3101461</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>???</td>\n",
       "      <td>D900614952385</td>\n",
       "      <td>20201121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169554</th>\n",
       "      <td>20201120</td>\n",
       "      <td>230079</td>\n",
       "      <td>1127</td>\n",
       "      <td>20201121 00:45:22</td>\n",
       "      <td>2080</td>\n",
       "      <td>?????</td>\n",
       "      <td>3100479</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>???</td>\n",
       "      <td>D900497930816</td>\n",
       "      <td>20201121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36261767 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        collectdate     seq route_nm          transdate  sumamount  \\\n",
       "0          20201003   26934    482-2  20201001 22:20:05          0   \n",
       "1          20201003   77969    482-2  20201001 22:15:04       1250   \n",
       "2          20201003  100264      104  20201001 22:44:42       1250   \n",
       "3          20201004  100508      701  20201001 18:20:02          0   \n",
       "4          20201004   59746      104  20201001 11:11:21        820   \n",
       "...             ...     ...      ...                ...        ...   \n",
       "169550     20201120   38071     1127  20201121 00:14:38       2080   \n",
       "169551     20201120    4216     1137  20201121 00:18:48       1700   \n",
       "169552     20201120  181900      106  20201121 00:06:19       1250   \n",
       "169553     20201120  240930     1127  20201121 00:12:30       2080   \n",
       "169554     20201120  230079     1127  20201121 00:45:22       2080   \n",
       "\n",
       "                 stop_nm  stop_id  normalcnt  studentcnt  studentamount  \\\n",
       "0                    공업탑  3101347          1           0              0   \n",
       "1       옥동행정복지센터.울산대공원정문  3102806          1           0              0   \n",
       "2                  울산대후문  3100479          1           0              0   \n",
       "3                  병영사거리  3101274          1           0              0   \n",
       "4                   남목1동  3101482          0           1            820   \n",
       "...                  ...      ...        ...         ...            ...   \n",
       "169550             ?????  3101460          1           0              0   \n",
       "169551                ??  3101456          0           1           1700   \n",
       "169552            ??????  3101242          1           0              0   \n",
       "169553             ?????  3101461          1           0              0   \n",
       "169554             ?????  3100479          1           0              0   \n",
       "\n",
       "        childcnt  childamount transflag mybicardnumber  base_ymd  \n",
       "0              0            0        환승  D900562094954  20201001  \n",
       "1              0            0       비환승  D900545114415  20201001  \n",
       "2              0            0       비환승  D100520894142  20201001  \n",
       "3              0            0        환승  D900554620077  20201001  \n",
       "4              0            0       비환승  D900525646981  20201001  \n",
       "...          ...          ...       ...            ...       ...  \n",
       "169550         0            0       ???  D900644987520  20201121  \n",
       "169551         0            0       ???  D900590544747  20201121  \n",
       "169552         0            0       ???  D900613753769  20201121  \n",
       "169553         0            0       ???  D900614952385  20201121  \n",
       "169554         0            0       ???  D900497930816  20201121  \n",
       "\n",
       "[36261767 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "functional-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# mybicard = mybicard.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electronic-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집일자 데이트 포맷으로 변환\n",
    "mybicard[\"collectdate\"] = pd.to_datetime(mybicard[\"collectdate\"], format = \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "discrete-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전송일자 데이트 포맷으로 변환\n",
    "mybicard[\"transdate\"] = pd.to_datetime(mybicard[\"transdate\"], format = \"%Y%m%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "published-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 승객 수 변수 생성(일반 + 학생 + 아동)\n",
    "mybicard[\"totalcnt\"] = mybicard[[\"normalcnt\", \"studentcnt\", \"childcnt\"]].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "loaded-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_nm에 공백이 포함되어 있어 공백 제거\n",
    "mybicard[\"route_nm\"] = mybicard[\"route_nm\"].replace(\"\\s\", \"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dimensional-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ;mybicard = mybicard.sort_values([\"transdate\", \"seq\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "external-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard = mybicard.rename(columns = {\"stop_id\" : \"mybi_stop_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-combining",
   "metadata": {},
   "source": [
    "### 401번 버스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "insured-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401 = mybicard.loc[(mybicard[\"route_nm\"] == \"401\")].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "raised-potato",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1964401, 17)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fatal-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg = (mybicard_401.loc[mybicard_401[\"transflag\"] != \"하차\"]\n",
    "                                   .groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='60Min')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brave-water",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314862, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "opening-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg.to_parquet(\"/home/seho/Passenger_Demand/data/mybicard_401_agg.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-museum",
   "metadata": {},
   "source": [
    "### 결측치 \n",
    "하루의 수집 데이터의 수가 0인 날짜의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immune-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_date = mybicard_401_agg.groupby([pd.Grouper(key=\"transdate\", freq=\"1D\")]).size().reset_index(name = \"cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "modular-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_date = count_by_date.loc[count_by_date[\"cnt\"] == 0, \"transdate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-thirty",
   "metadata": {},
   "source": [
    "#### n주 전 같은 요일 같은 시간대의 인원 수로 Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sufficient-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_recent_data(data, missing_date, date_col = \"transdate\"):\n",
    "    data = data.copy()\n",
    "    for x in missing_date:\n",
    "        temp = []\n",
    "        w = 0\n",
    "        while len(temp) == 0:\n",
    "            w +=1\n",
    "            temp = data.loc[data[date_col].dt.date == (x - timedelta(weeks = w)).date()].copy()\n",
    "\n",
    "        temp[date_col] = temp[date_col] + timedelta(weeks = w)\n",
    "        data = pd.concat([data, temp], 0)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-aruba",
   "metadata": {},
   "source": [
    "#### 최근 n주의 같은 요일 같은 시간대의 평균값으로 Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "vocal-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_recent_mean_data(data, missing_date, date_col):\n",
    "\n",
    "    data = data.copy()\n",
    "\n",
    "    # 요일, 시간 추가\n",
    "    data[\"dayofweek\"] = data[\"transdate\"].dt.dayofweek\n",
    "    dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "    data[\"dayofweek\"] = data[\"dayofweek\"].replace(dow_dict)\n",
    "    data[\"hour\"] = data[\"transdate\"].dt.hour\n",
    "\n",
    "    for x in missing_date:\n",
    "        base_date = x\n",
    "        w = 0\n",
    "        # 결측일의 이전 4주를 기본으로 검색하며, 데이터가 없는 경우 범위를 1주씩 늘려가며 데이터 조회\n",
    "        temp = []\n",
    "        while len(temp) == 0:\n",
    "            temp = data.loc[(data[\"transdate\"].dt.date.between((x - timedelta(weeks = 4+w)).date(), x.date())) & (data[\"transdate\"].dt.dayofweek == x.day_of_week)].copy()\n",
    "            w += 1\n",
    "\n",
    "        # 4+w 전까지의 데이터를 찾아서 정류장별, 요일별, 시간별 평균값 산출\n",
    "        temp2 = temp.groupby([\"mybi_stop_id\", \"dayofweek\", \"hour\"]).agg({\"totalcnt\" : np.mean,\n",
    "                                                                         \"normalcnt\" : np.mean,\n",
    "                                                                         \"studentcnt\" : np.mean,\n",
    "                                                                         \"childcnt\" : np.mean}).reset_index()\n",
    "        # 평균값 변환 (Float -> Int : 반올림 효과)\n",
    "        temp2[\"totalcnt\"] = temp2[\"totalcnt\"].astype(int)\n",
    "        temp2[\"normalcnt\"] = temp2[\"normalcnt\"].astype(int)\n",
    "        temp2[\"studentcnt\"] = temp2[\"studentcnt\"].astype(int)\n",
    "        temp2[\"childcnt\"] = temp2[\"childcnt\"].astype(int)\n",
    "\n",
    "        # 기준 일자, 시간으로 부터 transdate을 재생성\n",
    "        temp2[\"transdate\"] = temp2.apply(lambda x: base_date + timedelta(hours = x[\"hour\"]), 1)\n",
    "\n",
    "        data = pd.concat([data, temp2], 0)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "comfortable-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_impute = impute_recent_mean_data(data = mybicard_401_agg, missing_date = missing_date, date_col = \"transdate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ethical-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mybicard_401_agg = impute_recent_data(data = mybicard_401_agg, missing_date = missing_date, date_col = \"transdate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-pound",
   "metadata": {},
   "source": [
    "#### 결측일을 제외한 결측치(특정 시간에 데이터가 없는 경우)는 승객이 0이므로 0으로 대체한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "built-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 시작과 끝 사이를 1시간 간격으로 구분하여 list 생성\n",
    "dt_list = pd.date_range(start = mybicard_401_agg_impute[\"transdate\"].min(), end = mybicard_401_agg_impute[\"transdate\"].max(), freq = \"1h\")\n",
    "\n",
    "transdate_df = pd.DataFrame({\"transdate\" : dt_list}).reset_index(drop = True)\n",
    "mybi_stop_id_df = pd.DataFrame({\"mybi_stop_id\" : mybicard_401_agg_impute[\"mybi_stop_id\"].drop_duplicates()}).reset_index(drop = True)\n",
    "\n",
    "# 전체 일정(시간 단위)과 정류소 별 조합 DF 생성\n",
    "all_date = pd.merge(transdate_df, mybi_stop_id_df, how = \"cross\")\n",
    "\n",
    "# 결측일의 데이터를 채워넣은 전체 데이터를 left join\n",
    "ml_data = pd.merge(all_date, mybicard_401_agg_impute, on = [\"mybi_stop_id\", \"transdate\"], how = \"left\")\n",
    "\n",
    "ml_data[\"dayofweek\"] = ml_data[\"transdate\"].dt.dayofweek\n",
    "dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "ml_data[\"dayofweek\"] = ml_data[\"dayofweek\"].replace(dow_dict)\n",
    "ml_data[\"hour\"] = ml_data[\"transdate\"].dt.hour\n",
    "# 결측일이 아닌 결측값은 승객수가 없다고 판단하여 0으로 대체\n",
    "ml_data = ml_data.fillna(0)\n",
    "ml_data = ml_data.loc[ml_data[\"hour\"].isin([1,2,3,4]) == False ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "scientific-mirror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 8)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-failure",
   "metadata": {},
   "source": [
    "### 시계열 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ordered-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_feature(data, target_cols, date_cols, lags, groupby_cols = None):\n",
    "    data = data.copy()\n",
    "    if isinstance(lags, list) == False:\n",
    "        lags = [lags]\n",
    "    if isinstance(date_cols, list) == False:\n",
    "        date_cols = [date_cols]\n",
    "    if isinstance(target_cols, list) == False:\n",
    "        target_cols = [target_cols]\n",
    "    if isinstance(groupby_cols, list) == False:\n",
    "        groupby_cols = [groupby_cols]\n",
    "    \n",
    "    for lg in lags:\n",
    "        if groupby_cols is None:\n",
    "            cnt_bf = data.set_index(date_cols)[target_cols].shift(freq = lg).reset_index()\n",
    "        else:\n",
    "            cnt_bf = data.set_index(date_cols).groupby(groupby_cols)[target_cols].shift(freq = lg).reset_index()\n",
    "        \n",
    "        rename_dict = {col: f\"{col}_bf{lg}\" for col in target_cols}\n",
    "        cnt_bf = cnt_bf.rename(columns = rename_dict)\n",
    "        \n",
    "        data = pd.merge(data, cnt_bf, on = date_cols + groupby_cols, how = \"left\")\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "alive-blackberry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 9.14 ms, total: 1.27 s\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = create_lag_feature(data = ml_data, target_cols = \"totalcnt\", date_cols = \"transdate\", lags = [\"1d\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\"], groupby_cols = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dominant-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 15)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-musician",
   "metadata": {},
   "source": [
    "### 날짜별 평균 Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "imported-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_daily = (ml_data.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\", np.mean), \n",
    "                                        studentcnt = (\"studentcnt\", np.mean), \n",
    "                                        childcnt = (\"childcnt\", np.mean),\n",
    "                                        totalcnt = (\"totalcnt\", np.mean))\n",
    "                                   .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "banner-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lag = create_lag_feature(data = mybicard_401_agg_daily, target_cols = \"totalcnt\", date_cols = \"transdate\", lags = [\"1d\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\"], groupby_cols = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "separated-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [\"1d\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\"]\n",
    "rename_dict = {f\"{col}_bf{lg}\": f\"{col}_bf{lg}_total\" for col in [\"totalcnt\"] for lg in lags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "regional-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lag = daily_lag.rename(columns = rename_dict)\n",
    "daily_lag[\"date\"] = daily_lag[\"transdate\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "straight-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"date\"] = ml_data[\"transdate\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "latter-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_lag[[\"date\", \"mybi_stop_id\"] + list(rename_dict.values())], on = [\"date\", \"mybi_stop_id\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "empirical-evanescence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 23)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-vehicle",
   "metadata": {},
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-fence",
   "metadata": {},
   "source": [
    "#### 1) 이전 n개일자들의 동일 시간대 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "affiliated-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_agg(data, target_cols, date_col, groupby_cols, col_nm = \"\", rollings = [\"2d\"], agg_func = [np.mean, np.std]):\n",
    "    if isinstance(target_cols, list) == False:\n",
    "        target_cols = [target_cols]\n",
    "        \n",
    "    if isinstance(groupby_cols, list) == False:\n",
    "        groupby_cols = [groupby_cols]\n",
    "        \n",
    "    if col_nm != \"\":\n",
    "        col_nm = f\"{col_nm}_\"\n",
    "    \n",
    "    \n",
    "    for rl in rollings:\n",
    "        for tg in target_cols:\n",
    "            data = data.set_index(date_col).sort_index(ascending=True).copy()\n",
    "            rolling_data = data.groupby(groupby_cols)[tg].rolling(rl).agg(agg_func)\n",
    "            rolling_data = rolling_data.rename(columns = {\"mean\" : f\"{tg}_ma_{col_nm}mean_{rl}\", \n",
    "                                                          \"std\" : f\"{tg}_ma_{col_nm}std_{rl}\"})\n",
    "            rolling_data = rolling_data.groupby(groupby_cols).shift(1).reset_index()    \n",
    "            \n",
    "            data = pd.merge(data.reset_index(), rolling_data, on = [date_col] + groupby_cols, how = \"left\")\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fixed-declaration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 s, sys: 46.7 ms, total: 2.09 s\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = calculate_moving_agg(data = ml_data, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\", \"hour\"], col_nm = \"hour\", rollings = [\"2d\", \"3d\", \"4d\", \"5d\", \"6d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "arranged-match",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 33)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-invasion",
   "metadata": {},
   "source": [
    "#### 2) n주전까지의 동일 요일의 동일 시간대 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "molecular-ecology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.12 s, sys: 28.4 ms, total: 3.15 s\n",
      "Wall time: 3.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = calculate_moving_agg(data = ml_data, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\", \"hour\", \"dayofweek\"], col_nm = \"hour_week\", rollings = [\"14d\", \"21d\", \"28d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "improving-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 39)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-impact",
   "metadata": {},
   "source": [
    "#### 3) 이전 n개일자들의 전체 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "certified-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_1d = (ml_data.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())\n",
    "\n",
    "mybicard_401_agg_1d[\"dayofweek\"] = mybicard_401_agg_1d[\"transdate\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "opponent-compiler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 110 ms, sys: 0 ns, total: 110 ms\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "daily_agg = calculate_moving_agg(data = mybicard_401_agg_1d, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\"], col_nm = \"daily\", rollings = [\"2d\", \"3d\", \"4d\", \"5d\", \"6d\"])\n",
    "daily_agg[\"date\"] = daily_agg[\"transdate\"].dt.date\n",
    "daily_agg = daily_agg.drop([\"transdate\", \"normalcnt\", \"studentcnt\", \"childcnt\", \"totalcnt\", \"dayofweek\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fixed-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_agg, on = [\"mybi_stop_id\", \"date\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "present-listening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 49)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-survival",
   "metadata": {},
   "source": [
    "#### 4) n주전까지의 동일 요일의 전체 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "continued-coordinator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 137 ms, sys: 814 µs, total: 137 ms\n",
      "Wall time: 137 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "daily_week_agg = calculate_moving_agg(data = mybicard_401_agg_1d, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\", \"dayofweek\"], col_nm = \"daily_week\", rollings = [\"14d\", \"21d\", \"28d\"])\n",
    "daily_week_agg[\"date\"] = daily_week_agg[\"transdate\"].dt.date\n",
    "daily_week_agg = daily_week_agg.drop([\"transdate\", \"normalcnt\", \"studentcnt\", \"childcnt\", \"totalcnt\", \"dayofweek\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "attended-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_week_agg, on = [\"mybi_stop_id\", \"date\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "reported-monitoring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 55)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-escape",
   "metadata": {},
   "source": [
    "#### 5) n주전까지의 주 평균의 이동평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "detected-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_1d = (ml_data.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())\n",
    "mybicard_401_agg_1d[\"hour\"] = mybicard_401_agg_1d[\"transdate\"].dt.hour\n",
    "mybicard_401_agg_1d[\"weekofyear\"] = mybicard_401_agg_1d[\"transdate\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "quarterly-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_1w = mybicard_401_agg_1d.groupby([\"mybi_stop_id\", \"weekofyear\"])[\"totalcnt\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "disabled-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_agg = calculate_moving_agg(data = mybicard_401_agg_1w, target_cols = [\"totalcnt\"], date_col = \"weekofyear\", groupby_cols = [\"mybi_stop_id\"], col_nm = \"weekly\", rollings = [2,3,4])\n",
    "weekly_agg = weekly_agg.drop(\"totalcnt\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "broad-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"weekofyear\"] = ml_data[\"transdate\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "infrared-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, weekly_agg, on = [\"mybi_stop_id\", \"weekofyear\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "threatened-assessment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 62)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-franklin",
   "metadata": {},
   "source": [
    "### 특일 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "stunning-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/holiday_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bearing-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data[\"date\"] = pd.to_datetime(holiday_data[\"locdate\"], format = \"%Y%m%d\").dt.date\n",
    "holiday_data = holiday_data.drop([\"locdate\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "positive-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.DataFrame({\"date\" : pd.date_range(\"2020-01-01\", \"2020-12-31\", freq = \"1D\")})\n",
    "date_df[\"weekend\"] = np.where(date_df[\"date\"].dt.dayofweek.isin([5,6]), \"Y\", \"N\")\n",
    "date_df[\"date\"] = date_df[\"date\"].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-convergence",
   "metadata": {},
   "source": [
    "#### 공휴일 / 명절 여부 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "accompanied-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공휴일(holiday), 명절(ntl_holiday) 구분\n",
    "ntl_holiday = holiday_data.loc[holiday_data[\"dateName\"].isin([\"설날\", \"추석\"])]\n",
    "ntl_holiday = ntl_holiday.rename(columns = {\"dateName\" : \"ntl_holi\"})\n",
    "\n",
    "holiday = holiday_data.loc[holiday_data[\"dateName\"].isin([\"설날\", \"추석\"]) == False]\n",
    "holiday = holiday.rename(columns = {\"dateName\" : \"holi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "promotional-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.merge(date_df, ntl_holiday, on = \"date\", how = \"left\")\n",
    "date_df = pd.merge(date_df, holiday, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "inclusive-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df.assign(ntl_holi = np.where(date_df[\"ntl_holi\"].isna(), \"N\", \"Y\"),\n",
    "                         holi = np.where(date_df[\"holi\"].isna(), \"N\", \"Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-stamp",
   "metadata": {},
   "source": [
    "#### 3일 이상 연휴 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "medical-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df[\"rest_yn\"] = date_df[[\"weekend\", \"ntl_holi\", \"holi\"]].apply(lambda x: any(x == \"Y\"), 1)\n",
    "date_df[\"rest_yn\"] = np.where(date_df[\"rest_yn\"],\"Y\", \"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "assumed-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seq_y(data, criterion = 2):\n",
    "    seq_list = []\n",
    "    Y_cnt = 0\n",
    "    for i, x in enumerate(data):\n",
    "        if x == \"Y\":\n",
    "            Y_cnt += 1\n",
    "\n",
    "        if (x == \"N\") | (i == len(data)):\n",
    "            if Y_cnt > criterion:\n",
    "                temp_list = [\"Y\"] * Y_cnt\n",
    "                seq_list += temp_list\n",
    "            elif (Y_cnt > 0) & (Y_cnt <= criterion):\n",
    "                temp_list = [\"N\"] * Y_cnt\n",
    "                seq_list += temp_list\n",
    "            seq_list.append(\"N\")\n",
    "            Y_cnt = 0\n",
    "            \n",
    "    return seq_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "through-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df[\"seq_holi\"] = find_seq_y(data = date_df[\"rest_yn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "amended-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df.drop([\"weekend\", \"rest_yn\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "selective-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, date_df, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "moral-jackson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 65)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-medicaid",
   "metadata": {},
   "source": [
    "### 날씨 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "aerial-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/weather_2018.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "documented-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = weather_data.loc[:, [\"tm\", \"ta\", \"hm\", \"rn\", \"dc10Tca\",  \"dsnw\", \"wd\", \"ws\"]]\n",
    "weather_data = weather_data.rename(columns = {\"tm\" : \"time\",\n",
    "                                              \"ta\" : \"temperature\",\n",
    "                                              \"hm\" : \"humidity\",\n",
    "                                              \"rn\" : \"precipitation\",\n",
    "                                              \"dc10Tca\" : \"전운량\",\n",
    "                                              \"dsnw\" : \"snowfall\",\n",
    "                                              \"wd\" : \"풍향\",\n",
    "                                              \"ws\" : \"풍속\"})\n",
    "weather_data[\"time\"] = pd.to_datetime(weather_data[\"time\"], format = \"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "wanted-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weather_data.columns:\n",
    "    if col == \"time\":\n",
    "        continue\n",
    "    weather_data[col] = weather_data[col].replace(\"\", \"0.0\").astype(float)\n",
    "    weather_data[col] = weather_data[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "rural-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data[\"time_hours\"] = weather_data[\"time\"].dt.strftime(\"%Y-%m-%d %H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "first-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"transdate_hours\"] = ml_data[\"transdate\"].dt.strftime(\"%Y-%m-%d %H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "distinguished-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, weather_data[[\"time_hours\", \"temperature\", \"humidity\", \"precipitation\", \"snowfall\"]], left_on = \"transdate_hours\", right_on = \"time_hours\")\n",
    "ml_data = ml_data.drop([\"transdate_hours\", \"time_hours\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ideal-induction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 69)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-savings",
   "metadata": {},
   "source": [
    "### 미세먼지 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "romantic-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_data = pd.read_csv(\"/home/seho/Passenger_Demand/data/pm_data.csv\")\n",
    "pm_data[\"issueDate\"] = pd.to_datetime(pm_data[\"issueDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "capable-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_data_agg = pm_data.loc[pm_data[\"districtName\"] == \"울산\"].groupby(pd.Grouper(key=\"issueDate\", freq=\"1D\")).size().reset_index(name = \"pm_alert_cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "coated-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"date\"] = ml_data[\"transdate\"].dt.strftime(\"%Y-%m-%d\")\n",
    "pm_data_agg[\"issueDate\"] = pm_data_agg[\"issueDate\"].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "fifteen-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, pm_data_agg, how = \"left\", left_on = \"date\", right_on = \"issueDate\")\n",
    "ml_data = ml_data.drop([\"issueDate\"], 1)\n",
    "ml_data[\"pm_alert_cnt\"] = ml_data[\"pm_alert_cnt\"].fillna(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "constitutional-democracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 70)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-cabinet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-recovery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "comic-clone",
   "metadata": {},
   "source": [
    "### 정류장 X,Y 좌표 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "academic-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경주시, 양산시, 울산광역시, 부산광역시\n",
    "bus_stop_info = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_버스 정류소 위치 정보_20200531.csv\", encoding = \"euc-kr\")\n",
    "bus_stop_info = bus_stop_info.loc[bus_stop_info[\"권역\"] == \"울산광역시\"]\n",
    "bus_stop_info.columns = [\"stop_nm\", \"stop_id\", \"longitude\", \"latitude\", \"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "apart-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_1 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_율리_꽃바위.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401_2 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_꽃바위_율리.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401 = pd.concat([bus_stop_401_1, bus_stop_401_2])\n",
    "bus_stop_401.columns = [\"mybi_stop_id\", \"stop_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fatty-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_info = pd.merge(bus_stop_401, bus_stop_info, on = \"stop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-creativity",
   "metadata": {},
   "source": [
    "### 상권정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bibliographic-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_area = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_상권정보_201231.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "rubber-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = trading_area[\"상권업종중분류명\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "radio-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(latlon1, latlon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1 = map(radians, latlon1)\n",
    "    lat2, lon2 = map(radians, latlon2)\n",
    "#     lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def count_store_nearby(data, trading_area = trading_area, dist = 0.1, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = trading_area[\"상권업종중분류명\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = trading_area[[\"위도\", \"경도\"]].apply(lambda x: haversine((x[\"위도\"], x[\"경도\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = trading_area.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"store_category_{i}\"] = (within_data[\"상권업종중분류명\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "graduate-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n",
      " 45%|████▌     | 5/11 [00:03<00:05,  1.20it/s]]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.10it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n",
      " 45%|████▌     | 5/11 [00:03<00:05,  1.19it/s]]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.05it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.10it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.12it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 589 ms, total: 19.3 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                           func = count_store_nearby, \n",
    "                                           num_cores = 12, \n",
    "                                           trading_area = trading_area, \n",
    "                                           dist = 0.2, \n",
    "                                           category_list = category_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-cache",
   "metadata": {},
   "source": [
    "### 병원정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "theoretical-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/hospital_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "serious-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_data[\"category\"] = hospital_data[\"의료기관종별\"].replace({\"한방병원\" : \"병원\",\n",
    "                                                                  \"치과병원\" : \"병원\",\n",
    "                                                                  \"일반요양병원\" : \"요양병원\",\n",
    "                                                                  \"부속의원\" : \"의원\",\n",
    "                                                                  \"치과의원\" : \"의원\",\n",
    "                                                                  \"한의원\" : \"의원\",\n",
    "                                                                  \"보건지소\" : \"보건소\",\n",
    "                                                                  \"보건진료소\" : \"보건소\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "coastal-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_category_list = hospital_data[\"category\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "stuffed-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hospital_nearby(data, hospital_data = hospital_data, dist = 0.2, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = hospital_data[\"category\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = hospital_data[[\"lat\", \"lng\"]].apply(lambda x: haversine((x[\"lat\"], x[\"lng\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = hospital_data.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"hospital_category_{i}\"] = (within_data[\"category\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "cosmetic-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 22.59it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.89it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21.29it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20.96it/s]\n",
      " 82%|████████▏ | 9/11 [00:00<00:00, 21.81it/s]]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20.38it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20.88it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20.02it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20.67it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21.63it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 728 ms, sys: 503 ms, total: 1.23 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                           func = count_hospital_nearby, \n",
    "                                           num_cores = 12, \n",
    "                                           hospital_data = hospital_data, \n",
    "                                           dist = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-chorus",
   "metadata": {},
   "source": [
    "### 학교정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "radio-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = pd.read_excel(\"/home/seho/Passenger_Demand/data/gv_school.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "atmospheric-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"표준일차명\"] = school_data[\"표준일차명\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "bottom-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = school_data.loc[school_data[\"표준일차명\"].str.contains(\"울산\", na=\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "graduate-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "acting-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "sustainable-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geocode(x, gmaps):\n",
    "    try:\n",
    "        result = gmaps.geocode(x)[0][\"geometry\"][\"location\"]\n",
    "        # result = [temp[\"lat\"], temp[\"lng\"]]\n",
    "    except:\n",
    "        result = None\n",
    "    \n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "cloudy-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"category\"] = school_data[\"학교종류\"].replace({\"전문대학(3년제)\" : \"전문대학\",\n",
    "                                                          \"사내대학(전문)\" : \"전문대학\",\n",
    "                                                          \"기능대학\" : \"전문대학\",\n",
    "                                                          \"일반대학원\" : \"대학원\",\n",
    "                                                          \"전문대학원\" : \"대학원\",\n",
    "                                                          \"특수대학원\" : \"대학원\",\n",
    "                                                          \"일반고등학교\" : \"고등학교\",\n",
    "                                                          \"공업고등학교\" : \"고등학교\",\n",
    "                                                          \"상업고등학교\" : \"고등학교\",\n",
    "                                                          \"가사고등학교\" : \"고등학교\",\n",
    "                                                          \"체육고등학교\" : \"고등학교\",\n",
    "                                                          \"외국어고등학교\" : \"고등학교\",\n",
    "                                                          \"과학고등학교\" : \"고등학교\",\n",
    "                                                          \"예술고등학교\" : \"고등학교\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bigger-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "school_data[\"lat_lng\"] = school_data[\"새주소\"].apply(get_geocode, gmaps = gmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "graphic-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"lat\"] = school_data[\"lat_lng\"].apply(lambda x: x[\"lat\"])\n",
    "school_data[\"lng\"] = school_data[\"lat_lng\"].apply(lambda x: x[\"lng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "elementary-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_school_nearby(data, school_data = school_data, dist = 0.2, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = school_data[\"category\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = school_data[[\"lat\", \"lng\"]].apply(lambda x: haversine((x[\"lat\"], x[\"lng\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = school_data.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"school_category_{i}\"] = (within_data[\"category\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "anticipated-scroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 75.12it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 78.86it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 71.43it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 69.90it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 69.26it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 66.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 65.95it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 66.10it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 67.34it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 71.13it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 74.89it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 77.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 424 ms, sys: 449 ms, total: 872 ms\n",
      "Wall time: 975 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                              func = count_school_nearby, \n",
    "                                              num_cores = 12, \n",
    "                                              school_data = school_data, \n",
    "                                              dist = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-basin",
   "metadata": {},
   "source": [
    "### 정류장 정보 Join(거리기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "choice-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, bus_stop_401_info.drop([\"stop_id\", \"city\"],1), on = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "continuing-island",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 175)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-holder",
   "metadata": {},
   "source": [
    "### 울산행사정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "aggressive-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = pd.read_csv(\"~/Passenger_Demand/data/ulsan_event_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "funded-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data[\"eventStartDate\"] = pd.to_datetime(event_data[\"eventStartDate\"], format = \"%Y-%m-%d\")\n",
    "event_data[\"eventEndDate\"] = pd.to_datetime(event_data[\"eventEndDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "dress-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_event_nearby(data, event_data, dist = 0.2):\n",
    "    data_copy = data.copy()\n",
    "    within_data = event_data.loc[(event_data[\"eventStartDate\"] <= data_copy[\"transdate\"]) & (event_data[\"eventEndDate\"] >= data_copy[\"transdate\"])]\n",
    "    \n",
    "    if len(within_data) == 0:\n",
    "        data_copy[f\"event_nearby\"] = 0\n",
    "    else:\n",
    "        dist_list = within_data[[\"latitude\", \"longitude\"]].apply(lambda x: haversine((x[\"latitude\"], x[\"longitude\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "        data_copy[f\"event_nearby\"] = (dist_list <= dist).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "pleasant-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51745/51745 [04:27<00:00, 193.52it/s]\n",
      "100%|██████████| 51745/51745 [04:26<00:00, 194.04it/s]\n",
      "100%|██████████| 51745/51745 [04:28<00:00, 192.79it/s]\n",
      "100%|██████████| 51745/51745 [04:29<00:00, 192.17it/s]\n",
      "100%|██████████| 51745/51745 [04:24<00:00, 195.47it/s]\n",
      "100%|██████████| 51745/51745 [04:26<00:00, 194.07it/s]\n",
      "100%|██████████| 51745/51745 [04:26<00:00, 194.53it/s]\n",
      "100%|██████████| 51745/51745 [04:27<00:00, 193.25it/s]\n",
      "100%|██████████| 51745/51745 [04:24<00:00, 195.72it/s]\n",
      "100%|██████████| 51745/51745 [04:24<00:00, 195.89it/s]\n",
      "100%|██████████| 51745/51745 [04:26<00:00, 193.81it/s]\n",
      "100%|██████████| 51745/51745 [04:25<00:00, 195.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 18.8 s, total: 48.7 s\n",
      "Wall time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = parallelize_dataframe(df = ml_data, \n",
    "                                func = count_event_nearby, \n",
    "                                num_cores = 12, \n",
    "                                event_data = event_data, \n",
    "                                dist = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "military-raising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 176)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-water",
   "metadata": {},
   "source": [
    "### 축제 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "native-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data = pd.read_csv(\"~/Passenger_Demand/data/festival_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "heavy-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data[\"fstvlStartDate\"] = pd.to_datetime(festival_data[\"fstvlStartDate\"], format = \"%Y-%m-%d\")\n",
    "festival_data[\"fstvlEndDate\"] = pd.to_datetime(festival_data[\"fstvlEndDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "incoming-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_festival_nearby(data, festival_data, dist = 0.2):\n",
    "    data_copy = data.copy()\n",
    "    within_data = festival_data.loc[(festival_data[\"fstvlStartDate\"] <= data_copy[\"transdate\"]) & (festival_data[\"fstvlEndDate\"] >= data_copy[\"transdate\"])]\n",
    "    \n",
    "    if len(within_data) == 0:\n",
    "        data_copy[f\"festival_nearby\"] = 0\n",
    "    else:\n",
    "        dist_list = within_data[[\"latitude\", \"longitude\"]].apply(lambda x: haversine((x[\"latitude\"], x[\"longitude\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "        data_copy[f\"festival_nearby\"] = (dist_list <= dist).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "cardiovascular-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51745/51745 [01:53<00:00, 455.71it/s]\n",
      "100%|█████████▉| 51576/51745 [01:45<00:00, 309.50it/s]\n",
      "100%|██████████| 51745/51745 [01:54<00:00, 452.62it/s]\n",
      "100%|██████████| 51745/51745 [01:53<00:00, 455.10it/s]\n",
      "100%|██████████| 51745/51745 [01:53<00:00, 457.21it/s]\n",
      "100%|██████████| 51745/51745 [01:53<00:00, 455.10it/s]\n",
      "100%|██████████| 51745/51745 [01:53<00:00, 456.65it/s]\n",
      "100%|██████████| 51745/51745 [01:52<00:00, 459.80it/s]\n",
      "100%|██████████| 51745/51745 [01:53<00:00, 454.17it/s]\n",
      "100%|██████████| 51745/51745 [01:51<00:00, 462.20it/s]\n",
      "100%|██████████| 51745/51745 [01:52<00:00, 458.51it/s]\n",
      "100%|██████████| 51745/51745 [01:51<00:00, 462.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 s, sys: 10.5 s, total: 28.6 s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = parallelize_dataframe(df = ml_data, \n",
    "                                func = count_festival_nearby, \n",
    "                                num_cores = 12, \n",
    "                                festival_data = festival_data, \n",
    "                                dist = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "temporal-provider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 177)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-paragraph",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "accurate-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.to_pickle(\"/home/seho/Passenger_Demand/data/ml_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "looking-award",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transdate', 'mybi_stop_id', 'normalcnt', 'studentcnt', 'childcnt',\n",
       "       'totalcnt', 'dayofweek', 'hour', 'totalcnt_bf1d', 'totalcnt_bf2d',\n",
       "       ...\n",
       "       'hospital_category_4', 'hospital_category_5', 'school_category_0',\n",
       "       'school_category_1', 'school_category_2', 'school_category_3',\n",
       "       'school_category_4', 'school_category_5', 'event_nearby',\n",
       "       'festival_nearby'],\n",
       "      dtype='object', length=177)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-force",
   "metadata": {},
   "source": [
    "### 인구 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "stuffed-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = pd.read_csv(\"~/Passenger_Demand/data/울산광역시_인구 현황_20200727.csv\", encoding = \"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-modeling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
