{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "young-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rubber-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Parallelize_DataFrame import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "active-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-cholesterol",
   "metadata": {},
   "source": [
    "### 마이비 카드 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "serious-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 s, sys: 7.36 s, total: 33.4 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mybicard = pd.read_parquet('/home/seho/Passenger_Demand/data/mybicard.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "honest-charm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.7 s, sys: 3.34 s, total: 49.1 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mybicard = mybicard.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "combined-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집일자 데이트 포맷으로 변환\n",
    "mybicard[\"collectdate\"] = pd.to_datetime(mybicard[\"collectdate\"], format = \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automatic-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전송일자 데이트 포맷으로 변환\n",
    "mybicard[\"transdate\"] = pd.to_datetime(mybicard[\"transdate\"], format = \"%Y%m%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "emotional-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 승객 수 변수 생성(일반 + 학생 + 아동)\n",
    "mybicard[\"totalcnt\"] = mybicard[[\"normalcnt\", \"studentcnt\", \"childcnt\"]].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "informal-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_nm에 공백이 포함되어 있어 공백 제거\n",
    "mybicard[\"route_nm\"] = mybicard[\"route_nm\"].replace(\"\\s\", \"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "separate-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard = mybicard.sort_values([\"transdate\", \"seq\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "composed-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard = mybicard.rename(columns = {\"stop_id\" : \"mybi_stop_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-omaha",
   "metadata": {},
   "source": [
    "### 401번 버스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acquired-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401 = mybicard.loc[(mybicard[\"route_nm\"] == \"401\")].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adaptive-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg = (mybicard_401.loc[mybicard_401[\"transflag\"] != \"하차\"]\n",
    "                                   .groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='60Min')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "enabling-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg.to_parquet(\"/home/seho/Passenger_Demand/data/mybicard_401_agg.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-offset",
   "metadata": {},
   "source": [
    "### 결측치 \n",
    "하루의 수집 데이터의 수가 0인 날짜의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "completed-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_date = mybicard_401_agg.groupby([pd.Grouper(key=\"transdate\", freq=\"1D\")]).size().reset_index(name = \"cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gorgeous-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_date = count_by_date.loc[count_by_date[\"cnt\"] == 0, \"transdate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-porcelain",
   "metadata": {},
   "source": [
    "#### n주 전 같은 요일 같은 시간대의 인원 수로 Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314862, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392195, 6)\n",
      "CPU times: user 3.07 s, sys: 108 ms, total: 3.18 s\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnt_df= mybicard_401_agg.copy()\n",
    "print(cnt_df.shape)\n",
    "for x in missing_date:\n",
    "    cnt_df_temp = []\n",
    "    w = 0\n",
    "    while len(cnt_df_temp) == 0:\n",
    "        w +=1\n",
    "        cnt_df_temp = cnt_df.loc[cnt_df[\"transdate\"].dt.date == (x - timedelta(weeks = w)).date()]\n",
    "    \n",
    "    cnt_df_temp[\"transdate\"] = cnt_df_temp[\"transdate\"] + timedelta(weeks = w)\n",
    "    cnt_df = pd.concat([cnt_df, cnt_df_temp], 0)\n",
    "print(cnt_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-liquid",
   "metadata": {},
   "source": [
    "#### 결측일을 제외한 결측치(특정 시간에 데이터가 없는 경우)는 승객이 0이므로 0으로 대체한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "suspected-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 시작과 끝 사이를 1시간 간격으로 구분하여 list 생성\n",
    "dt_list = pd.date_range(start = cnt_df[\"transdate\"].min(), end = cnt_df[\"transdate\"].max(), freq = \"1h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "durable-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "transdate_df = pd.DataFrame({\"transdate\" : dt_list}).reset_index(drop = True)\n",
    "mybi_stop_id_df = pd.DataFrame({\"mybi_stop_id\" : cnt_df[\"mybi_stop_id\"].drop_duplicates()}).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sporting-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_date = pd.merge(transdate_df, mybi_stop_id_df, how = \"cross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "diagnostic-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(all_date, cnt_df, on = [\"mybi_stop_id\", \"transdate\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "useful-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일, 날짜, 월 변수 생성\n",
    "ml_data[\"dayofweek\"] = ml_data[\"transdate\"].dt.dayofweek\n",
    "dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "ml_data[\"dayofweek\"] = ml_data[\"dayofweek\"].replace(dow_dict)\n",
    "ml_data[\"day\"] = ml_data[\"transdate\"].dt.day\n",
    "ml_data[\"month\"] = ml_data[\"transdate\"].dt.month\n",
    "ml_data[\"hour\"] = ml_data[\"transdate\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "later-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = ml_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "different-control",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 130)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.loc[ml_data[\"hour\"].isin([1,2,3,4]) == False ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "killing-tutorial",
   "metadata": {},
   "source": [
    "#### 최근 n주의 같은 요일 같은 시간대의 평균값으로 Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "loaded-payment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314862, 8)\n",
      "(408337, 8)\n",
      "CPU times: user 5.06 s, sys: 168 ms, total: 5.23 s\n",
      "Wall time: 5.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnt_df= mybicard_401_agg.copy()\n",
    "\n",
    "# 요일, 시간 추가\n",
    "cnt_df[\"dayofweek\"] = cnt_df[\"transdate\"].dt.dayofweek\n",
    "dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "cnt_df[\"dayofweek\"] = cnt_df[\"dayofweek\"].replace(dow_dict)\n",
    "cnt_df[\"hour\"] = cnt_df[\"transdate\"].dt.hour\n",
    "\n",
    "print(cnt_df.shape)\n",
    "for x in missing_date:\n",
    "    base_date = x\n",
    "    w = 0\n",
    "    # 결측일의 이전 4주를 기본으로 검색하며, 데이터가 없는 경우 범위를 1주씩 늘려가며 데이터 조회\n",
    "    cnt_df_temp = []\n",
    "    while len(cnt_df_temp) == 0:\n",
    "        cnt_df_temp = cnt_df.loc[(cnt_df[\"transdate\"].dt.date.between((x - timedelta(weeks = 4+w)).date(), x.date())) & (cnt_df[\"transdate\"].dt.dayofweek == x.day_of_week)]\n",
    "        w += 1\n",
    "    \n",
    "    # 4+w 전까지의 데이터를 찾아서 정류장별, 요일별, 시간별 평균값 산출\n",
    "    cnt_df_temp2 = cnt_df_temp.groupby([\"mybi_stop_id\", \"dayofweek\", \"hour\"]).agg({\"totalcnt\" : np.mean,\n",
    "                                                                                   \"normalcnt\" : np.mean,\n",
    "                                                                                   \"studentcnt\" : np.mean,\n",
    "                                                                                   \"childcnt\" : np.mean}).reset_index()\n",
    "    # 평균값 변환 (Float -> Int : 반올림 효과)\n",
    "    cnt_df_temp2[\"totalcnt\"] = cnt_df_temp2[\"totalcnt\"].astype(int)\n",
    "    cnt_df_temp2[\"normalcnt\"] = cnt_df_temp2[\"normalcnt\"].astype(int)\n",
    "    cnt_df_temp2[\"studentcnt\"] = cnt_df_temp2[\"studentcnt\"].astype(int)\n",
    "    cnt_df_temp2[\"childcnt\"] = cnt_df_temp2[\"childcnt\"].astype(int)\n",
    "       \n",
    "    # 기준 일자, 시간으로 부터 transdate을 재생성\n",
    "    cnt_df_temp2[\"transdate\"] = cnt_df_temp2.apply(lambda x: base_date + timedelta(hours = x[\"hour\"]), 1)\n",
    "\n",
    "    cnt_df = pd.concat([cnt_df, cnt_df_temp2], 0)\n",
    "print(cnt_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "# 데이터의 시작과 끝 사이를 1시간 간격으로 구분하여 list 생성\n",
    "dt_list = pd.date_range(start = cnt_df[\"transdate\"].min(), end = cnt_df[\"transdate\"].max(), freq = \"1h\")\n",
    "\n",
    "transdate_df = pd.DataFrame({\"transdate\" : dt_list}).reset_index(drop = True)\n",
    "mybi_stop_id_df = pd.DataFrame({\"mybi_stop_id\" : cnt_df[\"mybi_stop_id\"].drop_duplicates()}).reset_index(drop = True)\n",
    "\n",
    "# 전체 일정(시간 단위)과 정류소 별 조합 DF 생성\n",
    "all_date = pd.merge(transdate_df, mybi_stop_id_df, how = \"cross\")\n",
    "\n",
    "# 결측일의 데이터를 채워넣은 전체 데이터를 left join\n",
    "ml_data = pd.merge(all_date, cnt_df, on = [\"mybi_stop_id\", \"transdate\"], how = \"left\")\n",
    "\n",
    "# 결측일이 아닌 결측값은 승객수가 없다고 판단하여 0으로 대체\n",
    "ml_data = ml_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "excessive-looking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transdate</th>\n",
       "      <th>mybi_stop_id</th>\n",
       "      <th>normalcnt</th>\n",
       "      <th>studentcnt</th>\n",
       "      <th>childcnt</th>\n",
       "      <th>totalcnt</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transdate  mybi_stop_id  normalcnt  studentcnt  childcnt  totalcnt  \\\n",
       "0 2020-04-08       3100020        0.0         0.0       0.0       0.0   \n",
       "1 2020-04-08       3100021        0.0         0.0       0.0       0.0   \n",
       "2 2020-04-08       3100057        0.0         0.0       0.0       0.0   \n",
       "3 2020-04-08       3100058        0.0         0.0       0.0       0.0   \n",
       "4 2020-04-08       3100085        0.0         0.0       0.0       0.0   \n",
       "\n",
       "  dayofweek  hour  \n",
       "0         0   0.0  \n",
       "1         0   0.0  \n",
       "2         0   0.0  \n",
       "3         0   0.0  \n",
       "4         0   0.0  "
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-pride",
   "metadata": {},
   "source": [
    "### 시계열 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "extra-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_feature(data, target_cols, date_cols, freqs, groupby_cols = None):\n",
    "    data = data.copy()\n",
    "    if isinstance(freqs, list) == False:\n",
    "        freqs = [freqs]\n",
    "    if isinstance(date_cols, list) == False:\n",
    "        date_cols = [date_cols]\n",
    "    if isinstance(target_cols, list) == False:\n",
    "        target_cols = [target_cols]\n",
    "    if isinstance(groupby_cols, list) == False:\n",
    "        groupby_cols = [groupby_cols]\n",
    "    \n",
    "    for frq in freqs:\n",
    "        if groupby_cols is None:\n",
    "            cnt_bf = data.set_index(date_cols)[target_cols].shift(freq = frq).reset_index()\n",
    "        else:\n",
    "            cnt_bf = data.set_index(date_cols).groupby(groupby_cols)[target_cols].shift(freq = frq).reset_index()\n",
    "        \n",
    "        rename_dict = {col: f\"{col}_bf{frq}\" for col in target_cols}\n",
    "        cnt_bf = cnt_bf.rename(columns = rename_dict)\n",
    "        \n",
    "        data = pd.merge(data, cnt_bf, on = date_cols + groupby_cols, how = \"left\")\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "listed-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = create_lag_feature(data = ml_data, target_cols = \"totalcnt\", date_cols = \"transdate\", freqs = [\"1d\", \"7d\"], groupby_cols = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-binding",
   "metadata": {},
   "source": [
    "### 날짜별 합계, 평균 Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "worth-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_daily = (mybicard_401.loc[mybicard_401[\"transflag\"] != \"하차\"]\n",
    "                                   .groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\", np.mean), \n",
    "                                        studentcnt = (\"studentcnt\", np.mean), \n",
    "                                        childcnt = (\"childcnt\", np.mean),\n",
    "                                        totalcnt = (\"totalcnt\", np.mean))\n",
    "                                   .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "changing-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lag = create_lag_feature(data = mybicard_401_agg_daily, target_cols = \"totalcnt\", date_cols = \"transdate\", freqs = [\"1d\", \"7d\"], groupby_cols = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "smooth-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lag = daily_lag.rename(columns = {\"totalcnt_bf1d\" : \"totalcnt_bf1d_total\", \"totalcnt_bf7d\" : \"totalcnt_bf7d_total\"})\n",
    "daily_lag[\"date\"] = daily_lag[\"transdate\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "american-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"date\"] = ml_data[\"transdate\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "interpreted-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_lag[[\"date\", \"mybi_stop_id\", \"totalcnt_bf1d_total\", \"totalcnt_bf7d_total\"]], on = [\"date\", \"mybi_stop_id\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-liverpool",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-bryan",
   "metadata": {},
   "source": [
    "### 특일 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "atmospheric-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/holiday_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "metropolitan-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data[\"date\"] = pd.to_datetime(holiday_data[\"locdate\"], format = \"%Y%m%d\").dt.date\n",
    "holiday_data = holiday_data.drop([\"locdate\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "functional-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.DataFrame({\"date\" : pd.date_range(\"2020-01-01\", \"2020-12-31\", freq = \"1D\")})\n",
    "date_df[\"weekend\"] = np.where(date_df[\"date\"].dt.dayofweek.isin([5,6]), \"Y\", \"N\")\n",
    "date_df[\"date\"] = date_df[\"date\"].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-agreement",
   "metadata": {},
   "source": [
    "#### 공휴일 / 명절 여부 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "shaped-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공휴일(holiday), 명절(ntl_holiday) 구분\n",
    "ntl_holiday = holiday_data.loc[holiday_data[\"dateName\"].isin([\"설날\", \"추석\"])]\n",
    "ntl_holiday = ntl_holiday.rename(columns = {\"dateName\" : \"ntl_holi\"})\n",
    "\n",
    "holiday = holiday_data.loc[holiday_data[\"dateName\"].isin([\"설날\", \"추석\"]) == False]\n",
    "holiday = holiday.rename(columns = {\"dateName\" : \"holi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "mexican-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.merge(date_df, ntl_holiday, on = \"date\", how = \"left\")\n",
    "date_df = pd.merge(date_df, holiday, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "ready-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df.assign(ntl_holi = np.where(date_df[\"ntl_holi\"].isna(), \"N\", \"Y\"),\n",
    "                         holi = np.where(date_df[\"holi\"].isna(), \"N\", \"Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-fishing",
   "metadata": {},
   "source": [
    "#### 3일 이상 연휴 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "independent-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df[\"rest_yn\"] = date_df[[\"weekend\", \"ntl_holi\", \"holi\"]].apply(lambda x: any(x == \"Y\"), 1)\n",
    "date_df[\"rest_yn\"] = np.where(date_df[\"rest_yn\"],\"Y\", \"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "ruled-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seq_y(data, criterion = 2):\n",
    "    seq_list = []\n",
    "    Y_cnt = 0\n",
    "    for i, x in enumerate(data):\n",
    "        if x == \"Y\":\n",
    "            Y_cnt += 1\n",
    "\n",
    "        if (x == \"N\") | (i == len(data)):\n",
    "            if Y_cnt > criterion:\n",
    "                temp_list = [\"Y\"] * Y_cnt\n",
    "                seq_list += temp_list\n",
    "            elif (Y_cnt > 0) & (Y_cnt <= criterion):\n",
    "                temp_list = [\"N\"] * Y_cnt\n",
    "                seq_list += temp_list\n",
    "            seq_list.append(\"N\")\n",
    "            Y_cnt = 0\n",
    "            \n",
    "    return seq_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "tired-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df[\"seq_holi\"] = find_seq_y(data = date_df[\"rest_yn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "temporal-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df.drop([\"weekend\", \"rest_yn\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "conservative-quantity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transdate</th>\n",
       "      <th>mybi_stop_id</th>\n",
       "      <th>normalcnt</th>\n",
       "      <th>studentcnt</th>\n",
       "      <th>childcnt</th>\n",
       "      <th>totalcnt</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>totalcnt_bf1d</th>\n",
       "      <th>totalcnt_bf7d</th>\n",
       "      <th>date</th>\n",
       "      <th>totalcnt_bf1d_total</th>\n",
       "      <th>totalcnt_bf7d_total</th>\n",
       "      <th>ntl_holi</th>\n",
       "      <th>holi</th>\n",
       "      <th>seq_holi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-08 00:00:00</td>\n",
       "      <td>3100020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-08 00:00:00</td>\n",
       "      <td>3100021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-08 00:00:00</td>\n",
       "      <td>3100057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-08 00:00:00</td>\n",
       "      <td>3100058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-08 00:00:00</td>\n",
       "      <td>3100085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745123</th>\n",
       "      <td>2020-11-30 23:00:00</td>\n",
       "      <td>3101560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.038095</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745124</th>\n",
       "      <td>2020-11-30 23:00:00</td>\n",
       "      <td>3102261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745125</th>\n",
       "      <td>2020-11-30 23:00:00</td>\n",
       "      <td>3102622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745126</th>\n",
       "      <td>2020-11-30 23:00:00</td>\n",
       "      <td>3102806</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>월</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.036364</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745127</th>\n",
       "      <td>2020-11-30 23:00:00</td>\n",
       "      <td>3103633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>745128 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 transdate  mybi_stop_id  normalcnt  studentcnt  childcnt  \\\n",
       "0      2020-04-08 00:00:00       3100020        0.0         0.0       0.0   \n",
       "1      2020-04-08 00:00:00       3100021        0.0         0.0       0.0   \n",
       "2      2020-04-08 00:00:00       3100057        0.0         0.0       0.0   \n",
       "3      2020-04-08 00:00:00       3100058        0.0         0.0       0.0   \n",
       "4      2020-04-08 00:00:00       3100085        0.0         0.0       0.0   \n",
       "...                    ...           ...        ...         ...       ...   \n",
       "745123 2020-11-30 23:00:00       3101560        0.0         0.0       0.0   \n",
       "745124 2020-11-30 23:00:00       3102261        0.0         0.0       0.0   \n",
       "745125 2020-11-30 23:00:00       3102622        0.0         0.0       0.0   \n",
       "745126 2020-11-30 23:00:00       3102806        2.0         0.0       0.0   \n",
       "745127 2020-11-30 23:00:00       3103633        0.0         0.0       0.0   \n",
       "\n",
       "        totalcnt dayofweek  hour  totalcnt_bf1d  totalcnt_bf7d        date  \\\n",
       "0            0.0         0   0.0            NaN            NaN  2020-04-08   \n",
       "1            0.0         0   0.0            NaN            NaN  2020-04-08   \n",
       "2            0.0         0   0.0            NaN            NaN  2020-04-08   \n",
       "3            0.0         0   0.0            NaN            NaN  2020-04-08   \n",
       "4            0.0         0   0.0            NaN            NaN  2020-04-08   \n",
       "...          ...       ...   ...            ...            ...         ...   \n",
       "745123       0.0         0   0.0            0.0            2.0  2020-11-30   \n",
       "745124       0.0         0   0.0            0.0            0.0  2020-11-30   \n",
       "745125       0.0         0   0.0            0.0            0.0  2020-11-30   \n",
       "745126       2.0         월  23.0            0.0            3.0  2020-11-30   \n",
       "745127       0.0         0   0.0            0.0            0.0  2020-11-30   \n",
       "\n",
       "        totalcnt_bf1d_total  totalcnt_bf7d_total ntl_holi holi seq_holi  \n",
       "0                       NaN                  NaN        N    N        N  \n",
       "1                       NaN                  NaN        N    N        N  \n",
       "2                       NaN                  NaN        N    N        N  \n",
       "3                       NaN                  NaN        N    N        N  \n",
       "4                       NaN                  NaN        N    N        N  \n",
       "...                     ...                  ...      ...  ...      ...  \n",
       "745123                  1.0             1.038095        N    N        N  \n",
       "745124                  NaN             1.000000        N    N        N  \n",
       "745125                  NaN             1.000000        N    N        N  \n",
       "745126                  1.0             1.036364        N    N        N  \n",
       "745127                  NaN                  NaN        N    N        N  \n",
       "\n",
       "[745128 rows x 16 columns]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(ml_data, date_df, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-arlington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "written-specialist",
   "metadata": {},
   "source": [
    "### 날씨 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "regular-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/weather_2018.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "precise-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = weather_data.loc[:, [\"tm\", \"ta\", \"hm\", \"rn\", \"dc10Tca\",  \"dsnw\", \"wd\", \"ws\"]]\n",
    "weather_data = weather_data.rename(columns = {\"tm\" : \"time\",\n",
    "                                              \"ta\" : \"temperature\",\n",
    "                                              \"hm\" : \"humidity\",\n",
    "                                              \"rn\" : \"precipitation\",\n",
    "                                              \"dc10Tca\" : \"전운량\",\n",
    "                                              \"dsnw\" : \"snowfall\",\n",
    "                                              \"wd\" : \"풍향\",\n",
    "                                              \"ws\" : \"풍속\"})\n",
    "weather_data[\"time\"] = pd.to_datetime(weather_data[\"time\"], format = \"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "yellow-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weather_data.columns:\n",
    "    if col == \"time\":\n",
    "        continue\n",
    "    weather_data[col] = weather_data[col].replace(\"\", \"0.0\").astype(float)\n",
    "    weather_data[col] = weather_data[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pursuant-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data[\"time_hours\"] = weather_data[\"time\"].dt.strftime(\"%Y-%m-%d %H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "second-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"transdate_hours\"] = ml_data[\"transdate\"].dt.strftime(\"%Y-%m-%d %H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "active-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, weather_data[[\"time_hours\", \"temperature\", \"humidity\", \"precipitation\", \"snowfall\"]], left_on = \"transdate_hours\", right_on = \"time_hours\")\n",
    "ml_data = ml_data.drop([\"transdate_hours\", \"time_hours\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "early-poultry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(745128, 22)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-clearing",
   "metadata": {},
   "source": [
    "### 미세먼지 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adverse-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_data = pd.read_csv(\"/home/seho/Passenger_Demand/data/pm_data.csv\")\n",
    "pm_data[\"issueDate\"] = pd.to_datetime(pm_data[\"issueDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "southern-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_data_agg = pm_data.loc[pm_data[\"districtName\"] == \"울산\"].groupby(pd.Grouper(key=\"issueDate\", freq=\"1D\")).size().reset_index(name = \"pm_alert_cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fabulous-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"date\"] = ml_data[\"transdate\"].dt.strftime(\"%Y-%m-%d\")\n",
    "pm_data_agg[\"issueDate\"] = pm_data_agg[\"issueDate\"].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "changed-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, pm_data_agg, how = \"left\", left_on = \"date\", right_on = \"issueDate\")\n",
    "ml_data = ml_data.drop([\"date\", \"issueDate\"], 1)\n",
    "ml_data[\"pm_alert_cnt\"] = ml_data[\"pm_alert_cnt\"].fillna(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "associate-petite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transdate</th>\n",
       "      <th>mybi_stop_id</th>\n",
       "      <th>normalcnt</th>\n",
       "      <th>studentcnt</th>\n",
       "      <th>childcnt</th>\n",
       "      <th>totalcnt</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>childcnt_bf1d</th>\n",
       "      <th>totalcnt_bf1w</th>\n",
       "      <th>normalcnt_bf1w</th>\n",
       "      <th>studentcnt_bf1w</th>\n",
       "      <th>childcnt_bf1w</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>pm_alert_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>수</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.8</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>수</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.8</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>수</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.8</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>수</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.8</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3100085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>수</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.8</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   transdate  mybi_stop_id  normalcnt  studentcnt  childcnt  totalcnt  \\\n",
       "0 2020-04-08       3100020        0.0         0.0       0.0       0.0   \n",
       "1 2020-04-08       3100021        0.0         0.0       0.0       0.0   \n",
       "2 2020-04-08       3100057        0.0         0.0       0.0       0.0   \n",
       "3 2020-04-08       3100058        0.0         0.0       0.0       0.0   \n",
       "4 2020-04-08       3100085        0.0         0.0       0.0       0.0   \n",
       "\n",
       "  dayofweek  day  month  hour  ...  childcnt_bf1d  totalcnt_bf1w  \\\n",
       "0         수    8      4     0  ...            NaN            NaN   \n",
       "1         수    8      4     0  ...            NaN            NaN   \n",
       "2         수    8      4     0  ...            NaN            NaN   \n",
       "3         수    8      4     0  ...            NaN            NaN   \n",
       "4         수    8      4     0  ...            NaN            NaN   \n",
       "\n",
       "   normalcnt_bf1w  studentcnt_bf1w  childcnt_bf1w  temperature  humidity  \\\n",
       "0             NaN              NaN            NaN         12.8      47.0   \n",
       "1             NaN              NaN            NaN         12.8      47.0   \n",
       "2             NaN              NaN            NaN         12.8      47.0   \n",
       "3             NaN              NaN            NaN         12.8      47.0   \n",
       "4             NaN              NaN            NaN         12.8      47.0   \n",
       "\n",
       "   precipitation  snowfall  pm_alert_cnt  \n",
       "0            0.0       0.0             0  \n",
       "1            0.0       0.0             0  \n",
       "2            0.0       0.0             0  \n",
       "3            0.0       0.0             0  \n",
       "4            0.0       0.0             0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-contamination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-ceramic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "short-nelson",
   "metadata": {},
   "source": [
    "### 정류장 X,Y 좌표 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "offensive-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경주시, 양산시, 울산광역시, 부산광역시\n",
    "bus_stop_info = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_버스 정류소 위치 정보_20200531.csv\", encoding = \"euc-kr\")\n",
    "bus_stop_info = bus_stop_info.loc[bus_stop_info[\"권역\"] == \"울산광역시\"]\n",
    "bus_stop_info.columns = [\"stop_nm\", \"stop_id\", \"longitude\", \"latitude\", \"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "artistic-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_1 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_율리_꽃바위.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401_2 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_꽃바위_율리.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401 = pd.concat([bus_stop_401_1, bus_stop_401_2])\n",
    "bus_stop_401.columns = [\"mybi_stop_id\", \"stop_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "animated-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_info = pd.merge(bus_stop_401, bus_stop_info, on = \"stop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-linux",
   "metadata": {},
   "source": [
    "### 상권정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "another-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_area = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_상권정보_201231.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "instrumental-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = trading_area[\"상권업종중분류명\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "surprised-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(latlon1, latlon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1 = map(radians, latlon1)\n",
    "    lat2, lon2 = map(radians, latlon2)\n",
    "#     lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def count_store_nearby(data, trading_area = trading_area, dist = 0.1, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = trading_area[\"상권업종중분류명\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = trading_area[[\"위도\", \"경도\"]].apply(lambda x: haversine((x[\"위도\"], x[\"경도\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = trading_area.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"store_category_{i}\"] = (within_data[\"상권업종중분류명\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "athletic-august",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'자동차/이륜차'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_list[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "amateur-wheel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:09<00:00,  1.17it/s]\n",
      " 91%|█████████ | 10/11 [00:08<00:00,  1.02it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.05it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.02it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.01it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.04it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.02it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.00it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.04it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.04it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 s, sys: 765 ms, total: 18.3 s\n",
      "Wall time: 27.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                           func = count_store_nearby, \n",
    "                                           num_cores = 12, \n",
    "                                           trading_area = trading_area, \n",
    "                                           dist = 0.2, \n",
    "                                           category_list = category_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-housing",
   "metadata": {},
   "source": [
    "### 병원정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "whole-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/hospital_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "returning-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_data[\"category\"] = hospital_data[\"의료기관종별\"].replace({\"한방병원\" : \"병원\",\n",
    "                                                                  \"치과병원\" : \"병원\",\n",
    "                                                                  \"일반요양병원\" : \"요양병원\",\n",
    "                                                                  \"부속의원\" : \"의원\",\n",
    "                                                                  \"치과의원\" : \"의원\",\n",
    "                                                                  \"한의원\" : \"의원\",\n",
    "                                                                  \"보건지소\" : \"보건소\",\n",
    "                                                                  \"보건진료소\" : \"보건소\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "brief-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>의료기관명</th>\n",
       "      <th>의료기관종별</th>\n",
       "      <th>의료기관주소(도로명)</th>\n",
       "      <th>lat_lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>의료법인 정안의료재단 중앙병원</td>\n",
       "      <td>종합병원</td>\n",
       "      <td>울산광역시 남구 문수로480번길 10 (신정동)</td>\n",
       "      <td>{'lat': 35.5315233, 'lng': 129.3052032}</td>\n",
       "      <td>35.531523</td>\n",
       "      <td>129.305203</td>\n",
       "      <td>종합병원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>의료법인 은성의료재단 좋은삼정병원</td>\n",
       "      <td>종합병원</td>\n",
       "      <td>울산광역시 남구 북부순환도로 51 (무거동)</td>\n",
       "      <td>{'lat': 35.5528284, 'lng': 129.2690588}</td>\n",
       "      <td>35.552828</td>\n",
       "      <td>129.269059</td>\n",
       "      <td>종합병원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>의료법인혜명심의료재단 울산병원</td>\n",
       "      <td>종합병원</td>\n",
       "      <td>울산광역시 남구 월평로171번길 13 (신정동)</td>\n",
       "      <td>{'lat': 35.546209, 'lng': 129.3230784}</td>\n",
       "      <td>35.546209</td>\n",
       "      <td>129.323078</td>\n",
       "      <td>종합병원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>학교법인 울산공업학원 울산대학교병원</td>\n",
       "      <td>종합병원</td>\n",
       "      <td>울산광역시 동구 방어진순환도로 877, 울산대학교병원 (전하동)</td>\n",
       "      <td>{'lat': 35.5199931, 'lng': 129.4289601}</td>\n",
       "      <td>35.519993</td>\n",
       "      <td>129.428960</td>\n",
       "      <td>종합병원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>의료법인 송은의료재단 울산시티병원</td>\n",
       "      <td>종합병원</td>\n",
       "      <td>울산광역시 북구 산업로 1007(연암동)</td>\n",
       "      <td>{'lat': 35.5810679, 'lng': 129.3623813}</td>\n",
       "      <td>35.581068</td>\n",
       "      <td>129.362381</td>\n",
       "      <td>종합병원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 의료기관명 의료기관종별                          의료기관주소(도로명)  \\\n",
       "0     의료법인 정안의료재단 중앙병원   종합병원           울산광역시 남구 문수로480번길 10 (신정동)   \n",
       "1   의료법인 은성의료재단 좋은삼정병원   종합병원             울산광역시 남구 북부순환도로 51 (무거동)   \n",
       "2     의료법인혜명심의료재단 울산병원   종합병원           울산광역시 남구 월평로171번길 13 (신정동)   \n",
       "3  학교법인 울산공업학원 울산대학교병원   종합병원  울산광역시 동구 방어진순환도로 877, 울산대학교병원 (전하동)   \n",
       "4   의료법인 송은의료재단 울산시티병원   종합병원               울산광역시 북구 산업로 1007(연암동)   \n",
       "\n",
       "                                   lat_lng        lat         lng category  \n",
       "0  {'lat': 35.5315233, 'lng': 129.3052032}  35.531523  129.305203     종합병원  \n",
       "1  {'lat': 35.5528284, 'lng': 129.2690588}  35.552828  129.269059     종합병원  \n",
       "2   {'lat': 35.546209, 'lng': 129.3230784}  35.546209  129.323078     종합병원  \n",
       "3  {'lat': 35.5199931, 'lng': 129.4289601}  35.519993  129.428960     종합병원  \n",
       "4  {'lat': 35.5810679, 'lng': 129.3623813}  35.581068  129.362381     종합병원  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospital_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "essential-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_category_list = hospital_data[\"category\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "pregnant-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'의원'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospital_category_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "parliamentary-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hospital_nearby(data, hospital_data = hospital_data, dist = 0.2, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = hospital_data[\"category\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = hospital_data[[\"lat\", \"lng\"]].apply(lambda x: haversine((x[\"lat\"], x[\"lng\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = hospital_data.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"hospital_category_{i}\"] = (within_data[\"category\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "manufactured-stable",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s].76it/s]]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.53it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.39it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24.12it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.95it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.49it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.10it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.25it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.54it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.48it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 658 ms, sys: 455 ms, total: 1.11 s\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                           func = count_hospital_nearby, \n",
    "                                           num_cores = 12, \n",
    "                                           hospital_data = hospital_data, \n",
    "                                           dist = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-hammer",
   "metadata": {},
   "source": [
    "### 학교정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "circular-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = pd.read_excel(\"/home/seho/Passenger_Demand/data/gv_school.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "established-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"표준일차명\"] = school_data[\"표준일차명\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bizarre-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = school_data.loc[school_data[\"표준일차명\"].str.contains(\"울산\", na=\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ranging-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eight-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "persistent-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geocode(x, gmaps):\n",
    "    try:\n",
    "        result = gmaps.geocode(x)[0][\"geometry\"][\"location\"]\n",
    "        # result = [temp[\"lat\"], temp[\"lng\"]]\n",
    "    except:\n",
    "        result = None\n",
    "    \n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dental-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"category\"] = school_data[\"학교종류\"].replace({\"전문대학(3년제)\" : \"전문대학\",\n",
    "                                                          \"사내대학(전문)\" : \"전문대학\",\n",
    "                                                          \"기능대학\" : \"전문대학\",\n",
    "                                                          \"일반대학원\" : \"대학원\",\n",
    "                                                          \"전문대학원\" : \"대학원\",\n",
    "                                                          \"특수대학원\" : \"대학원\",\n",
    "                                                          \"일반고등학교\" : \"고등학교\",\n",
    "                                                          \"공업고등학교\" : \"고등학교\",\n",
    "                                                          \"상업고등학교\" : \"고등학교\",\n",
    "                                                          \"가사고등학교\" : \"고등학교\",\n",
    "                                                          \"체육고등학교\" : \"고등학교\",\n",
    "                                                          \"외국어고등학교\" : \"고등학교\",\n",
    "                                                          \"과학고등학교\" : \"고등학교\",\n",
    "                                                          \"예술고등학교\" : \"고등학교\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "current-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"lat_lng\"] = school_data[\"새주소\"].apply(get_geocode, gmaps = gmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "adequate-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"lat\"] = school_data[\"lat_lng\"].apply(lambda x: x[\"lat\"])\n",
    "school_data[\"lng\"] = school_data[\"lat_lng\"].apply(lambda x: x[\"lng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "offensive-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_school_nearby(data, school_data = school_data, dist = 0.2, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = school_data[\"category\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = school_data[[\"lat\", \"lng\"]].apply(lambda x: haversine((x[\"lat\"], x[\"lng\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = school_data.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"school_category_{i}\"] = (within_data[\"category\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "crucial-account",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 90.13it/s]]\n",
      "100%|██████████| 11/11 [00:00<00:00, 85.72it/s] \n",
      "100%|██████████| 11/11 [00:00<00:00, 85.85it/s] \n",
      "100%|██████████| 11/11 [00:00<00:00, 93.12it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 92.27it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 79.33it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 75.62it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 70.70it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 73.95it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 81.71it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 82.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 295 ms, sys: 423 ms, total: 718 ms\n",
      "Wall time: 777 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                              func = count_school_nearby, \n",
    "                                              num_cores = 12, \n",
    "                                              school_data = school_data, \n",
    "                                              dist = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "prime-analyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mybi_stop_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_nm</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>city</th>\n",
       "      <th>store_category_0</th>\n",
       "      <th>store_category_1</th>\n",
       "      <th>store_category_2</th>\n",
       "      <th>store_category_3</th>\n",
       "      <th>...</th>\n",
       "      <th>hospital_category_2</th>\n",
       "      <th>hospital_category_3</th>\n",
       "      <th>hospital_category_4</th>\n",
       "      <th>hospital_category_5</th>\n",
       "      <th>school_category_0</th>\n",
       "      <th>school_category_1</th>\n",
       "      <th>school_category_2</th>\n",
       "      <th>school_category_3</th>\n",
       "      <th>school_category_4</th>\n",
       "      <th>school_category_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3100597</td>\n",
       "      <td>30504</td>\n",
       "      <td>율리공영차고지</td>\n",
       "      <td>129.246863</td>\n",
       "      <td>35.529520</td>\n",
       "      <td>울산광역시</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3100339</td>\n",
       "      <td>30714</td>\n",
       "      <td>우신고등학교입구</td>\n",
       "      <td>129.255322</td>\n",
       "      <td>35.537435</td>\n",
       "      <td>울산광역시</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3101462</td>\n",
       "      <td>30712</td>\n",
       "      <td>울산과학대학앞</td>\n",
       "      <td>129.257440</td>\n",
       "      <td>35.539800</td>\n",
       "      <td>울산광역시</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3101461</td>\n",
       "      <td>30708</td>\n",
       "      <td>울산대학교앞</td>\n",
       "      <td>129.260306</td>\n",
       "      <td>35.543755</td>\n",
       "      <td>울산광역시</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3100479</td>\n",
       "      <td>30706</td>\n",
       "      <td>울산대학교후문</td>\n",
       "      <td>129.261981</td>\n",
       "      <td>35.546813</td>\n",
       "      <td>울산광역시</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mybi_stop_id  stop_id   stop_nm   longitude   latitude   city  \\\n",
       "0       3100597    30504   율리공영차고지  129.246863  35.529520  울산광역시   \n",
       "1       3100339    30714  우신고등학교입구  129.255322  35.537435  울산광역시   \n",
       "2       3101462    30712   울산과학대학앞  129.257440  35.539800  울산광역시   \n",
       "3       3101461    30708    울산대학교앞  129.260306  35.543755  울산광역시   \n",
       "4       3100479    30706   울산대학교후문  129.261981  35.546813  울산광역시   \n",
       "\n",
       "   store_category_0  store_category_1  store_category_2  store_category_3  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 2                 0                10   \n",
       "2                 3                 6                 0                27   \n",
       "3                 6                 3                 0                42   \n",
       "4                 5                 7                 0                14   \n",
       "\n",
       "   ...  hospital_category_2  hospital_category_3  hospital_category_4  \\\n",
       "0  ...                    0                    0                    0   \n",
       "1  ...                    0                    0                    0   \n",
       "2  ...                    0                    1                    0   \n",
       "3  ...                    0                    1                    1   \n",
       "4  ...                    2                   27                    4   \n",
       "\n",
       "   hospital_category_5  school_category_0  school_category_1  \\\n",
       "0                    0                  0                  0   \n",
       "1                    0                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    0                  0                  0   \n",
       "4                    0                  0                  0   \n",
       "\n",
       "   school_category_2  school_category_3  school_category_4  school_category_5  \n",
       "0                  0                  0                  0                  0  \n",
       "1                  0                  0                  1                  0  \n",
       "2                  0                  1                  1                  0  \n",
       "3                  0                  0                  0                  0  \n",
       "4                  0                  0                  0                  0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_stop_401_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-verification",
   "metadata": {},
   "source": [
    "### 정류장 정보 Join(거리기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "champion-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, bus_stop_401_info.drop([\"stop_id\", \"city\"],1), on = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bound-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = ml_data_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "saved-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_temp = ml_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-butter",
   "metadata": {},
   "source": [
    "### 울산행사정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "clean-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = pd.read_csv(\"~/Passenger_Demand/data/ulsan_event_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "collectible-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data[\"eventStartDate\"] = pd.to_datetime(event_data[\"eventStartDate\"], format = \"%Y-%m-%d\")\n",
    "event_data[\"eventEndDate\"] = pd.to_datetime(event_data[\"eventEndDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "atomic-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_event_nearby(data, event_data, dist = 0.2):\n",
    "    data_copy = data.copy()\n",
    "    within_data = event_data.loc[(event_data[\"eventStartDate\"] <= data_copy[\"transdate\"]) & (event_data[\"eventEndDate\"] >= data_copy[\"transdate\"])]\n",
    "    \n",
    "    if len(within_data) == 0:\n",
    "        data_copy[f\"event_nearby\"] = 0\n",
    "    else:\n",
    "        dist_list = within_data[[\"latitude\", \"longitude\"]].apply(lambda x: haversine((x[\"latitude\"], x[\"longitude\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "        data_copy[f\"event_nearby\"] = (dist_list <= dist).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "quarterly-vision",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62094/62094 [04:19<00:00, 238.93it/s]\n",
      "100%|██████████| 62094/62094 [04:21<00:00, 237.88it/s]\n",
      "100%|██████████| 62094/62094 [04:24<00:00, 234.87it/s]\n",
      "100%|██████████| 62094/62094 [04:28<00:00, 231.39it/s]\n",
      "100%|██████████| 62094/62094 [04:26<00:00, 232.86it/s]\n",
      "100%|██████████| 62094/62094 [04:26<00:00, 233.08it/s]\n",
      "100%|██████████| 62094/62094 [04:28<00:00, 231.14it/s]\n",
      "100%|██████████| 62094/62094 [04:27<00:00, 232.42it/s]\n",
      "100%|██████████| 62094/62094 [04:28<00:00, 231.34it/s]\n",
      "100%|██████████| 62094/62094 [04:29<00:00, 230.59it/s]\n",
      "100%|██████████| 62094/62094 [04:28<00:00, 230.86it/s]\n",
      "100%|██████████| 62094/62094 [04:29<00:00, 230.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 13 s, total: 27.5 s\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = parallelize_dataframe(df = ml_data, \n",
    "                                func = count_event_nearby, \n",
    "                                num_cores = 12, \n",
    "                                event_data = event_data, \n",
    "                                dist = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-definition",
   "metadata": {},
   "source": [
    "### 축제 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dried-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data = pd.read_csv(\"~/Passenger_Demand/data/festival_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "normal-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data[\"fstvlStartDate\"] = pd.to_datetime(festival_data[\"fstvlStartDate\"], format = \"%Y-%m-%d\")\n",
    "festival_data[\"fstvlEndDate\"] = pd.to_datetime(festival_data[\"fstvlEndDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "unique-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_festival_nearby(data, festival_data, dist = 0.2):\n",
    "    data_copy = data.copy()\n",
    "    within_data = festival_data.loc[(festival_data[\"fstvlStartDate\"] <= data_copy[\"transdate\"]) & (festival_data[\"fstvlEndDate\"] >= data_copy[\"transdate\"])]\n",
    "    \n",
    "    if len(within_data) == 0:\n",
    "        data_copy[f\"festival_nearby\"] = 0\n",
    "    else:\n",
    "        dist_list = within_data[[\"latitude\", \"longitude\"]].apply(lambda x: haversine((x[\"latitude\"], x[\"longitude\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "        data_copy[f\"festival_nearby\"] = (dist_list <= dist).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "competitive-pearl",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62094/62094 [01:50<00:00, 564.10it/s]\n",
      "100%|██████████| 62094/62094 [01:51<00:00, 557.63it/s]\n",
      "100%|██████████| 62094/62094 [01:51<00:00, 559.08it/s]\n",
      "100%|██████████| 62094/62094 [01:50<00:00, 561.15it/s]\n",
      "100%|██████████| 62094/62094 [01:50<00:00, 560.48it/s]\n",
      "100%|██████████| 62094/62094 [01:50<00:00, 563.29it/s]\n",
      "100%|██████████| 62094/62094 [01:50<00:00, 564.37it/s]\n",
      "100%|██████████| 62094/62094 [01:51<00:00, 555.30it/s]\n",
      "100%|██████████| 62094/62094 [01:49<00:00, 564.95it/s]\n",
      "100%|██████████| 62094/62094 [01:51<00:00, 558.95it/s]\n",
      "100%|██████████| 62094/62094 [01:49<00:00, 565.03it/s]\n",
      "100%|██████████| 62094/62094 [01:50<00:00, 563.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.65 s, sys: 6.27 s, total: 14.9 s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = parallelize_dataframe(df = ml_data, \n",
    "                                func = count_festival_nearby, \n",
    "                                num_cores = 12, \n",
    "                                festival_data = festival_data, \n",
    "                                dist = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-bacon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "romance-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.to_pickle(\"/home/seho/Passenger_Demand/data/ml_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "individual-negotiation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowTypeError",
     "evalue": "(\"Expected bytes, got a 'float' object\", 'Conversion failed for column pm_alert_cnt with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-b09b7810587f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mml_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/seho/Passenger_Demand/data/ml_data.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2453\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2455\u001b[0;31m         return to_parquet(\n\u001b[0m\u001b[1;32m   2456\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFilePathOrBuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m     impl.write(\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mfrom_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"preserve_index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfrom_pandas_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_fut\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_fut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_fut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mconvert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    572\u001b[0m             e.args += (\"Conversion failed for column {!s} with type {!s}\"\n\u001b[1;32m    573\u001b[0m                        .format(col.name, col.dtype),)\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfield_nullable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnull_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             raise ValueError(\"Field {} was non-nullable but pandas column \"\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mconvert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         except (pa.ArrowInvalid,\n\u001b[1;32m    570\u001b[0m                 \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrowNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: (\"Expected bytes, got a 'float' object\", 'Conversion failed for column pm_alert_cnt with type object')"
     ]
    }
   ],
   "source": [
    "ml_data.to_parquet(\"/home/seho/Passenger_Demand/data/ml_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "helpful-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>childcnt</th>\n",
       "      <th>childcnt_bf1d</th>\n",
       "      <th>childcnt_bf1w</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>event_nearby</th>\n",
       "      <th>festival_nearby</th>\n",
       "      <th>hospital_category_0</th>\n",
       "      <th>hospital_category_1</th>\n",
       "      <th>...</th>\n",
       "      <th>store_category_89</th>\n",
       "      <th>store_category_9</th>\n",
       "      <th>studentcnt</th>\n",
       "      <th>studentcnt_bf1d</th>\n",
       "      <th>studentcnt_bf1w</th>\n",
       "      <th>temperature</th>\n",
       "      <th>totalcnt</th>\n",
       "      <th>totalcnt_bf1d</th>\n",
       "      <th>totalcnt_bf1w</th>\n",
       "      <th>transdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  childcnt  childcnt_bf1d  childcnt_bf1w  day dayofweek  event_nearby  \\\n",
       "0  0       NaN            NaN            NaN  NaN       NaN           NaN   \n",
       "1  0       NaN            NaN            NaN  NaN       NaN           NaN   \n",
       "2  0       NaN            NaN            NaN  NaN       NaN           NaN   \n",
       "3  0       NaN            NaN            NaN  NaN       NaN           NaN   \n",
       "4  0       NaN            NaN            NaN  NaN       NaN           NaN   \n",
       "\n",
       "   festival_nearby  hospital_category_0  hospital_category_1  ...  \\\n",
       "0              NaN                  NaN                  NaN  ...   \n",
       "1              NaN                  NaN                  NaN  ...   \n",
       "2              NaN                  NaN                  NaN  ...   \n",
       "3              NaN                  NaN                  NaN  ...   \n",
       "4              NaN                  NaN                  NaN  ...   \n",
       "\n",
       "   store_category_89  store_category_9  studentcnt  studentcnt_bf1d  \\\n",
       "0                NaN               NaN         NaN              NaN   \n",
       "1                NaN               NaN         NaN              NaN   \n",
       "2                NaN               NaN         NaN              NaN   \n",
       "3                NaN               NaN         NaN              NaN   \n",
       "4                NaN               NaN         NaN              NaN   \n",
       "\n",
       "   studentcnt_bf1w  temperature  totalcnt  totalcnt_bf1d  totalcnt_bf1w  \\\n",
       "0              NaN          NaN       NaN            NaN            NaN   \n",
       "1              NaN          NaN       NaN            NaN            NaN   \n",
       "2              NaN          NaN       NaN            NaN            NaN   \n",
       "3              NaN          NaN       NaN            NaN            NaN   \n",
       "4              NaN          NaN       NaN            NaN            NaN   \n",
       "\n",
       "   transdate  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "overall-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = ml_data.drop([\"event_nearby\", \"festival_nearby\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-visitor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lonely-mobile",
   "metadata": {},
   "source": [
    "### 인구 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "demographic-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = pd.read_csv(\"~/Passenger_Demand/data/울산광역시_인구 현황_20200727.csv\", encoding = \"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "copyrighted-christopher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>행정구역코드</th>\n",
       "      <th>행정구역명</th>\n",
       "      <th>행정구역레벨</th>\n",
       "      <th>성별</th>\n",
       "      <th>총 이동 전입</th>\n",
       "      <th>총 이동 전출</th>\n",
       "      <th>시군구내 전입</th>\n",
       "      <th>시군구내 전출</th>\n",
       "      <th>시군구간 전입</th>\n",
       "      <th>시군구간 전출</th>\n",
       "      <th>시도간 전입</th>\n",
       "      <th>시도간 전출</th>\n",
       "      <th>순이동</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>울산광역시</td>\n",
       "      <td>시도</td>\n",
       "      <td>남자</td>\n",
       "      <td>74934</td>\n",
       "      <td>80048</td>\n",
       "      <td>25926</td>\n",
       "      <td>25926</td>\n",
       "      <td>26968</td>\n",
       "      <td>26968</td>\n",
       "      <td>22040</td>\n",
       "      <td>27154</td>\n",
       "      <td>-5114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>울산광역시</td>\n",
       "      <td>시도</td>\n",
       "      <td>여자</td>\n",
       "      <td>67122</td>\n",
       "      <td>72180</td>\n",
       "      <td>24209</td>\n",
       "      <td>24209</td>\n",
       "      <td>24880</td>\n",
       "      <td>24880</td>\n",
       "      <td>18033</td>\n",
       "      <td>23091</td>\n",
       "      <td>-5058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31110</td>\n",
       "      <td>울산광역시 중구</td>\n",
       "      <td>시군구</td>\n",
       "      <td>남자</td>\n",
       "      <td>12119</td>\n",
       "      <td>16494</td>\n",
       "      <td>4273</td>\n",
       "      <td>4273</td>\n",
       "      <td>4624</td>\n",
       "      <td>7674</td>\n",
       "      <td>3222</td>\n",
       "      <td>4547</td>\n",
       "      <td>-4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31110</td>\n",
       "      <td>울산광역시 중구</td>\n",
       "      <td>시군구</td>\n",
       "      <td>여자</td>\n",
       "      <td>11358</td>\n",
       "      <td>15454</td>\n",
       "      <td>4202</td>\n",
       "      <td>4202</td>\n",
       "      <td>4393</td>\n",
       "      <td>7272</td>\n",
       "      <td>2763</td>\n",
       "      <td>3980</td>\n",
       "      <td>-4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31140</td>\n",
       "      <td>울산광역시 남구</td>\n",
       "      <td>시군구</td>\n",
       "      <td>남자</td>\n",
       "      <td>21038</td>\n",
       "      <td>24659</td>\n",
       "      <td>8500</td>\n",
       "      <td>8500</td>\n",
       "      <td>6361</td>\n",
       "      <td>8356</td>\n",
       "      <td>6177</td>\n",
       "      <td>7803</td>\n",
       "      <td>-3621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   행정구역코드     행정구역명 행정구역레벨  성별  총 이동 전입  총 이동 전출  시군구내 전입  시군구내 전출  시군구간 전입  \\\n",
       "0      31     울산광역시     시도  남자    74934    80048    25926    25926    26968   \n",
       "1      31     울산광역시     시도  여자    67122    72180    24209    24209    24880   \n",
       "2   31110  울산광역시 중구    시군구  남자    12119    16494     4273     4273     4624   \n",
       "3   31110  울산광역시 중구    시군구  여자    11358    15454     4202     4202     4393   \n",
       "4   31140  울산광역시 남구    시군구  남자    21038    24659     8500     8500     6361   \n",
       "\n",
       "   시군구간 전출  시도간 전입  시도간 전출   순이동  \n",
       "0    26968   22040   27154 -5114  \n",
       "1    24880   18033   23091 -5058  \n",
       "2     7674    3222    4547 -4375  \n",
       "3     7272    2763    3980 -4096  \n",
       "4     8356    6177    7803 -3621  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-secretary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
