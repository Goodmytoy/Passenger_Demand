{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thirty-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Ulsan_Event_Data_by_API import * \n",
    "from utils.Festival_Data_by_API import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-blues",
   "metadata": {},
   "source": [
    "### 울산시 행사 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "illegal-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "serviceKey = \"eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "recorded-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict1 = {\"serviceKey\" : serviceKey,\n",
    "                \"pageNo\" : 1,\n",
    "                \"numOfRows\" : 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entire-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "ulsan_event_api = Ulsan_Event_Data_by_API(params_dict = params_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "superior-tissue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows : 1000, total_count : 312, max_page = 1\n"
     ]
    }
   ],
   "source": [
    "ulsan_event_data = ulsan_event_api.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "phantom-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "ulsan_event_data.to_csv(\"/home/seho/Passenger_Demand/data/ulsan_event_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-omaha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eastern-chicago",
   "metadata": {},
   "source": [
    "### 전국 행사 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceramic-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import ast\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Data_by_API(object):\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.features = None\n",
    "        self.main_key = None\n",
    "#         self.serviceKey = serviceKey\n",
    "    \n",
    "    \n",
    "    def calculate_max_page(self, type = \"json\"):\n",
    "        rq = self.request()\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = rq.text, type = type)\n",
    "        \n",
    "        self.n_rows = int(self.params_dict[\"numOfRows\"])\n",
    "        \n",
    "        try:\n",
    "            self.total_count = int(rq_dict[\"response\"][\"body\"][\"totalCount\"])\n",
    "        except:\n",
    "            xmlsoup = BeautifulSoup(rq.text,'html.parser')\n",
    "            self.total_count = int(xmlsoup.find(\"totalcount\").text)\n",
    "                \n",
    "        max_page = int(np.ceil(self.total_count / self.n_rows))\n",
    "        \n",
    "        print(f\"n_rows : {self.n_rows}, total_count : {self.total_count}, max_page = {max_page}\")\n",
    "        \n",
    "        return max_page\n",
    "    \n",
    "    \n",
    "    def create_request_url(self, params_dict):\n",
    "#         params_dict[\"service_key\"] = self.serviceKey\n",
    "        params_list = [f\"{k}={v}\" for k, v in params_dict.items()]\n",
    "        params_str = \"&\".join(params_list)\n",
    "#         print(params_str)\n",
    "        \n",
    "        request_url = self.url + params_str\n",
    "        \n",
    "        return request_url\n",
    "    \n",
    "    \n",
    "    def create_request_urls(self):\n",
    "        max_page = self.calculate_max_page(type = self.type)\n",
    "        \n",
    "        params_dict = self.params_dict.copy()\n",
    "        \n",
    "        request_urls= []\n",
    "        for i in range(max_page):\n",
    "            params_dict[\"pageNo\"] = i + 1\n",
    "            request_urls.append(self.create_request_url(params_dict = params_dict))\n",
    "            \n",
    "        return request_urls\n",
    "    \n",
    "    \n",
    "    def to_dict(self, txt, type):\n",
    "        # json / xml to dict\n",
    "        if type == \"json\":\n",
    "            rq_dict = ast.literal_eval(txt)\n",
    "        elif type == \"xml\":\n",
    "            rq_dict = xmltodict.parse(txt)\n",
    "            \n",
    "        return rq_dict\n",
    "    \n",
    "    \n",
    "    def extract_values_from_dict(self, dct):\n",
    "        try: \n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"][\"item\"]\n",
    "        except:\n",
    "            dict_list = dct[\"response\"][\"body\"][\"items\"]\n",
    "            \n",
    "        return dict_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    def parse(self, rq, features = None, type = \"json\"):\n",
    "        \n",
    "        data_dict = defaultdict(list)\n",
    "        \n",
    "        rq_dict = self.to_dict(txt = rq.text, type = type)\n",
    "\n",
    "        # 일부 url의 경우는 item이 아닌 items에 값이 존재\n",
    "        dict_list = self.extract_values_from_dict(dct = rq_dict)\n",
    "        \n",
    "        # 값이 1개인 경우 list가 아니라 dictionary 1개가 반환되므로, 이를 list(dict)형태로 변환\n",
    "        if isinstance(dict_list, dict):\n",
    "            dict_list = [dict_list]\n",
    "        \n",
    "        # item이 없는 경우 빈 Dictionary(data dict)를 반환\n",
    "        if dict_list is None:\n",
    "            return data_dict\n",
    "        \n",
    "        if features is None:\n",
    "            features = dict_list[0].keys()\n",
    "            \n",
    "        for x in dict_list:\n",
    "            for col in features:\n",
    "                data_dict[col].append(x.get(col))\n",
    "\n",
    "        return data_dict\n",
    "    \n",
    "    \n",
    "    def request(self, request_url = None):\n",
    "        \n",
    "        if request_url == None:\n",
    "            request_url = self.request_url\n",
    "            \n",
    "        rq = requests.get(request_url, allow_redirects = True)\n",
    "        \n",
    "        return rq\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occupational-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "class Event_Data_by_API(Data_by_API):\n",
    "    \n",
    "    base_url = \"http://api.data.go.kr/openapi/tn_pubr_public_pblprfr_event_info_api?\" # JSON , XML\n",
    "    \n",
    "    def __init__(self, params_dict):\n",
    "        super().__init__(url = self.base_url)\n",
    "        self.request_url = super().create_request_url(params_dict = params_dict)\n",
    "        self.params_dict = params_dict\n",
    "        self.type = params_dict.get(\"type\").lower()\n",
    "              \n",
    "    \n",
    "    def get(self):\n",
    "        \n",
    "        self.request_urls = self.create_request_urls()\n",
    "        \n",
    "        data_dict = defaultdict(list)\n",
    "        for i, request_url in enumerate(self.request_urls):\n",
    "            rq = self.request(request_url = request_url)\n",
    "            temp_dict = self.parse(rq = rq, features = None, type = self.type)\n",
    "            \n",
    "            for k, v in temp_dict.items():\n",
    "                data_dict[k].extend(v)\n",
    "            \n",
    "        return pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selective-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "serviceKey = \"eLWdQyzctRdtv8bEOuewsTtK6sNkoWp1bE74OUBk43jg4tU6AsI6yYt6Z%2B7sOeaqtB5pTH2yHuPRIuEHtu5amQ%3D%3D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "primary-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict1 = {\"serviceKey\" : serviceKey,\n",
    "                \"pageNo\" : 1,\n",
    "                \"numOfRows\" : 1000,\n",
    "                \"type\" : \"json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "approved-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_api = Event_Data_by_API(params_dict = params_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geological-transparency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows : 1000, total_count : 6396, max_page = 7\n"
     ]
    }
   ],
   "source": [
    "temp2 = event_api.get() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-fishing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-cricket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-fields",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "single-forge",
   "metadata": {},
   "source": [
    "### 전국 축제 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "african-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict2 = {\"serviceKey\" : serviceKey,\n",
    "                \"pageNo\" : 1,\n",
    "                \"numOfRows\" : 1000,\n",
    "                \"type\" : \"json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desperate-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_api = Festival_Data_by_API(params_dict = params_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "linear-terrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows : 1000, total_count : 1027, max_page = 2\n"
     ]
    }
   ],
   "source": [
    "festival_data = festival_api.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polish-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data[\"fstvlStartDate\"] = pd.to_datetime(festival_data[\"fstvlStartDate\"], format = \"%Y-%m-%d\")\n",
    "festival_data[\"fstvlEndDate\"] = pd.to_datetime(festival_data[\"fstvlEndDate\"], format = \"%Y-%m-%d\")\n",
    "festival_data[\"referenceDate\"] = pd.to_datetime(festival_data[\"referenceDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "regulated-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data = festival_data.loc[(festival_data[\"fstvlStartDate\"].dt.year == 2020) & (festival_data[\"rdnmadr\"].str.contains(\"울산\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sunset-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data.to_csv(\"/home/seho/Passenger_Demand/data/festival_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
