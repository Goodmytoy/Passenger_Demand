{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rotary-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organizational-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Parallelize_DataFrame import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "environmental-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-feeling",
   "metadata": {},
   "source": [
    "### 마이비 카드 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informative-cooler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 11.1 s, total: 36.1 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mybicard = pd.read_parquet('/home/seho/Passenger_Demand/data/mybicard.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abstract-savage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36261767, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liked-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집일자 데이트 포맷으로 변환\n",
    "#mybicard[\"collectdate\"] = pd.to_datetime(mybicard[\"collectdate\"], format = \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "discrete-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전송일자 데이트 포맷으로 변환\n",
    "mybicard[\"transdate\"] = pd.to_datetime(mybicard[\"transdate\"], format = \"%Y%m%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "micro-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 승객 수 변수 생성(일반 + 학생 + 아동)\n",
    "mybicard[\"totalcnt\"] = mybicard[[\"normalcnt\", \"studentcnt\", \"childcnt\"]].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "higher-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_nm에 공백이 포함되어 있어 공백 제거\n",
    "mybicard[\"route_nm\"] = mybicard[\"route_nm\"].replace(\"\\s\", \"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fatty-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ;mybicard = mybicard.sort_values([\"transdate\", \"seq\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spanish-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard = mybicard.rename(columns = {\"stop_id\" : \"mybi_stop_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-integer",
   "metadata": {},
   "source": [
    "### 401번 버스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "original-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401 = mybicard.loc[(mybicard[\"route_nm\"] == \"401\") & (mybicard[\"transflag\"].isin([\"환승\", \"비환승\"])), [\"route_nm\", \"transdate\", \"mybi_stop_id\", \"normalcnt\", \"studentcnt\", \"childcnt\", \"totalcnt\"]].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "leading-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1964401, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "special-madison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770869, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-quest",
   "metadata": {},
   "source": [
    "### 정류장 X,Y 좌표 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "differential-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경주시, 양산시, 울산광역시, 부산광역시\n",
    "bus_stop_info = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_버스 정류소 위치 정보_20200531.csv\", encoding = \"euc-kr\")\n",
    "bus_stop_info = bus_stop_info.loc[bus_stop_info[\"권역\"] == \"울산광역시\"]\n",
    "bus_stop_info.columns = [\"stop_nm\", \"stop_id\", \"longitude\", \"latitude\", \"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ancient-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_1 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_율리_꽃바위.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401_2 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_꽃바위_율리.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401 = pd.concat([bus_stop_401_1, bus_stop_401_2])\n",
    "bus_stop_401.columns = [\"mybi_stop_id\", \"stop_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "handed-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_info = pd.merge(bus_stop_401, bus_stop_info, on = \"stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "reserved-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401 = pd.merge(mybicard_401, bus_stop_401_info[[\"mybi_stop_id\", \"stop_id\", \"stop_nm\", \"longitude\", \"latitude\"]], on = \"mybi_stop_id\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fitting-service",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mybicard_401 = mybicard_401.drop([\"mybi_stop_id\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "handy-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401 = mybicard_401.loc[mybicard_401[\"transdate\"].dt.hour.isin([1,2,3,4]) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "prepared-modeling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770869, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "elegant-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg = (mybicard_401.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='60Min')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "civic-violence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mybi_stop_id</th>\n",
       "      <th>transdate</th>\n",
       "      <th>normalcnt</th>\n",
       "      <th>studentcnt</th>\n",
       "      <th>childcnt</th>\n",
       "      <th>totalcnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 08:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 10:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 11:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3100020</td>\n",
       "      <td>2020-04-08 12:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314857</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-25 08:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314858</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-25 17:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314859</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-25 21:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314860</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-26 18:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314861</th>\n",
       "      <td>3103633</td>\n",
       "      <td>2020-11-28 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314862 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mybi_stop_id           transdate  normalcnt  studentcnt  childcnt  \\\n",
       "0            3100020 2020-04-08 06:00:00          2           0         0   \n",
       "1            3100020 2020-04-08 08:00:00          7           0         0   \n",
       "2            3100020 2020-04-08 10:00:00          2           0         0   \n",
       "3            3100020 2020-04-08 11:00:00          2           0         0   \n",
       "4            3100020 2020-04-08 12:00:00          1           0         0   \n",
       "...              ...                 ...        ...         ...       ...   \n",
       "314857       3103633 2020-11-25 08:00:00          6           0         0   \n",
       "314858       3103633 2020-11-25 17:00:00          1           0         0   \n",
       "314859       3103633 2020-11-25 21:00:00          2           2         0   \n",
       "314860       3103633 2020-11-26 18:00:00          1           0         0   \n",
       "314861       3103633 2020-11-28 10:00:00          1           0         0   \n",
       "\n",
       "        totalcnt  \n",
       "0              2  \n",
       "1              7  \n",
       "2              2  \n",
       "3              2  \n",
       "4              1  \n",
       "...          ...  \n",
       "314857         6  \n",
       "314858         1  \n",
       "314859         4  \n",
       "314860         1  \n",
       "314861         1  \n",
       "\n",
       "[314862 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "injured-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314862, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybicard_401_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "developed-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg.to_parquet(\"/home/seho/Passenger_Demand/data/mybicard_401_agg.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-saint",
   "metadata": {},
   "source": [
    "### 결측치 \n",
    "하루의 수집 데이터의 수가 0인 날짜의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "suffering-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_data(data, date_col, stop_id_col, target_cols):\n",
    "    \n",
    "    if isinstance(target_cols, list) == False:\n",
    "        target_cols = [target_cols]\n",
    "    \n",
    "    # 1시간 단위로 Target 변수들을 집계\n",
    "    agg_dict = {col:sum for col in target_cols}\n",
    "    data_agg = (data.groupby([stop_id_col, pd.Grouper(key=date_col, freq='60Min')])\n",
    "                    .agg(agg_dict)\n",
    "                    .reset_index())\n",
    "    \n",
    "    return data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adolescent-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = create_base_data(mybicard_401, date_col = \"transdate\", stop_id_col = \"stop_id\", target_cols = [\"totalcnt\", \"normalcnt\", \"studentcnt\", \"childcnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "obvious-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(data, date_col):\n",
    "    \n",
    "    # 시간 변수들 생성\n",
    "    # 요일\n",
    "    data[\"dayofweek\"] = data[date_col].dt.dayofweek\n",
    "    dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "    data[\"dayofweek\"] = data[\"dayofweek\"].replace(dow_dict)\n",
    "    \n",
    "    # 시간\n",
    "    data[\"hour\"] = data[date_col].dt.hour\n",
    "    \n",
    "    # 월\n",
    "    data[\"month\"] = data[date_col].dt.month\n",
    "    \n",
    "    # 주\n",
    "    data[\"weekofyear\"] = data[date_col].dt.isocalendar().week\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "studied-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_date(data, date_col, stop_id_col, except_hours = None):\n",
    "    \n",
    "    if isinstance(except_hours, list) == False:\n",
    "        except_hours = [except_hours]\n",
    "        \n",
    "    # 정류장별 모든 시간대의 조합을 생성해 버스 집계 데이터를 Join\n",
    "    # 데이터가 존재하지 않는 시간대 : NA -> 이후 Impute\n",
    "    \n",
    "    # 데이터의 시작과 끝 사이를 1시간 간격으로 구분하여 list 생성\n",
    "    dt_list = pd.date_range(start = data[date_col].min(), end = data[date_col].max(), freq = \"1h\")\n",
    "    date_df = pd.DataFrame({date_col : dt_list}).reset_index(drop = True)\n",
    "    stop_id_df = pd.DataFrame({stop_id_col : data[stop_id_col].drop_duplicates()}).reset_index(drop = True)\n",
    "\n",
    "    # 전체 일정(시간 단위)과 정류소 별 조합 DF 생성\n",
    "    all_date = pd.merge(date_df, stop_id_df, how = \"cross\")\n",
    "    \n",
    "    # 결측일의 데이터를 채워넣은 전체 데이터를 left join\n",
    "    all_date = pd.merge(all_date, data, on = [date_col, stop_id_col], how = \"left\")\n",
    "    \n",
    "    all_date = all_date.loc[all_date[date_col].dt.hour.isin(except_hours) == False]\n",
    "    \n",
    "    return all_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "constant-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_date = create_all_date(data = base_data, date_col = \"transdate\", stop_id_col = \"stop_id\", except_hours=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "clinical-adapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(563300, 6)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_date.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "leading-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_date = add_time_features(data = all_date, date_col = \"transdate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "favorite-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_bus_demand_data(data, date_col, stop_id_col):\n",
    "    # 일 단위 집계 -> 데이터가 존재하지 않는 일은 결측일로 판단 (missing_date)\n",
    "    count_by_date = data.groupby([pd.Grouper(key=date_col, freq=\"1D\")]).size().reset_index(name = \"cnt\")\n",
    "    missing_date = count_by_date.loc[count_by_date[\"cnt\"] == 0, date_col]\n",
    "    \n",
    "    # 1) 결측일을 제외한 결측치(데이터가 존재하지 않는 시간대)는 승객이 0명 이므로 0으로 대체\n",
    "    data = data.loc[data[date_col].dt.date.isin(missing_date.dt.date) == False].fillna(0)\n",
    "    \n",
    "    # 2) 최근 n주의 같은 요일 같은 시간대의 평균값으로 Impute\n",
    "    data = impute_recent_mean_data(data = data, missing_date = missing_date, date_col = \"transdate\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_bus_demand_data(data = all_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "honey-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_date = mybicard_401_agg.groupby([pd.Grouper(key=\"transdate\", freq=\"1D\")]).size().reset_index(name = \"cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "derived-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_date = count_by_date.loc[count_by_date[\"cnt\"] == 0, \"transdate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-jerusalem",
   "metadata": {},
   "source": [
    "#### 결측일을 제외한 결측치(특정 시간에 데이터가 없는 경우)는 승객이 0이므로 0으로 대체한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "minor-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 시작과 끝 사이를 1시간 간격으로 구분하여 list 생성\n",
    "dt_list = pd.date_range(start = mybicard_401_agg[\"transdate\"].min(), end = mybicard_401_agg[\"transdate\"].max(), freq = \"1h\")\n",
    "\n",
    "transdate_df = pd.DataFrame({\"transdate\" : dt_list}).reset_index(drop = True)\n",
    "mybi_stop_id_df = pd.DataFrame({\"mybi_stop_id\" : mybicard_401_agg[\"mybi_stop_id\"].drop_duplicates()}).reset_index(drop = True)\n",
    "\n",
    "# 전체 일정(시간 단위)과 정류소 별 조합 DF 생성\n",
    "all_date = pd.merge(transdate_df, mybi_stop_id_df, how = \"cross\")\n",
    "\n",
    "# 결측일의 데이터를 채워넣은 전체 데이터를 left join\n",
    "ml_data = pd.merge(all_date, mybicard_401_agg, on = [\"mybi_stop_id\", \"transdate\"], how = \"left\")\n",
    "\n",
    "ml_data[\"dayofweek\"] = ml_data[\"transdate\"].dt.dayofweek\n",
    "dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "ml_data[\"dayofweek\"] = ml_data[\"dayofweek\"].replace(dow_dict)\n",
    "ml_data[\"hour\"] = ml_data[\"transdate\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cognitive-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측일이 아닌 결측값은 승객수가 없다고 판단하여 0으로 대체\n",
    "ml_data = ml_data.loc[ml_data[\"transdate\"].dt.date.isin(missing_date.dt.date) == False].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "loaded-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차량을 운행하지 않는 1, 2, 3, 4 시간대 제외\n",
    "ml_data = ml_data.loc[ml_data[\"hour\"].isin([1,2,3,4]) == False ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-roads",
   "metadata": {},
   "source": [
    "#### n주 전 같은 요일 같은 시간대의 인원 수로 Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "built-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_recent_data(data, missing_date, date_col = \"transdate\"):\n",
    "    data = data.copy()\n",
    "    for x in missing_date:\n",
    "        temp = []\n",
    "        w = 0\n",
    "        while len(temp) == 0:\n",
    "            w +=1\n",
    "            temp = data.loc[data[date_col].dt.date == (x - timedelta(weeks = w)).date()].copy()\n",
    "\n",
    "        temp[date_col] = temp[date_col] + timedelta(weeks = w)\n",
    "        data = pd.concat([data, temp], 0)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-novelty",
   "metadata": {},
   "source": [
    "#### 최근 n주의 같은 요일 같은 시간대의 평균값으로 Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "collected-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_recent_mean_data(data, missing_date, date_col):\n",
    "\n",
    "    data = data.copy()\n",
    "\n",
    "    # 요일, 시간 추가\n",
    "    data[\"dayofweek\"] = data[\"transdate\"].dt.dayofweek\n",
    "    dow_dict = {0:\"월\", 1:\"화\", 2:\"수\", 3:\"목\", 4:\"금\", 5:\"토\", 6:\"일\"}\n",
    "    data[\"dayofweek\"] = data[\"dayofweek\"].replace(dow_dict)\n",
    "    data[\"hour\"] = data[\"transdate\"].dt.hour\n",
    "         \n",
    "    \n",
    "    for x in missing_date:\n",
    "        base_date = x\n",
    "        w = 0\n",
    "        # 결측일의 이전 4주를 기본으로 검색하며, 데이터가 없는 경우 범위를 1주씩 늘려가며 데이터 조회\n",
    "        temp = []\n",
    "        while len(temp) == 0:\n",
    "            temp = data.loc[(data[\"transdate\"].dt.date.between((x - timedelta(weeks = 4+w)).date(), x.date())) & (data[\"transdate\"].dt.dayofweek == x.day_of_week)].copy()\n",
    "            w += 1\n",
    "\n",
    "        # 4+w 전까지의 데이터를 찾아서 정류장별, 요일별, 시간별 평균값 산출\n",
    "        temp2 = temp.groupby([\"mybi_stop_id\", \"dayofweek\", \"hour\"]).agg({\"totalcnt\" : np.mean,\n",
    "                                                                         \"normalcnt\" : np.mean,\n",
    "                                                                         \"studentcnt\" : np.mean,\n",
    "                                                                         \"childcnt\" : np.mean}).reset_index()\n",
    "        # 평균값 변환 (Float -> Int : 반올림 효과)\n",
    "        temp2[\"totalcnt\"] = temp2[\"totalcnt\"].astype(int)\n",
    "        temp2[\"normalcnt\"] = temp2[\"normalcnt\"].astype(int)\n",
    "        temp2[\"studentcnt\"] = temp2[\"studentcnt\"].astype(int)\n",
    "        temp2[\"childcnt\"] = temp2[\"childcnt\"].astype(int)\n",
    "\n",
    "        # 기준 일자, 시간으로 부터 transdate을 재생성\n",
    "        temp2[\"transdate\"] = temp2.apply(lambda x: base_date + timedelta(hours = x[\"hour\"]), 1)\n",
    "\n",
    "        data = pd.concat([data, temp2], 0)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "enabling-homeless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.51 s, sys: 0 ns, total: 7.51 s\n",
      "Wall time: 7.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = impute_recent_mean_data(data = ml_data, missing_date = missing_date, date_col = \"transdate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "excellent-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-hudson",
   "metadata": {},
   "source": [
    "### 시계열 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "advisory-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_feature(data, target_cols, date_cols, lags, groupby_cols = None):\n",
    "    data = data.copy()\n",
    "    if isinstance(lags, list) == False:\n",
    "        lags = [lags]\n",
    "    if isinstance(date_cols, list) == False:\n",
    "        date_cols = [date_cols]\n",
    "    if isinstance(target_cols, list) == False:\n",
    "        target_cols = [target_cols]\n",
    "    if isinstance(groupby_cols, list) == False:\n",
    "        groupby_cols = [groupby_cols]\n",
    "    \n",
    "    for lg in lags:\n",
    "        if groupby_cols is None:\n",
    "            cnt_bf = data.set_index(date_cols)[target_cols].shift(freq = lg).reset_index()\n",
    "        else:\n",
    "            cnt_bf = data.set_index(date_cols).groupby(groupby_cols)[target_cols].shift(freq = lg).reset_index()\n",
    "        \n",
    "        rename_dict = {col: f\"{col}_bf{lg}\" for col in target_cols}\n",
    "        cnt_bf = cnt_bf.rename(columns = rename_dict)\n",
    "        \n",
    "        data = pd.merge(data, cnt_bf, on = date_cols + groupby_cols, how = \"left\")\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "failing-switch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 0 ns, total: 1.35 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = create_lag_feature(data = ml_data, target_cols = \"totalcnt\", date_cols = \"transdate\", lags = [\"1d\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\"], groupby_cols = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "liked-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 15)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-journey",
   "metadata": {},
   "source": [
    "### 날짜별 평균 Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "descending-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_daily = (ml_data.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\", np.mean), \n",
    "                                        studentcnt = (\"studentcnt\", np.mean), \n",
    "                                        childcnt = (\"childcnt\", np.mean),\n",
    "                                        totalcnt = (\"totalcnt\", np.mean))\n",
    "                                   .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "representative-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lag = create_lag_feature(data = mybicard_401_agg_daily, target_cols = \"totalcnt\", date_cols = \"transdate\", lags = [\"1d\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\"], groupby_cols = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "positive-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [\"1d\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\"]\n",
    "rename_dict = {f\"{col}_bf{lg}\": f\"{col}_bf{lg}_total\" for col in [\"totalcnt\"] for lg in lags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "considered-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lag = daily_lag.rename(columns = rename_dict)\n",
    "daily_lag[\"date\"] = daily_lag[\"transdate\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acting-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"date\"] = ml_data[\"transdate\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "italian-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_lag[[\"date\", \"mybi_stop_id\"] + list(rename_dict.values())], on = [\"date\", \"mybi_stop_id\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "enormous-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 23)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-archive",
   "metadata": {},
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-assistant",
   "metadata": {},
   "source": [
    "#### 1) 이전 n개일자들의 동일 시간대 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "pressing-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_agg(data, target_cols, date_col, groupby_cols, col_nm = \"\", rollings = [\"2d\"], agg_func = [np.mean, np.std]):\n",
    "    if isinstance(target_cols, list) == False:\n",
    "        target_cols = [target_cols]\n",
    "        \n",
    "    if isinstance(groupby_cols, list) == False:\n",
    "        groupby_cols = [groupby_cols]\n",
    "        \n",
    "    if col_nm != \"\":\n",
    "        col_nm = f\"{col_nm}_\"\n",
    "    \n",
    "    \n",
    "    for rl in rollings:\n",
    "        for tg in target_cols:\n",
    "            data = data.set_index(date_col).sort_index(ascending=True).copy()\n",
    "            rolling_data = data.groupby(groupby_cols)[tg].rolling(rl).agg(agg_func)\n",
    "            rolling_data = rolling_data.rename(columns = {\"mean\" : f\"{tg}_ma_{col_nm}mean_{rl}\", \n",
    "                                                          \"std\" : f\"{tg}_ma_{col_nm}std_{rl}\"})\n",
    "            rolling_data = rolling_data.groupby(groupby_cols).shift(1).reset_index()    \n",
    "            \n",
    "            data = pd.merge(data.reset_index(), rolling_data, on = [date_col] + groupby_cols, how = \"left\")\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beginning-methodology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 0 ns, total: 2.89 s\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = calculate_moving_agg(data = ml_data, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\", \"hour\"], col_nm = \"hour\", rollings = [\"2d\", \"3d\", \"4d\", \"5d\", \"6d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "classical-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 33)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-scratch",
   "metadata": {},
   "source": [
    "#### 2) n주전까지의 동일 요일의 동일 시간대 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unauthorized-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.6 s, sys: 0 ns, total: 3.6 s\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = calculate_moving_agg(data = ml_data, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\", \"hour\", \"dayofweek\"], col_nm = \"hour_week\", rollings = [\"14d\", \"21d\", \"28d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "exclusive-earth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 39)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-aspect",
   "metadata": {},
   "source": [
    "#### 3) 이전 n개일자들의 전체 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "enabling-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_1d = (ml_data.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())\n",
    "\n",
    "mybicard_401_agg_1d[\"dayofweek\"] = mybicard_401_agg_1d[\"transdate\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fitting-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 ms, sys: 0 ns, total: 118 ms\n",
      "Wall time: 122 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "daily_agg = calculate_moving_agg(data = mybicard_401_agg_1d, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\"], col_nm = \"daily\", rollings = [\"2d\", \"3d\", \"4d\", \"5d\", \"6d\"])\n",
    "daily_agg[\"date\"] = daily_agg[\"transdate\"].dt.date\n",
    "daily_agg = daily_agg.drop([\"transdate\", \"normalcnt\", \"studentcnt\", \"childcnt\", \"totalcnt\", \"dayofweek\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "perfect-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_agg, on = [\"mybi_stop_id\", \"date\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "unexpected-hayes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 49)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-hierarchy",
   "metadata": {},
   "source": [
    "#### 4) n주전까지의 동일 요일의 전체 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "equipped-verse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 143 ms, sys: 0 ns, total: 143 ms\n",
      "Wall time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "daily_week_agg = calculate_moving_agg(data = mybicard_401_agg_1d, target_cols = [\"totalcnt\"], date_col = \"transdate\", groupby_cols = [\"mybi_stop_id\", \"dayofweek\"], col_nm = \"daily_week\", rollings = [\"14d\", \"21d\", \"28d\"])\n",
    "daily_week_agg[\"date\"] = daily_week_agg[\"transdate\"].dt.date\n",
    "daily_week_agg = daily_week_agg.drop([\"transdate\", \"normalcnt\", \"studentcnt\", \"childcnt\", \"totalcnt\", \"dayofweek\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "curious-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, daily_week_agg, on = [\"mybi_stop_id\", \"date\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "chinese-mileage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 55)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-keeping",
   "metadata": {},
   "source": [
    "#### 5) n주전까지의 주 평균의 이동평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "necessary-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_1d = (ml_data.groupby([\"mybi_stop_id\", pd.Grouper(key=\"transdate\", freq='1d')])\n",
    "                                   .agg(normalcnt = (\"normalcnt\",sum), \n",
    "                                        studentcnt = (\"studentcnt\", sum), \n",
    "                                        childcnt = (\"childcnt\", sum),\n",
    "                                        totalcnt = (\"totalcnt\", sum))\n",
    "                                   .reset_index())\n",
    "mybicard_401_agg_1d[\"hour\"] = mybicard_401_agg_1d[\"transdate\"].dt.hour\n",
    "mybicard_401_agg_1d[\"weekofyear\"] = mybicard_401_agg_1d[\"transdate\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fiscal-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybicard_401_agg_1w = mybicard_401_agg_1d.groupby([\"mybi_stop_id\", \"weekofyear\"])[\"totalcnt\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "abroad-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_agg = calculate_moving_agg(data = mybicard_401_agg_1w, target_cols = [\"totalcnt\"], date_col = \"weekofyear\", groupby_cols = [\"mybi_stop_id\"], col_nm = \"weekly\", rollings = [2,3,4])\n",
    "weekly_agg = weekly_agg.drop(\"totalcnt\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cellular-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"weekofyear\"] = ml_data[\"transdate\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "secure-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, weekly_agg, on = [\"mybi_stop_id\", \"weekofyear\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "deluxe-majority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 62)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 62)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-integration",
   "metadata": {},
   "source": [
    "### 특일 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "operational-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/holiday_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "vocal-crazy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holiday_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "structural-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data[\"date\"] = pd.to_datetime(holiday_data[\"locdate\"], format = \"%Y%m%d\").dt.date\n",
    "holiday_data = holiday_data.drop([\"locdate\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "capable-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.DataFrame({\"date\" : pd.date_range(\"2020-01-01\", \"2020-12-31\", freq = \"1D\")})\n",
    "date_df[\"weekend\"] = np.where(date_df[\"date\"].dt.dayofweek.isin([5,6]), \"Y\", \"N\")\n",
    "date_df[\"date\"] = date_df[\"date\"].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-visibility",
   "metadata": {},
   "source": [
    "#### 공휴일 / 명절 여부 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "judicial-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공휴일(holiday), 명절(ntl_holiday) 구분\n",
    "ntl_holiday = holiday_data.loc[holiday_data[\"dateName\"].isin([\"설날\", \"추석\"])]\n",
    "ntl_holiday = ntl_holiday.rename(columns = {\"dateName\" : \"ntl_holi\"})\n",
    "\n",
    "holiday = holiday_data.loc[holiday_data[\"dateName\"].isin([\"설날\", \"추석\"]) == False]\n",
    "holiday = holiday.rename(columns = {\"dateName\" : \"holi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "closing-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.merge(date_df, ntl_holiday, on = \"date\", how = \"left\")\n",
    "date_df = pd.merge(date_df, holiday, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fuzzy-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df.assign(ntl_holi = np.where(date_df[\"ntl_holi\"].isna(), \"N\", \"Y\"),\n",
    "                         holi = np.where(date_df[\"holi\"].isna(), \"N\", \"Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-jewelry",
   "metadata": {},
   "source": [
    "#### 3일 이상 연휴 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "vital-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df[\"rest_yn\"] = date_df[[\"weekend\", \"ntl_holi\", \"holi\"]].apply(lambda x: any(x == \"Y\"), 1)\n",
    "date_df[\"rest_yn\"] = np.where(date_df[\"rest_yn\"],\"Y\", \"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "periodic-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seq_y(data, criterion = 2):\n",
    "    seq_list = []\n",
    "    Y_cnt = 0\n",
    "    for i, x in enumerate(data):\n",
    "        if x == \"Y\":\n",
    "            Y_cnt += 1\n",
    "\n",
    "        if (x == \"N\") | (i == len(data)):\n",
    "            if Y_cnt > criterion:\n",
    "                temp_list = [\"Y\"] * Y_cnt\n",
    "                seq_list += temp_list\n",
    "            elif (Y_cnt > 0) & (Y_cnt <= criterion):\n",
    "                temp_list = [\"N\"] * Y_cnt\n",
    "                seq_list += temp_list\n",
    "            seq_list.append(\"N\")\n",
    "            Y_cnt = 0\n",
    "            \n",
    "    return seq_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "premium-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df[\"seq_holi\"] = find_seq_y(data = date_df[\"rest_yn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "manufactured-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df.drop([\"weekend\", \"rest_yn\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aggregate-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, date_df, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "express-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 65)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-worker",
   "metadata": {},
   "source": [
    "### 날씨 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "proprietary-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/weather_2018.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "resident-cornwall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8064, 38)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "undefined-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = weather_data.loc[:, [\"tm\", \"ta\", \"hm\", \"rn\", \"dc10Tca\",  \"dsnw\", \"wd\", \"ws\"]]\n",
    "weather_data = weather_data.rename(columns = {\"tm\" : \"time\",\n",
    "                                              \"ta\" : \"temperature\",\n",
    "                                              \"hm\" : \"humidity\",\n",
    "                                              \"rn\" : \"precipitation\",\n",
    "                                              \"dc10Tca\" : \"전운량\",\n",
    "                                              \"dsnw\" : \"snowfall\",\n",
    "                                              \"wd\" : \"풍향\",\n",
    "                                              \"ws\" : \"풍속\"})\n",
    "weather_data[\"time\"] = pd.to_datetime(weather_data[\"time\"], format = \"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "formal-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weather_data.columns:\n",
    "    if col == \"time\":\n",
    "        continue\n",
    "    weather_data[col] = weather_data[col].replace(\"\", \"0.0\").astype(float)\n",
    "    weather_data[col] = weather_data[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "smaller-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data[\"time_hours\"] = weather_data[\"time\"].dt.strftime(\"%Y-%m-%d %H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "floppy-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"transdate_hours\"] = ml_data[\"transdate\"].dt.strftime(\"%Y-%m-%d %H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "narrow-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, weather_data[[\"time_hours\", \"temperature\", \"humidity\", \"precipitation\", \"snowfall\"]], left_on = \"transdate_hours\", right_on = \"time_hours\")\n",
    "ml_data = ml_data.drop([\"transdate_hours\", \"time_hours\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aboriginal-alignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 69)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 69)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-profile",
   "metadata": {},
   "source": [
    "### 미세먼지 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "legendary-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_data = pd.read_csv(\"/home/seho/Passenger_Demand/data/pm_data.csv\")\n",
    "pm_data[\"issueDate\"] = pd.to_datetime(pm_data[\"issueDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "optimum-blond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clearVal</th>\n",
       "      <th>sn</th>\n",
       "      <th>districtName</th>\n",
       "      <th>dataDate</th>\n",
       "      <th>issueVal</th>\n",
       "      <th>issueTime</th>\n",
       "      <th>clearDate</th>\n",
       "      <th>issueDate</th>\n",
       "      <th>moveName</th>\n",
       "      <th>clearTime</th>\n",
       "      <th>issueGbn</th>\n",
       "      <th>itemCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>322</td>\n",
       "      <td>세종</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>80</td>\n",
       "      <td>12:00</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>세종권역</td>\n",
       "      <td>19:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>323</td>\n",
       "      <td>충북</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>77</td>\n",
       "      <td>13:00</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>중부권역</td>\n",
       "      <td>19:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>320</td>\n",
       "      <td>대구</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>83</td>\n",
       "      <td>14:00</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>대구권역</td>\n",
       "      <td>16:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>321</td>\n",
       "      <td>충남</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>76</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>북부권역</td>\n",
       "      <td>22:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>316</td>\n",
       "      <td>경남</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>84</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>함안권역</td>\n",
       "      <td>15:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>충남</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>85</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>북부권역</td>\n",
       "      <td>15:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>전북</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>77</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>장수권역</td>\n",
       "      <td>14:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>전북</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>80</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>익산권역</td>\n",
       "      <td>15:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>302</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>경기</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>82</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>남부권</td>\n",
       "      <td>17:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>303</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>전북</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>81</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>전주권역</td>\n",
       "      <td>14:00</td>\n",
       "      <td>주의보</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  clearVal   sn districtName    dataDate  issueVal issueTime  \\\n",
       "0             0        33  322           세종  2020-12-29        80     12:00   \n",
       "1             1        33  323           충북  2020-12-29        77     13:00   \n",
       "2             2        34  320           대구  2020-12-28        83     14:00   \n",
       "3             3        28  321           충남  2020-12-28        76     21:00   \n",
       "4             4        30  316           경남  2020-12-24        84     11:00   \n",
       "..          ...       ...  ...          ...         ...       ...       ...   \n",
       "299         299        31    3           충남  2020-01-03        85     11:00   \n",
       "300         300        29    6           전북  2020-01-03        77     00:00   \n",
       "301         301        19    1           전북  2020-01-03        80     02:00   \n",
       "302         302        33    2           경기  2020-01-03        82     11:00   \n",
       "303         303        34    5           전북  2020-01-03        81     22:00   \n",
       "\n",
       "      clearDate  issueDate moveName clearTime issueGbn itemCode  \n",
       "0    2020-12-29 2020-12-29     세종권역     19:00      주의보     PM25  \n",
       "1    2020-12-29 2020-12-29     중부권역     19:00      주의보     PM25  \n",
       "2    2020-12-28 2020-12-28     대구권역     16:00      주의보     PM25  \n",
       "3    2020-12-29 2020-12-28     북부권역     22:00      주의보     PM25  \n",
       "4    2020-12-24 2020-12-24     함안권역     15:00      주의보     PM25  \n",
       "..          ...        ...      ...       ...      ...      ...  \n",
       "299  2020-01-05 2020-01-03     북부권역     15:00      주의보     PM25  \n",
       "300  2020-01-04 2020-01-04     장수권역     14:00      주의보     PM25  \n",
       "301  2020-01-05 2020-01-03     익산권역     15:00      주의보     PM25  \n",
       "302  2020-01-04 2020-01-03      남부권     17:00      주의보     PM25  \n",
       "303  2020-01-05 2020-01-03     전주권역     14:00      주의보     PM25  \n",
       "\n",
       "[304 rows x 13 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "medical-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_data_agg = pm_data.loc[pm_data[\"districtName\"] == \"울산\"].groupby(pd.Grouper(key=\"issueDate\", freq=\"1D\")).size().reset_index(name = \"pm_alert_cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acute-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data[\"date\"] = ml_data[\"transdate\"].dt.strftime(\"%Y-%m-%d\")\n",
    "pm_data_agg[\"issueDate\"] = pm_data_agg[\"issueDate\"].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "possible-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, pm_data_agg, how = \"left\", left_on = \"date\", right_on = \"issueDate\")\n",
    "ml_data = ml_data.drop([\"issueDate\"], 1)\n",
    "ml_data[\"pm_alert_cnt\"] = ml_data[\"pm_alert_cnt\"].fillna(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "logical-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 70)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-aquarium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-train",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "meaning-forum",
   "metadata": {},
   "source": [
    "### 정류장 X,Y 좌표 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "owned-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경주시, 양산시, 울산광역시, 부산광역시\n",
    "bus_stop_info = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_버스 정류소 위치 정보_20200531.csv\", encoding = \"euc-kr\")\n",
    "bus_stop_info = bus_stop_info.loc[bus_stop_info[\"권역\"] == \"울산광역시\"]\n",
    "bus_stop_info.columns = [\"stop_nm\", \"stop_id\", \"longitude\", \"latitude\", \"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "subject-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_1 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_율리_꽃바위.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401_2 = pd.read_csv(\"/home/seho/Passenger_Demand/data/401_꽃바위_율리.csv\", encoding = \"euc_kr\")\n",
    "bus_stop_401 = pd.concat([bus_stop_401_1, bus_stop_401_2])\n",
    "bus_stop_401.columns = [\"mybi_stop_id\", \"stop_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bigger-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_401_info = pd.merge(bus_stop_401, bus_stop_info, on = \"stop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-distinction",
   "metadata": {},
   "source": [
    "### 상권정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "speaking-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_area = pd.read_csv(\"/home/seho/Passenger_Demand/data/울산광역시_상권정보_201231.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "round-science",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52188, 39)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_area.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "changing-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = trading_area[\"상권업종중분류명\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "approved-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(latlon1, latlon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1 = map(radians, latlon1)\n",
    "    lat2, lon2 = map(radians, latlon2)\n",
    "#     lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def count_store_nearby(data, trading_area = trading_area, dist = 0.1, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = trading_area[\"상권업종중분류명\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = trading_area[[\"위도\", \"경도\"]].apply(lambda x: haversine((x[\"위도\"], x[\"경도\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = trading_area.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"store_category_{i}\"] = (within_data[\"상권업종중분류명\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "governing-oriental",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.12it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.10it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.13it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 s, sys: 0 ns, total: 19.4 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                           func = count_store_nearby, \n",
    "                                           num_cores = 12, \n",
    "                                           trading_area = trading_area, \n",
    "                                           dist = 0.2, \n",
    "                                           category_list = category_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-plaza",
   "metadata": {},
   "source": [
    "### 병원정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hawaiian-parts",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3eb9f93f00ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhospital_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/seho/Passenger_Demand/data/hospital_data.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "hospital_data = pd.read_parquet(\"/home/seho/Passenger_Demand/data/hospital_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "every-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_data.to_csv(\"hospital_data.csv\", encoding = \"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-huntington",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hospital_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b23a326438ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhospital_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hospital_data' is not defined"
     ]
    }
   ],
   "source": [
    "hospital_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "organized-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_data[\"category\"] = hospital_data[\"의료기관종별\"].replace({\"한방병원\" : \"병원\",\n",
    "                                                                  \"치과병원\" : \"병원\",\n",
    "                                                                  \"일반요양병원\" : \"요양병원\",\n",
    "                                                                  \"부속의원\" : \"의원\",\n",
    "                                                                  \"치과의원\" : \"의원\",\n",
    "                                                                  \"한의원\" : \"의원\",\n",
    "                                                                  \"보건지소\" : \"보건소\",\n",
    "                                                                  \"보건진료소\" : \"보건소\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "brutal-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_category_list = hospital_data[\"category\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "athletic-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hospital_nearby(data, hospital_data = hospital_data, dist = 0.2, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = hospital_data[\"category\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = hospital_data[[\"lat\", \"lng\"]].apply(lambda x: haversine((x[\"lat\"], x[\"lng\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = hospital_data.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"hospital_category_{i}\"] = (within_data[\"category\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "enormous-purple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 23.78it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24.00it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.93it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.80it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.79it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.66it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.19it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.41it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23.66it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22.36it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24.53it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.07 s, sys: 0 ns, total: 1.07 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                           func = count_hospital_nearby, \n",
    "                                           num_cores = 12, \n",
    "                                           hospital_data = hospital_data, \n",
    "                                           dist = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-project",
   "metadata": {},
   "source": [
    "### 학교정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "european-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "integral-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = pd.read_excel(\"/home/seho/Passenger_Demand/data/gv_school.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "democratic-accused",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12883, 35)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "partial-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"표준일차명\"] = school_data[\"표준일차명\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "partial-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = school_data.loc[school_data[\"표준일차명\"].str.contains(\"울산\", na=\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "permanent-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "joined-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "upper-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geocode(x, gmaps):\n",
    "    try:\n",
    "        result = gmaps.geocode(x)[0][\"geometry\"][\"location\"]\n",
    "        # result = [temp[\"lat\"], temp[\"lng\"]]\n",
    "    except:\n",
    "        result = None\n",
    "    \n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "reported-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"category\"] = school_data[\"학교종류\"].replace({\"전문대학(3년제)\" : \"전문대학\",\n",
    "                                                          \"사내대학(전문)\" : \"전문대학\",\n",
    "                                                          \"기능대학\" : \"전문대학\",\n",
    "                                                          \"일반대학원\" : \"대학원\",\n",
    "                                                          \"전문대학원\" : \"대학원\",\n",
    "                                                          \"특수대학원\" : \"대학원\",\n",
    "                                                          \"일반고등학교\" : \"고등학교\",\n",
    "                                                          \"공업고등학교\" : \"고등학교\",\n",
    "                                                          \"상업고등학교\" : \"고등학교\",\n",
    "                                                          \"가사고등학교\" : \"고등학교\",\n",
    "                                                          \"체육고등학교\" : \"고등학교\",\n",
    "                                                          \"외국어고등학교\" : \"고등학교\",\n",
    "                                                          \"과학고등학교\" : \"고등학교\",\n",
    "                                                          \"예술고등학교\" : \"고등학교\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gothic-trout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 499 ms, sys: 12.6 ms, total: 512 ms\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "school_data[\"lat_lng\"] = school_data[\"새주소\"].apply(get_geocode, gmaps = gmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regional-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data[\"latitude\"] = school_data[\"lat_lng\"].apply(lambda x: x[\"lat\"])\n",
    "school_data[\"longitude\"] = school_data[\"lat_lng\"].apply(lambda x: x[\"lng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ranking-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data.to_csv(\"/home/seho/Passenger_Demand/data/school_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "binary-kentucky",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연번</th>\n",
       "      <th>학교종류</th>\n",
       "      <th>학교명</th>\n",
       "      <th>학교명(영문)</th>\n",
       "      <th>본분교</th>\n",
       "      <th>학교상태</th>\n",
       "      <th>설립</th>\n",
       "      <th>남여공학</th>\n",
       "      <th>전화번호</th>\n",
       "      <th>팩스번호</th>\n",
       "      <th>...</th>\n",
       "      <th>우편번호</th>\n",
       "      <th>UTM-K_X좌표</th>\n",
       "      <th>UTM-K_Y좌표</th>\n",
       "      <th>WGS84_X좌표</th>\n",
       "      <th>WGS84_Y좌표</th>\n",
       "      <th>TM60_X좌표</th>\n",
       "      <th>TM60_Y좌표</th>\n",
       "      <th>lat_lng</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21</td>\n",
       "      <td>전문대학(3년제)</td>\n",
       "      <td>울산과학대학교</td>\n",
       "      <td>ULSAN COLLEGE</td>\n",
       "      <td>본교</td>\n",
       "      <td>기존</td>\n",
       "      <td>사립</td>\n",
       "      <td>NaN</td>\n",
       "      <td>052-230-0500</td>\n",
       "      <td>052-234-9300</td>\n",
       "      <td>...</td>\n",
       "      <td>44061.0</td>\n",
       "      <td>1174001.090</td>\n",
       "      <td>1724535.741</td>\n",
       "      <td>129.418488</td>\n",
       "      <td>35.501490</td>\n",
       "      <td>419445.2886</td>\n",
       "      <td>325423.2799</td>\n",
       "      <td>{'lat': 35.49578930000001, 'lng': 129.4156498}</td>\n",
       "      <td>35.495789</td>\n",
       "      <td>129.415650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22</td>\n",
       "      <td>전문대학(3년제)</td>\n",
       "      <td>춘해보건대학교</td>\n",
       "      <td>Choonhae College of Health Sciences</td>\n",
       "      <td>본교</td>\n",
       "      <td>기존</td>\n",
       "      <td>사립</td>\n",
       "      <td>NaN</td>\n",
       "      <td>052-270-0100</td>\n",
       "      <td>052-225-9889</td>\n",
       "      <td>...</td>\n",
       "      <td>44965.0</td>\n",
       "      <td>1153859.743</td>\n",
       "      <td>1719369.249</td>\n",
       "      <td>129.195529</td>\n",
       "      <td>35.458252</td>\n",
       "      <td>399318.1433</td>\n",
       "      <td>320151.5394</td>\n",
       "      <td>{'lat': 35.4578572, 'lng': 129.1964003}</td>\n",
       "      <td>35.457857</td>\n",
       "      <td>129.196400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>244</td>\n",
       "      <td>대학교</td>\n",
       "      <td>울산과학기술원</td>\n",
       "      <td>Ulsan National Institute of Science and Techno...</td>\n",
       "      <td>본교</td>\n",
       "      <td>기존</td>\n",
       "      <td>특별법법인</td>\n",
       "      <td>NaN</td>\n",
       "      <td>052-217-0114</td>\n",
       "      <td>052-217-1169</td>\n",
       "      <td>...</td>\n",
       "      <td>44919.0</td>\n",
       "      <td>1153251.630</td>\n",
       "      <td>1732117.722</td>\n",
       "      <td>129.191239</td>\n",
       "      <td>35.573245</td>\n",
       "      <td>398644.9578</td>\n",
       "      <td>332904.3754</td>\n",
       "      <td>{'lat': 35.5763317, 'lng': 129.189255}</td>\n",
       "      <td>35.576332</td>\n",
       "      <td>129.189255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>245</td>\n",
       "      <td>대학교</td>\n",
       "      <td>울산대학교</td>\n",
       "      <td>University of Ulsan</td>\n",
       "      <td>본교</td>\n",
       "      <td>기존</td>\n",
       "      <td>사립</td>\n",
       "      <td>NaN</td>\n",
       "      <td>052-259-2065</td>\n",
       "      <td>052-277-3419</td>\n",
       "      <td>...</td>\n",
       "      <td>44610.0</td>\n",
       "      <td>1159512.607</td>\n",
       "      <td>1728908.697</td>\n",
       "      <td>129.259673</td>\n",
       "      <td>35.543335</td>\n",
       "      <td>404925.9203</td>\n",
       "      <td>329725.2832</td>\n",
       "      <td>{'lat': 35.5437411, 'lng': 129.2562843}</td>\n",
       "      <td>35.543741</td>\n",
       "      <td>129.256284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>404</td>\n",
       "      <td>사내대학(전문)</td>\n",
       "      <td>현대중공업공과대학</td>\n",
       "      <td>Hyundai Heavy Industries Technical College</td>\n",
       "      <td>본교</td>\n",
       "      <td>기존</td>\n",
       "      <td>사립</td>\n",
       "      <td>NaN</td>\n",
       "      <td>052-202-9248</td>\n",
       "      <td>052-250-9066</td>\n",
       "      <td>...</td>\n",
       "      <td>44032.0</td>\n",
       "      <td>1175158.455</td>\n",
       "      <td>1726593.103</td>\n",
       "      <td>129.431687</td>\n",
       "      <td>35.519826</td>\n",
       "      <td>420592.9123</td>\n",
       "      <td>327487.7686</td>\n",
       "      <td>{'lat': 35.5166357, 'lng': 129.4380112}</td>\n",
       "      <td>35.516636</td>\n",
       "      <td>129.438011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      연번       학교종류        학교명  \\\n",
       "17    21  전문대학(3년제)    울산과학대학교   \n",
       "18    22  전문대학(3년제)    춘해보건대학교   \n",
       "214  244        대학교    울산과학기술원   \n",
       "215  245        대학교      울산대학교   \n",
       "369  404   사내대학(전문)  현대중공업공과대학   \n",
       "\n",
       "                                               학교명(영문) 본분교 학교상태     설립 남여공학  \\\n",
       "17                                       ULSAN COLLEGE  본교   기존     사립  NaN   \n",
       "18                 Choonhae College of Health Sciences  본교   기존     사립  NaN   \n",
       "214  Ulsan National Institute of Science and Techno...  본교   기존  특별법법인  NaN   \n",
       "215                                University of Ulsan  본교   기존     사립  NaN   \n",
       "369         Hyundai Heavy Industries Technical College  본교   기존     사립  NaN   \n",
       "\n",
       "             전화번호          팩스번호  ...     우편번호    UTM-K_X좌표    UTM-K_Y좌표  \\\n",
       "17   052-230-0500  052-234-9300  ...  44061.0  1174001.090  1724535.741   \n",
       "18   052-270-0100  052-225-9889  ...  44965.0  1153859.743  1719369.249   \n",
       "214  052-217-0114  052-217-1169  ...  44919.0  1153251.630  1732117.722   \n",
       "215  052-259-2065  052-277-3419  ...  44610.0  1159512.607  1728908.697   \n",
       "369  052-202-9248  052-250-9066  ...  44032.0  1175158.455  1726593.103   \n",
       "\n",
       "      WGS84_X좌표  WGS84_Y좌표     TM60_X좌표     TM60_Y좌표  \\\n",
       "17   129.418488  35.501490  419445.2886  325423.2799   \n",
       "18   129.195529  35.458252  399318.1433  320151.5394   \n",
       "214  129.191239  35.573245  398644.9578  332904.3754   \n",
       "215  129.259673  35.543335  404925.9203  329725.2832   \n",
       "369  129.431687  35.519826  420592.9123  327487.7686   \n",
       "\n",
       "                                            lat_lng   latitude   longitude  \n",
       "17   {'lat': 35.49578930000001, 'lng': 129.4156498}  35.495789  129.415650  \n",
       "18          {'lat': 35.4578572, 'lng': 129.1964003}  35.457857  129.196400  \n",
       "214          {'lat': 35.5763317, 'lng': 129.189255}  35.576332  129.189255  \n",
       "215         {'lat': 35.5437411, 'lng': 129.2562843}  35.543741  129.256284  \n",
       "369         {'lat': 35.5166357, 'lng': 129.4380112}  35.516636  129.438011  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "arranged-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_school_nearby(data, school_data = school_data, dist = 0.2, category_list = None):\n",
    "    data_copy = data.copy()\n",
    "    if category_list == None:\n",
    "        category_list = school_data[\"category\"].drop_duplicates().to_list()\n",
    "    \n",
    "    dist_list = school_data[[\"lat\", \"lng\"]].apply(lambda x: haversine((x[\"lat\"], x[\"lng\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "    within_data = school_data.loc[dist_list <= dist]\n",
    "    \n",
    "    \n",
    "    for i, ctgr in enumerate(category_list):\n",
    "        data_copy[f\"school_category_{i}\"] = (within_data[\"category\"] == ctgr).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "substantial-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 102.96it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 77.12it/s] \n",
      "100%|██████████| 11/11 [00:00<00:00, 76.67it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 81.10it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 79.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 74.05it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 75.82it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 73.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 74.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 86.17it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 81.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 747 ms, sys: 0 ns, total: 747 ms\n",
      "Wall time: 807 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bus_stop_401_info = parallelize_dataframe(df = bus_stop_401_info, \n",
    "                                              func = count_school_nearby, \n",
    "                                              num_cores = 12, \n",
    "                                              school_data = school_data, \n",
    "                                              dist = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-billion",
   "metadata": {},
   "source": [
    "### 정류장 정보 Join(거리기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "lyric-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.merge(ml_data, bus_stop_401_info.drop([\"stop_id\", \"city\"],1), on = \"mybi_stop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "demanding-lindsay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 175)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 175)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-military",
   "metadata": {},
   "source": [
    "### 울산행사정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "intelligent-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = pd.read_csv(\"~/Passenger_Demand/data/ulsan_event_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "handy-identity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 19)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "banned-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data[\"eventStartDate\"] = pd.to_datetime(event_data[\"eventStartDate\"], format = \"%Y-%m-%d\")\n",
    "event_data[\"eventEndDate\"] = pd.to_datetime(event_data[\"eventEndDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "broad-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_event_nearby(data, event_data, dist = 0.2):\n",
    "    data_copy = data.copy()\n",
    "    within_data = event_data.loc[(event_data[\"eventStartDate\"] <= data_copy[\"transdate\"]) & (event_data[\"eventEndDate\"] >= data_copy[\"transdate\"])]\n",
    "    \n",
    "    if len(within_data) == 0:\n",
    "        data_copy[f\"event_nearby\"] = 0\n",
    "    else:\n",
    "        dist_list = within_data[[\"latitude\", \"longitude\"]].apply(lambda x: haversine((x[\"latitude\"], x[\"longitude\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "        data_copy[f\"event_nearby\"] = (dist_list <= dist).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "indoor-lloyd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51745/51745 [03:32<00:00, 243.24it/s]\n",
      "100%|██████████| 51745/51745 [03:33<00:00, 242.30it/s]\n",
      "100%|██████████| 51745/51745 [03:38<00:00, 236.29it/s]\n",
      "100%|██████████| 51745/51745 [03:41<00:00, 234.05it/s]\n",
      "100%|██████████| 51745/51745 [03:42<00:00, 233.08it/s]\n",
      "100%|██████████| 51745/51745 [03:39<00:00, 235.81it/s]\n",
      "100%|██████████| 51745/51745 [03:41<00:00, 233.70it/s]\n",
      "100%|██████████| 51745/51745 [03:41<00:00, 233.23it/s]\n",
      "100%|██████████| 51745/51745 [03:39<00:00, 235.56it/s]\n",
      "100%|██████████| 51745/51745 [03:42<00:00, 232.61it/s]\n",
      "100%|██████████| 51745/51745 [03:41<00:00, 233.26it/s]\n",
      "100%|██████████| 51745/51745 [03:42<00:00, 232.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.8 s, sys: 0 ns, total: 32.8 s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = parallelize_dataframe(df = ml_data, \n",
    "                                func = count_event_nearby, \n",
    "                                num_cores = 12, \n",
    "                                event_data = event_data, \n",
    "                                dist = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "accepting-afternoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 176)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 176)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-cornell",
   "metadata": {},
   "source": [
    "### 축제 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "liberal-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data = pd.read_csv(\"~/Passenger_Demand/data/festival_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "spare-beaver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 18)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "festival_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "organizational-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "festival_data[\"fstvlStartDate\"] = pd.to_datetime(festival_data[\"fstvlStartDate\"], format = \"%Y-%m-%d\")\n",
    "festival_data[\"fstvlEndDate\"] = pd.to_datetime(festival_data[\"fstvlEndDate\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "automated-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_festival_nearby(data, festival_data, dist = 0.2):\n",
    "    data_copy = data.copy()\n",
    "    within_data = festival_data.loc[(festival_data[\"fstvlStartDate\"] <= data_copy[\"transdate\"]) & (festival_data[\"fstvlEndDate\"] >= data_copy[\"transdate\"])]\n",
    "    \n",
    "    if len(within_data) == 0:\n",
    "        data_copy[f\"festival_nearby\"] = 0\n",
    "    else:\n",
    "        dist_list = within_data[[\"latitude\", \"longitude\"]].apply(lambda x: haversine((x[\"latitude\"], x[\"longitude\"]), (data_copy[\"latitude\"], data_copy[\"longitude\"])), 1)\n",
    "        data_copy[f\"festival_nearby\"] = (dist_list <= dist).sum()\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "stuffed-lemon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51745/51745 [01:31<00:00, 563.83it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 560.97it/s]\n",
      "100%|██████████| 51745/51745 [01:31<00:00, 563.95it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 560.48it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 561.49it/s]\n",
      "100%|██████████| 51745/51745 [01:31<00:00, 563.31it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 561.81it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 561.99it/s]\n",
      "100%|██████████| 51745/51745 [01:32<00:00, 561.17it/s]\n",
      "100%|██████████| 51745/51745 [02:26<00:00, 352.92it/s]\n",
      "100%|██████████| 51745/51745 [02:27<00:00, 349.96it/s]\n",
      "100%|██████████| 51745/51745 [02:26<00:00, 353.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 0 ns, total: 1min 17s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_data = parallelize_dataframe(df = ml_data, \n",
    "                                func = count_festival_nearby, \n",
    "                                num_cores = 12, \n",
    "                                festival_data = festival_data, \n",
    "                                dist = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "configured-russell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620940, 177)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data.shape\n",
    "# (620940, 177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "political-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.drop([\"weekofyear\", \"date\"], 1).to_pickle(\"/home/seho/Passenger_Demand/data/ml_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-wings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-society",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-palestine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-auckland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "executive-disorder",
   "metadata": {},
   "source": [
    "### 인구 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = pd.read_csv(\"~/Passenger_Demand/data/울산광역시_인구 현황_20200727.csv\", encoding = \"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?latlng=35.60467,129.4328&key=AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://maps.googleapis.com/maps/api/geocode/json?latlng=35.60467,129.4328&key=AIzaSyBRxjIW7qfFhaVyCsc2xhk5mf1hXUSi9DI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps.reverse_geocode((35.60467, 129.4328), language = \"korean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
